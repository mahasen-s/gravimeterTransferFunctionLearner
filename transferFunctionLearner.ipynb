{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning prototype model\n",
    "Tensorflow implementation of a fully connected deep net for arbitrarily shaped input and output layers, with the following features:\n",
    "- Easy control of net topology and hyperparameters\n",
    "- Abstracted functions for retrieving/constructing training data\n",
    "- Exponential decay of learning rate\n",
    "- Dropout regularisation\n",
    "- Batch normalisation\n",
    "- Automatic logging of bulk statistics of each layer through tensorboard (and convenient functions to attach logging to custom functions)\n",
    "\n",
    "\n",
    "## Visualising progress\n",
    "To inspect the training progress, run\n",
    "\n",
    ">  `>tensorboard --logdir=<log_dir>`\n",
    "\n",
    "\n",
    "from the terminal, where `log_dir` as as defined above\n",
    "\n",
    "## Requirements\n",
    "- TensorFlow 1.8\n",
    "- numpy\n",
    "- subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from subprocess import call\n",
    "import time, math\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting dtype for tensorflow and numpy environments\n",
    "DTYPE = tf.float32\n",
    "DTYPE_np = np.float32\n",
    "log_dir = '/tmp/funclearn' # Directory where we dump tensorboard log files\n",
    "\n",
    "# Useful function for resetting logdir and tensorflow graph\n",
    "def reset_tf():\n",
    "    call([\"rm\",\"-rf\",log_dir+'/'])\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    \n",
    "# Define some functions for initialising layers with appropriate statistics    \n",
    "def get_weights(shape,dtype):\n",
    "    # Returns trainable weight variable, initialised from truncated (+\\- 2std. dev. only) standard normal distribution\n",
    "    return tf.Variable(tf.truncated_normal(shape, dtype=dtype),name='weights')\n",
    "\n",
    "def get_biases(shape,dtype):\n",
    "    # Returns trainable bias variable, initialised arbitrarily as a small constant\n",
    "    return tf.Variable(tf.constant(0.01, shape=shape, dtype=dtype),name='biases')\n",
    "\n",
    "def get_bn_offset(shape,dtype):\n",
    "    # Returns trainable bias/offset variable for batch normalisation\n",
    "    return tf.Variable(tf.truncated_normal(shape=shape, dtype=dtype),name='beta_offset')\n",
    "\n",
    "def get_bn_scale(shape,dtype):\n",
    "    # Returns trainable scale variable for batch normalisation\n",
    "    return tf.Variable(tf.constant(1.0, shape=shape, dtype=dtype),name='gamma_scale')\n",
    "\n",
    "\n",
    "def variable_summaries(var):\n",
    "    # Attaches mean, stddev, max, min, and a histogram of an input var to a tensor\n",
    "    # Useful for TensorBoard visualisation\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var,name='mean')\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var-mean)),name='stddev')\n",
    "        \n",
    "        tf.summary.scalar('mean',mean)\n",
    "        tf.summary.scalar('stddev',stddev)\n",
    "        tf.summary.scalar('max',tf.reduce_max(var))\n",
    "        tf.summary.scalar('min',tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)\n",
    "        \n",
    "def batchnorm(logits, is_test, offset, scale, iteration):\n",
    "    # Get summary statistics of this batch\n",
    "    mean, variance    = tf.nn.moments(logits, [0],name='moments')\n",
    "    \n",
    "    # We'll use an exponential moving average over the training iterations during test time\n",
    "    # This is a tool to do that\n",
    "    exp_moving_avg    = tf.train.ExponentialMovingAverage(0.9999, iteration)\n",
    "    update_moving_avg = exp_moving_avg.apply([mean, variance])\n",
    "    \n",
    "    # If this is the test, we use the m,v values we obtained from the exponential moving average \n",
    "    # over mean, variance that we obtained from training. otherwise use the batch mean, variance\n",
    "    mean_cond        = tf.cond(is_test, lambda: exp_moving_avg.average(mean), lambda: mean, name='mean_cond')\n",
    "    variance_cond    = tf.cond(is_test, lambda: exp_moving_avg.average(variance), lambda: variance, name='variance_cond')\n",
    "    \n",
    "    # This applies the following normalisation: x-> scale*(x-mean(x))/(variance_epsilon+std(x)) + offset\n",
    "    logits_bn = tf.nn.batch_normalization(logits, mean_cond, variance_cond, offset, scale, variance_epsilon=1e-5,name='logits_batchnormed')\n",
    "    \n",
    "    return logits_bn, update_moving_avg\n",
    "\n",
    "def get_layer_complete(input_tensor,input_dim, output_dim, layer_name, is_test, prob_keep, global_step, act_func=tf.nn.relu):\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = get_weights([input_dim, output_dim],DTYPE)\n",
    "            variable_summaries(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = get_biases([output_dim],DTYPE)\n",
    "            variable_summaries(biases)\n",
    "        with tf.name_scope('batchnorm'):\n",
    "            offset = get_bn_offset([output_dim], DTYPE)\n",
    "            scale  = get_bn_scale([output_dim], DTYPE)\n",
    "        \n",
    "        logits = tf.add(tf.matmul(input_tensor, weights),biases,name='logits')\n",
    "        tf.summary.histogram('logits', logits)\n",
    "        logits_bn, update_moving_avg = batchnorm(logits, is_test, offset, scale, global_step)\n",
    "        tf.summary.histogram('logits_batchNormed', logits_bn)\n",
    "        activated = act_func(logits_bn, name='activation')\n",
    "        dropped_out = tf.nn.dropout(activated,prob_keep,name='dropout')\n",
    "        tf.summary.histogram('activations', activated)\n",
    "        return dropped_out, update_moving_avg \n",
    "    \n",
    "def func_deep_learner_complete(x,m,n,h,is_test,global_step,prob_keep,act_func=tf.nn.relu,num_layers=5):\n",
    "    # x is the input variable, probably a TensorFlow placeholder object\n",
    "    # m is the input dimension\n",
    "    # n is the output dimension\n",
    "    # h is the number of hidden neurons\n",
    "    # act_func is the activation function to be applied\n",
    "    # is_test is a flag is use to control batch normalisation behaviour during inferene on test data\n",
    "    # iteration is the iteration counter used inside the training loop; required for batch normalisation\n",
    "    \n",
    "    bn_moving_avg_updates = []\n",
    "\n",
    "    with tf.variable_scope('func_learner'):\n",
    "        # 0th hidden layer\n",
    "        hidden_layer, update_moving_avg = get_layer_complete(x,m,h,'hidden_layer_0',is_test,prob_keep,global_step)\n",
    "        bn_moving_avg_updates.append(update_moving_avg)\n",
    "\n",
    "        # Other hidden layers\n",
    "        for i in range(num_layers-1):\n",
    "            hidden_layer, update_moving_avg = get_layer_complete(hidden_layer,h,h,'hidden_layer_'+str(i+1),is_test,prob_keep,global_step)\n",
    "            bn_moving_avg_updates.append(update_moving_avg)\n",
    "\n",
    "        # Output layer\n",
    "        weights1= tf.get_variable(name='output_layer_weights',\n",
    "                              shape=[h,n],\n",
    "                              initializer=tf.random_normal_initializer(),\n",
    "                              dtype=DTYPE)\n",
    "\n",
    "    return tf.matmul(hidden_layer,weights1), bn_moving_avg_updates\n",
    "\n",
    "def train_RBM_complete(input_size=1,output_size=1,hidden_size=1,num_layers=5,model_func=None,unknown_func=None,\n",
    "                  test_x=None, test_y = None, generate_training_samples_fun=None,\n",
    "                  batch_size=25, max_steps = 1000, epochs =5,\n",
    "                  initial_learning_rate = 0.02, decay_rate = 1/math.e, decay_steps=1000,\n",
    "                  prob_keep = 0.8):\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "            \n",
    "        with tf.name_scope('input'):\n",
    "            # Placeholder variables which will be fed data at train time\n",
    "            x  = tf.placeholder(DTYPE,[None,input_size],name='x_input')\n",
    "            y  = tf.placeholder(DTYPE,[None,output_size],name='y_input')\n",
    "        \n",
    "        with tf.name_scope('control_inputs'):\n",
    "            global_step = tf.Variable(0, trainable=False,name='global_step')\n",
    "            epoch_ind = tf.Variable(0,trainable=False,name='epoch_ind')\n",
    "            increment_epoch_ind = tf.assign_add(epoch_ind,1,name='increment_epoch_ind')\n",
    "            is_test = tf.contrib.eager.Variable(False, trainable=False,name='is_test')\n",
    "\n",
    "        # Predictions of the NN\n",
    "        y_pred, bn_moving_avg_updates = func_deep_learner_complete(x,input_size,output_size,hidden_size,is_test,global_step,1,num_layers=num_layers)\n",
    "\n",
    "        # Should add dropout!\n",
    "\n",
    "        with tf.name_scope('mean_squared_error'):\n",
    "            mse = tf.losses.mean_squared_error(y,y_pred)\n",
    "        tf.summary.scalar('mean_squared_error',mse)\n",
    "\n",
    "        with tf.name_scope('train'):\n",
    "            global_step_in_epoch = global_step - epoch_ind*max_steps\n",
    "            learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step_in_epoch, decay_steps, decay_rate, staircase=True)\n",
    "            tf.summary.scalar('learning_rate', learning_rate)\n",
    "            train_step = tf.train.AdamOptimizer(learning_rate).minimize(mse, global_step = global_step)\n",
    "\n",
    "        # Create merged summary object and file writers\n",
    "        merged_summaries = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(log_dir + '/test', sess.graph)\n",
    "        \n",
    "        # Initialise variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Train the model\n",
    "        start_time = time.time()\n",
    "        old_time = start_time\n",
    "        for j in range(epochs):\n",
    "            for i in range(max_steps):\n",
    "                if i % 100 ==0:\n",
    "                    # Check how our model performs against the test data\n",
    "                    [summary, mse_val] = sess.run([merged_summaries,mse], feed_dict={x: test_x, y: test_y, is_test: True})\n",
    "                    test_writer.add_summary(summary,i + j*max_steps)\n",
    "                    curr_time = time.time()\n",
    "                    print('Epoch %d, Step %04d, MSE: %4.3e,  LearnRate: %4.3e, Time taken : %4.3fs' % (sess.run(epoch_ind),i, mse_val, sess.run(learning_rate),curr_time-old_time))\n",
    "                    old_time = curr_time\n",
    "                else:\n",
    "                    # Generate new sample data and train our model\n",
    "                    train_x, train_y = generate_training_samples_fun(epoch_ind, global_step)\n",
    "                    summary, _ = sess.run([merged_summaries, train_step], feed_dict={x: train_x, y: train_y, is_test: False})\n",
    "                    sess.run(bn_moving_avg_updates, feed_dict={x: train_x, y: train_y, is_test: False})\n",
    "                    train_writer.add_summary(summary,i+ j*max_steps)\n",
    "            sess.run(increment_epoch_ind)\n",
    "        train_writer.close()\n",
    "        test_writer.close()     \n",
    "        print('\\nTotal time:\\t %4.3fs' % (time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex nonlinear function\n",
    "Example of learning a toy random nonlinear compelex-valued function. \n",
    "We separate real and imaginary parts and concatenate them into the inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function to create a random linear operator, f, \n",
    "# and another function to generate (x, f(x)) pairs\n",
    "\n",
    "def build_unknown_complex_nonlinear_func(m,n):\n",
    "    # m is the input dimension\n",
    "    # n is the output dimension\n",
    "    \n",
    "    #mat = tf.constant(np.random.rand(m,n),dtype=DTYPE)\n",
    "    #def unknown_func(x):\n",
    "    #   return tf.tensordot(x,mat,1) # check!\n",
    "    \n",
    "    mat0 = np.random.rand(m,n).astype(DTYPE_np) + 1j*np.random.rand(m,n).astype(DTYPE_np)\n",
    "    mat1 = np.random.rand(m,n).astype(DTYPE_np) + 1j*np.random.rand(m,n).astype(DTYPE_np)\n",
    "    \n",
    "    def unknown_func(x):\n",
    "        return np.matmul(np.power(x,2),mat0) + np.matmul(x,mat1)\n",
    "    \n",
    "    return [(mat0,mat1),unknown_func]\n",
    "\n",
    "def generate_samples(m,batch_size,unknown_func):\n",
    "    # Let's just assume that the input x values are random\n",
    "    \n",
    "    x = np.random.rand(batch_size,m)\n",
    "    y = unknown_func(x) \n",
    "    \n",
    "    # Concat real and imag\n",
    "    x_cat = np.concatenate((np.real(x),np.imag(x)),axis=1)\n",
    "    y_cat = np.concatenate((np.real(y),np.imag(y)),axis=1)\n",
    "    \n",
    "    return [x_cat,y_cat]\n",
    "\n",
    "def train_complex_func():\n",
    "    input_size = 8\n",
    "    output_size = 13\n",
    "    \n",
    "    hidden_size = 30\n",
    "    num_layers = 5\n",
    "    batch_size = 25\n",
    "    \n",
    "    test_size = 200\n",
    "    max_steps = 2001\n",
    "    decay_steps = 500\n",
    "    \n",
    "    \n",
    "    mat,unknown_func = build_unknown_complex_nonlinear_func(input_size,output_size)\n",
    "    test_x, test_y = generate_samples(input_size,test_size,unknown_func)\n",
    "    \n",
    "    # Define the function that will be called to create a new set batch of training data.\n",
    "    # It will be passed two arguments: epoch and global step (which is NOT reset at the start of each epoch)\n",
    "    generate_training_samples_fun = lambda epoch_ind, global_step: generate_samples(input_size,batch_size,unknown_func) # \n",
    "    \n",
    "    train_RBM_complete(input_size=2*input_size,output_size=2*output_size,hidden_size=hidden_size,num_layers = num_layers,unknown_func=unknown_func,\n",
    "                  test_x=test_x, test_y = test_y, generate_training_samples_fun=generate_training_samples_fun,\n",
    "                  batch_size=25, max_steps = max_steps, epochs =5, initial_learning_rate = 0.02, decay_rate = 1/math.e, decay_steps=decay_steps, prob_keep = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 0000, MSE: 4.233e+01,  LearnRate: 2.000e-02, Time taken : 0.323s\n",
      "Epoch 0, Step 0100, MSE: 3.496e-01,  LearnRate: 2.000e-02, Time taken : 2.049s\n",
      "Epoch 0, Step 0200, MSE: 1.809e-01,  LearnRate: 2.000e-02, Time taken : 0.879s\n",
      "Epoch 0, Step 0300, MSE: 1.076e-01,  LearnRate: 2.000e-02, Time taken : 0.802s\n",
      "Epoch 0, Step 0400, MSE: 9.051e-02,  LearnRate: 2.000e-02, Time taken : 0.848s\n",
      "Epoch 0, Step 0500, MSE: 9.097e-02,  LearnRate: 2.000e-02, Time taken : 0.990s\n",
      "Epoch 0, Step 0600, MSE: 7.832e-02,  LearnRate: 7.358e-03, Time taken : 0.945s\n",
      "Epoch 0, Step 0700, MSE: 7.033e-02,  LearnRate: 7.358e-03, Time taken : 0.878s\n",
      "Epoch 0, Step 0800, MSE: 7.854e-02,  LearnRate: 7.358e-03, Time taken : 0.831s\n",
      "Epoch 0, Step 0900, MSE: 7.081e-02,  LearnRate: 7.358e-03, Time taken : 0.871s\n",
      "Epoch 0, Step 1000, MSE: 6.770e-02,  LearnRate: 7.358e-03, Time taken : 0.941s\n",
      "Epoch 0, Step 1100, MSE: 5.948e-02,  LearnRate: 2.707e-03, Time taken : 0.974s\n",
      "Epoch 0, Step 1200, MSE: 5.801e-02,  LearnRate: 2.707e-03, Time taken : 0.991s\n",
      "Epoch 0, Step 1300, MSE: 5.778e-02,  LearnRate: 2.707e-03, Time taken : 0.908s\n",
      "Epoch 0, Step 1400, MSE: 5.530e-02,  LearnRate: 2.707e-03, Time taken : 0.901s\n",
      "Epoch 0, Step 1500, MSE: 5.497e-02,  LearnRate: 2.707e-03, Time taken : 0.967s\n",
      "Epoch 0, Step 1600, MSE: 5.435e-02,  LearnRate: 9.957e-04, Time taken : 1.027s\n",
      "Epoch 0, Step 1700, MSE: 5.360e-02,  LearnRate: 9.957e-04, Time taken : 0.931s\n",
      "Epoch 0, Step 1800, MSE: 5.281e-02,  LearnRate: 9.957e-04, Time taken : 0.924s\n",
      "Epoch 0, Step 1900, MSE: 5.270e-02,  LearnRate: 9.957e-04, Time taken : 0.897s\n",
      "Epoch 0, Step 2000, MSE: 5.207e-02,  LearnRate: 9.957e-04, Time taken : 0.896s\n",
      "Epoch 1, Step 0000, MSE: 5.207e-02,  LearnRate: 5.437e-02, Time taken : 0.032s\n",
      "Epoch 1, Step 0100, MSE: 4.768e-02,  LearnRate: 2.000e-02, Time taken : 0.941s\n",
      "Epoch 1, Step 0200, MSE: 5.149e-02,  LearnRate: 2.000e-02, Time taken : 0.896s\n",
      "Epoch 1, Step 0300, MSE: 4.327e-02,  LearnRate: 2.000e-02, Time taken : 0.869s\n",
      "Epoch 1, Step 0400, MSE: 4.937e-02,  LearnRate: 2.000e-02, Time taken : 0.846s\n",
      "Epoch 1, Step 0500, MSE: 3.159e-02,  LearnRate: 2.000e-02, Time taken : 0.837s\n",
      "Epoch 1, Step 0600, MSE: 4.086e-02,  LearnRate: 7.358e-03, Time taken : 0.975s\n",
      "Epoch 1, Step 0700, MSE: 4.278e-02,  LearnRate: 7.358e-03, Time taken : 0.934s\n",
      "Epoch 1, Step 0800, MSE: 2.937e-02,  LearnRate: 7.358e-03, Time taken : 0.931s\n",
      "Epoch 1, Step 0900, MSE: 2.747e-02,  LearnRate: 7.358e-03, Time taken : 0.916s\n",
      "Epoch 1, Step 1000, MSE: 2.884e-02,  LearnRate: 7.358e-03, Time taken : 0.925s\n",
      "Epoch 1, Step 1100, MSE: 2.444e-02,  LearnRate: 2.707e-03, Time taken : 0.892s\n",
      "Epoch 1, Step 1200, MSE: 2.679e-02,  LearnRate: 2.707e-03, Time taken : 0.866s\n",
      "Epoch 1, Step 1300, MSE: 2.667e-02,  LearnRate: 2.707e-03, Time taken : 0.909s\n",
      "Epoch 1, Step 1400, MSE: 2.592e-02,  LearnRate: 2.707e-03, Time taken : 0.935s\n",
      "Epoch 1, Step 1500, MSE: 2.762e-02,  LearnRate: 2.707e-03, Time taken : 0.881s\n",
      "Epoch 1, Step 1600, MSE: 2.176e-02,  LearnRate: 9.957e-04, Time taken : 0.941s\n",
      "Epoch 1, Step 1700, MSE: 2.112e-02,  LearnRate: 9.957e-04, Time taken : 0.942s\n",
      "Epoch 1, Step 1800, MSE: 2.162e-02,  LearnRate: 9.957e-04, Time taken : 0.912s\n",
      "Epoch 1, Step 1900, MSE: 2.051e-02,  LearnRate: 9.957e-04, Time taken : 0.888s\n",
      "Epoch 1, Step 2000, MSE: 2.088e-02,  LearnRate: 9.957e-04, Time taken : 0.958s\n",
      "Epoch 2, Step 0000, MSE: 2.088e-02,  LearnRate: 5.437e-02, Time taken : 0.008s\n",
      "Epoch 2, Step 0100, MSE: 3.217e-02,  LearnRate: 2.000e-02, Time taken : 0.848s\n",
      "Epoch 2, Step 0200, MSE: 6.804e-02,  LearnRate: 2.000e-02, Time taken : 0.980s\n",
      "Epoch 2, Step 0300, MSE: 2.428e-02,  LearnRate: 2.000e-02, Time taken : 0.944s\n",
      "Epoch 2, Step 0400, MSE: 3.071e-02,  LearnRate: 2.000e-02, Time taken : 0.824s\n",
      "Epoch 2, Step 0500, MSE: 1.398e-01,  LearnRate: 2.000e-02, Time taken : 0.919s\n",
      "Epoch 2, Step 0600, MSE: 2.220e-02,  LearnRate: 7.358e-03, Time taken : 0.996s\n",
      "Epoch 2, Step 0700, MSE: 1.844e-02,  LearnRate: 7.358e-03, Time taken : 0.959s\n",
      "Epoch 2, Step 0800, MSE: 2.455e-02,  LearnRate: 7.358e-03, Time taken : 1.039s\n",
      "Epoch 2, Step 0900, MSE: 1.361e-02,  LearnRate: 7.358e-03, Time taken : 0.993s\n",
      "Epoch 2, Step 1000, MSE: 3.975e-02,  LearnRate: 7.358e-03, Time taken : 1.075s\n",
      "Epoch 2, Step 1100, MSE: 1.464e-02,  LearnRate: 2.707e-03, Time taken : 0.956s\n",
      "Epoch 2, Step 1200, MSE: 1.005e-02,  LearnRate: 2.707e-03, Time taken : 0.927s\n",
      "Epoch 2, Step 1300, MSE: 1.020e-02,  LearnRate: 2.707e-03, Time taken : 0.849s\n",
      "Epoch 2, Step 1400, MSE: 1.054e-02,  LearnRate: 2.707e-03, Time taken : 0.845s\n",
      "Epoch 2, Step 1500, MSE: 1.054e-02,  LearnRate: 2.707e-03, Time taken : 0.872s\n",
      "Epoch 2, Step 1600, MSE: 1.174e-02,  LearnRate: 9.957e-04, Time taken : 0.860s\n",
      "Epoch 2, Step 1700, MSE: 1.510e-02,  LearnRate: 9.957e-04, Time taken : 0.873s\n",
      "Epoch 2, Step 1800, MSE: 8.796e-03,  LearnRate: 9.957e-04, Time taken : 0.862s\n",
      "Epoch 2, Step 1900, MSE: 9.229e-03,  LearnRate: 9.957e-04, Time taken : 0.803s\n",
      "Epoch 2, Step 2000, MSE: 8.106e-03,  LearnRate: 9.957e-04, Time taken : 0.791s\n",
      "Epoch 3, Step 0000, MSE: 8.106e-03,  LearnRate: 5.437e-02, Time taken : 0.009s\n",
      "Epoch 3, Step 0100, MSE: 3.103e-02,  LearnRate: 2.000e-02, Time taken : 0.811s\n",
      "Epoch 3, Step 0200, MSE: 2.815e-02,  LearnRate: 2.000e-02, Time taken : 0.880s\n",
      "Epoch 3, Step 0300, MSE: 1.892e-02,  LearnRate: 2.000e-02, Time taken : 0.899s\n",
      "Epoch 3, Step 0400, MSE: 1.374e-02,  LearnRate: 2.000e-02, Time taken : 0.891s\n",
      "Epoch 3, Step 0500, MSE: 3.689e-02,  LearnRate: 2.000e-02, Time taken : 0.858s\n",
      "Epoch 3, Step 0600, MSE: 6.492e-03,  LearnRate: 7.358e-03, Time taken : 0.887s\n",
      "Epoch 3, Step 0700, MSE: 6.723e-03,  LearnRate: 7.358e-03, Time taken : 0.852s\n",
      "Epoch 3, Step 0800, MSE: 9.801e-03,  LearnRate: 7.358e-03, Time taken : 0.895s\n",
      "Epoch 3, Step 0900, MSE: 8.107e-03,  LearnRate: 7.358e-03, Time taken : 0.869s\n",
      "Epoch 3, Step 1000, MSE: 8.188e-03,  LearnRate: 7.358e-03, Time taken : 0.847s\n",
      "Epoch 3, Step 1100, MSE: 8.410e-03,  LearnRate: 2.707e-03, Time taken : 0.843s\n",
      "Epoch 3, Step 1200, MSE: 4.602e-03,  LearnRate: 2.707e-03, Time taken : 0.895s\n",
      "Epoch 3, Step 1300, MSE: 6.540e-03,  LearnRate: 2.707e-03, Time taken : 0.956s\n",
      "Epoch 3, Step 1400, MSE: 5.096e-03,  LearnRate: 2.707e-03, Time taken : 0.849s\n",
      "Epoch 3, Step 1500, MSE: 8.566e-03,  LearnRate: 2.707e-03, Time taken : 0.836s\n",
      "Epoch 3, Step 1600, MSE: 4.987e-03,  LearnRate: 9.957e-04, Time taken : 0.961s\n",
      "Epoch 3, Step 1700, MSE: 5.063e-03,  LearnRate: 9.957e-04, Time taken : 0.914s\n",
      "Epoch 3, Step 1800, MSE: 5.553e-03,  LearnRate: 9.957e-04, Time taken : 0.848s\n",
      "Epoch 3, Step 1900, MSE: 4.458e-03,  LearnRate: 9.957e-04, Time taken : 0.875s\n",
      "Epoch 3, Step 2000, MSE: 9.627e-03,  LearnRate: 9.957e-04, Time taken : 0.883s\n",
      "Epoch 4, Step 0000, MSE: 9.627e-03,  LearnRate: 5.437e-02, Time taken : 0.007s\n",
      "Epoch 4, Step 0100, MSE: 3.662e-02,  LearnRate: 2.000e-02, Time taken : 0.874s\n",
      "Epoch 4, Step 0200, MSE: 2.133e-02,  LearnRate: 2.000e-02, Time taken : 0.864s\n",
      "Epoch 4, Step 0300, MSE: 1.693e-02,  LearnRate: 2.000e-02, Time taken : 0.885s\n",
      "Epoch 4, Step 0400, MSE: 1.312e-02,  LearnRate: 2.000e-02, Time taken : 0.888s\n",
      "Epoch 4, Step 0500, MSE: 1.722e-02,  LearnRate: 2.000e-02, Time taken : 0.888s\n",
      "Epoch 4, Step 0600, MSE: 8.178e-03,  LearnRate: 7.358e-03, Time taken : 0.928s\n",
      "Epoch 4, Step 0700, MSE: 1.864e-02,  LearnRate: 7.358e-03, Time taken : 0.936s\n",
      "Epoch 4, Step 0800, MSE: 7.340e-03,  LearnRate: 7.358e-03, Time taken : 0.899s\n",
      "Epoch 4, Step 0900, MSE: 1.036e-02,  LearnRate: 7.358e-03, Time taken : 0.873s\n",
      "Epoch 4, Step 1000, MSE: 2.931e-02,  LearnRate: 7.358e-03, Time taken : 0.862s\n",
      "Epoch 4, Step 1100, MSE: 6.394e-03,  LearnRate: 2.707e-03, Time taken : 0.876s\n",
      "Epoch 4, Step 1200, MSE: 5.402e-03,  LearnRate: 2.707e-03, Time taken : 0.936s\n",
      "Epoch 4, Step 1300, MSE: 4.610e-03,  LearnRate: 2.707e-03, Time taken : 0.842s\n",
      "Epoch 4, Step 1400, MSE: 7.503e-03,  LearnRate: 2.707e-03, Time taken : 0.828s\n",
      "Epoch 4, Step 1500, MSE: 5.053e-03,  LearnRate: 2.707e-03, Time taken : 0.916s\n",
      "Epoch 4, Step 1600, MSE: 9.811e-03,  LearnRate: 9.957e-04, Time taken : 0.942s\n",
      "Epoch 4, Step 1700, MSE: 4.044e-03,  LearnRate: 9.957e-04, Time taken : 0.933s\n",
      "Epoch 4, Step 1800, MSE: 4.170e-03,  LearnRate: 9.957e-04, Time taken : 0.851s\n",
      "Epoch 4, Step 1900, MSE: 3.968e-03,  LearnRate: 9.957e-04, Time taken : 0.840s\n",
      "Epoch 4, Step 2000, MSE: 4.531e-03,  LearnRate: 9.957e-04, Time taken : 0.935s\n",
      "\n",
      "Total time:\t 91.587s\n"
     ]
    }
   ],
   "source": [
    "train_complex_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = './ChrisFreierPhDCampaigns/campaign4a.h5'\n",
    "f = h5py.File(fname,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: KeysView(<HDF5 file \"campaign4a.h5\" (mode r)>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys: %s\" % f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(T,tau)\n",
      "accelerometer\n",
      "ai_kdown\n",
      "ai_kup\n"
     ]
    }
   ],
   "source": [
    "for key in f.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerometer = np.array(f['accelerometer'])\n",
    "ai_kdown = np.array(f['ai_kdown'])\n",
    "ai_kup = np.array(f['ai_kup'])\n",
    "T_tau = np.array(f['(T,tau)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000001, 2)\n",
      "(103427, 2)\n",
      "(103403, 2)\n"
     ]
    }
   ],
   "source": [
    "print(accelerometer.shape)\n",
    "print(ai_kdown.shape)\n",
    "print(ai_kup.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a Mach-Zehnder interferometer with interrogation time $T$ and pulse duration $\\tau$. The total interferometer phase is given by:\n",
    "$$\\Delta\\Phi = \\phi_{eff}^1 - 2\\phi_{eff}^2 + \\phi_{eff}^3 + \\left(\\mathrm{arg}(\\Theta_0^1)-\\mathrm{arg}(\\Theta^3_0)\\right)$$\n",
    "where $\\phi_{eff}^i$ describes the \"light phase at the atomic positions during the three Raman pulses\". $\\Theta_0^i$ descibes secondary phase shifts due to \"different light shifts between the first and last pulse\".\n",
    "\n",
    "Define the sensitivity function $g(t)$ as the effect on the total interferometer phase due to a phase jump $\\delta\\phi$ at time $t$. For the three-pulse Mach-Zehnder, with second pulse centered at $t=0$, $g(t)$ is given by:\n",
    "$$g(t) = \\begin{cases}\n",
    "\\sin(\\Omega_rt), & 0<t\\leq\\tau \\\\\n",
    "1, & \\tau<t\\leq T+\\tau\\\\\n",
    "-\\sin(\\Omega_r(T-t)), & T+\\tau<t\\leq T+2\\tau \\\\\n",
    "0, & t>T+2\\tau\n",
    "\\end{cases}$$\n",
    "\n",
    "For finite Raman pulse duration (i.e. $\\tau>0$), the total interferometer phase is given by:\n",
    "$$\\Delta\\Phi = \\int_{-(T_2\\tau)}^{(T+2\\tau)}g(t)\\frac{d\\phi(t)}{dt}dt$$\n",
    "\n",
    "To perform post-correction, we separtely calculate the phase offset caused by mirror vibrations:\n",
    "$$\\Phi_{vib} = k_{eff}\\int_{t_1}^{t_3}g(t)v(t)dt$$\n",
    "where $v(t)=\\frac{1}{k_{eff}}\\frac{d\\phi}{dt}$ is the mirror velocity and $k_eff$ is the effective wavevector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data layout\n",
    "Data is organised into campaigns, each containing ~10^5 interferometer runs. Use only 4a onwards.\n",
    "Each `.h5` has three fields\n",
    "- `accelerometer`: `[N_a,2]` linearly proportional to the raw out from the accelerometer as a time series. 1st column is linux time, 2nd column is signal\n",
    "- `ai_kdown`: `[N_p,2]` total interferometer phase for kdown? configuration. 1st column is linux time, 2nd column is phase. Each row is the total interferometer phase for an Mach-Zehnder sequence with 2nd pulse centered at the given time\n",
    "- `ai_kup`: `[N_p,2]` total interferometer phase for kup? configuration. Same layout as `ai_kdown`\n",
    "- `(T,tau)`: `[2,]` the interferometer interrogation time `T` and the $\\frac{\\pi}{2}$ Raman pulse duration `tau`\n",
    "\n",
    "First we need to prepare the data.\n",
    "\n",
    "(1) Check timestamps of `ai_kdown`==`ai_kup`\n",
    "- THEY DON'T; they aren't even necessarily the same length. Assume that each corresponds to a completely different subsequence of `accelerometer`\n",
    "- Also, note that the distribution of delays between successive runs is weirdly distributed\n",
    "\n",
    "(2) For each ai_* associate a contiguous subsequence of `accelerometer`\n",
    " - Ensure each subsequence is of equal length `N_s`\n",
    " - Will being left/right aligned w.r.t. rounding of `ai_kdown` timestamp to `accelerometer` timestamps affect anything?\n",
    " - Safest thing to do might be linearly interpolate `accelerometer` to ensure that `accelerometer` subsequence is correctly time-aligned with `ai_*`\n",
    " \n",
    "(3) Construct our inputs and outputs\n",
    " - `x_input` = `[N_s,N_p]` array\n",
    " - `y_output` = `[N_p,2]` concatenate 2nd column of `ai_kdown` and `ai_kup`\n",
    "    \n",
    "## Check\n",
    "Make sure we can reproduce original data (i.e. reproduce original $\\Phi_{vib}$)\n",
    " - Do we have this data?\n",
    "    \n",
    "## Modelling\n",
    "(1) *Model-free* Just use the inputs and labels as they are (assuming `N_s` is small enough)\n",
    " - Pros: easy\n",
    " - Cons: no ground-truth to compare against\n",
    "\n",
    "(2) *Explicit transfer function* Apply unknown function in Laplace space ($\\mathcal{L}\\{y(t)\\}(Z) =H(Z)\\mathcal{L}\\{x(t)\\}(Z)$ )\n",
    " - Pros: ground-truth to compare against\n",
    " - Cons: less easy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(T,tau)', 'accelerometer', 'ai_kdown', 'ai_kup']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('(T,tau)', <HDF5 dataset \"(T,tau)\": shape (2,), type \"<f8\">),\n",
       " ('accelerometer',\n",
       "  <HDF5 dataset \"accelerometer\": shape (100000001, 2), type \"<f8\">),\n",
       " ('ai_kdown', <HDF5 dataset \"ai_kdown\": shape (103427, 2), type \"<f8\">),\n",
       " ('ai_kup', <HDF5 dataset \"ai_kup\": shape (103403, 2), type \"<f8\">)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('(T,tau)', <HDF5 dataset \"(T,tau)\": shape (2,), type \"<f8\">),\n",
       " ('accelerometer',\n",
       "  <HDF5 dataset \"accelerometer\": shape (100000001, 2), type \"<f8\">),\n",
       " ('ai_kdown', <HDF5 dataset \"ai_kdown\": shape (80337, 2), type \"<f8\">),\n",
       " ('ai_kup', <HDF5 dataset \"ai_kup\": shape (80347, 2), type \"<f8\">)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = './ChrisFreierPhDCampaigns/campaign5a.h5'\n",
    "f0 = h5py.File(fname,'r')\n",
    "list(f0.keys())\n",
    "list(f0.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Processed campaign4a\n",
    "Matlab used to assign subsequences in `accelerometer` to each entry in `ai_kup` and `ai_kdown`.\n",
    "Subsequence length is 195. ~100000 entries for each of `ai_kup` and `ai_kdown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('T', <HDF5 dataset \"T\": shape (1,), type \"<f8\">),\n",
       " ('ai_kdown', <HDF5 group \"/ai_kdown\" (3 members)>),\n",
       " ('ai_kup', <HDF5 group \"/ai_kup\" (3 members)>),\n",
       " ('tau', <HDF5 dataset \"tau\": shape (1,), type \"<f8\">)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = './campaign4a_proc.h5'\n",
    "f0 = h5py.File(fname,'r')\n",
    "list(f0.keys())\n",
    "list(f0.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function that will generate indices for batches\n",
    "# accounting for the possibility that the size of the dataset\n",
    "# will not be an even multiple of the batch size\n",
    "def generate_batches(N,batch_size=32):\n",
    "    # N is the number of elements in the dataset\n",
    "    if N<batch_size:\n",
    "        raise ValueError('batch_size must be smaller than N')\n",
    "    perm = np.random.permutation(N);\n",
    "    if np.mod(N,batch_size)!=0:\n",
    "        # We need to append to perm so that is is an even multiple of batch_size\n",
    "        perm2= np.random.permutation(N);\n",
    "        perm = np.concatenate((perm,perm2[0:batch_size-np.mod(N,batch_size)]))\n",
    "    \n",
    "    n_batches = np.int(len(perm)/batch_size)\n",
    "    batches = perm.reshape(batch_size,n_batches)\n",
    "    \n",
    "    return batches\n",
    "\n",
    "def get_xy_by_inds(x,y,inds):\n",
    "    # Get values from 2Dx, 1Dy arrays\n",
    "    x0 = x[inds,:]\n",
    "    y0 = np.array(list(map(y.__getitem__,inds))) # because Python treats 1D arrays differently from ND arrays\n",
    "    y0 = y0.reshape([len(y0),1])\n",
    "    return x0,y0\n",
    "    \n",
    "def generate_testtrain(x,y,test_fraction,batch_size=32):\n",
    "    # Assumes x.shape = [n_samples,input_size], y.shape = [input_size,]\n",
    "    if test_fraction<0 or test_fraction>1:\n",
    "        raise ValueError('test_fraction must be between 0 and 1')\n",
    "    \n",
    "    n_samples  = x.shape[0]\n",
    "    test_size  = np.int(np.round(n_samples*test_fraction))\n",
    "    if test_size<1:\n",
    "        raise ValueError('test_fraction is too small')\n",
    "    train_size = np.int(n_samples-test_size)\n",
    "    \n",
    "    # Permute x,y\n",
    "    perm = np.random.permutation(n_samples)\n",
    "    permi= np.argsort(perm)\n",
    "    x0,y0= get_xy_by_inds(x,y,permi)\n",
    "                    \n",
    "    train_x = x0[:train_size,:]\n",
    "    train_y = y0[:train_size,:]\n",
    "    \n",
    "    test_x  = x0[train_size:,:]\n",
    "    test_y  = y0[train_size:,:]\n",
    "    \n",
    "    batches = generate_batches(train_size,batch_size)\n",
    "    \n",
    "    return test_x,test_y,train_x,train_y,batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 1 3 5 0 6]\n",
      "[7, 4, 5, 6, 6, 0, 9]\n",
      "[[8 0 7 7 3 6 7 6]\n",
      " [3 6 1 9 3 4 7 5]\n",
      " [1 3 8 6 4 9 5 0]\n",
      " [5 5 7 8 0 0 2 4]\n",
      " [2 4 1 2 5 2 0 4]\n",
      " [3 3 1 7 0 8 3 3]\n",
      " [7 4 6 2 6 9 5 6]]\n",
      "[[2 4 1 2 5 2 0 4]\n",
      " [1 3 8 6 4 9 5 0]\n",
      " [3 6 1 9 3 4 7 5]\n",
      " [5 5 7 8 0 0 2 4]\n",
      " [3 3 1 7 0 8 3 3]\n",
      " [8 0 7 7 3 6 7 6]\n",
      " [7 4 6 2 6 9 5 6]]\n"
     ]
    }
   ],
   "source": [
    "P = [0,5,4,6,7,6,9]\n",
    "X = np.random.randint(10,size=[7,8])\n",
    "p = np.random.permutation(len(P))\n",
    "pi= np.argsort(p)\n",
    "print(pi)\n",
    "print(list(map(P.__getitem__,pi)))\n",
    "print(X)\n",
    "print(X[pi,:])\n",
    "test_x,test_y,train_x,train_y,batches = generate_testtrain(X,P,0.25,batch_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5, 5, 7, 8, 0, 0, 2, 4],\n",
       "        [3, 6, 1, 9, 3, 4, 7, 5],\n",
       "        [1, 3, 8, 6, 4, 9, 5, 0]]), array([6, 5, 4]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_xy_by_inds(X,P,batches[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'phase', 'timestamp']\n",
      "<HDF5 dataset \"acc\": shape (103403, 195), type \"<f8\">\n",
      "<HDF5 dataset \"phase\": shape (103403,), type \"<f8\">\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "103403"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(dset.keys()))\n",
    "print(repr(dset['acc']))\n",
    "print(repr(dset['phase']))\n",
    "dset['phase'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_deep_learner_arbshape(x,m,n,h,is_test,global_step,prob_keep,act_func=tf.nn.relu):\n",
    "    # x is the input variable, probably a TensorFlow placeholder object\n",
    "    # m is the input dimension\n",
    "    # n is the output dimension\n",
    "    # h is a LIST of hidden neurons\n",
    "    # act_func is the activation function to be applied\n",
    "    # is_test is a flag is use to control batch normalisation behaviour during inferene on test data\n",
    "    # iteration is the iteration counter used inside the training loop; required for batch normalisation\n",
    "    \n",
    "    num_layers = len(h)\n",
    "    \n",
    "    bn_moving_avg_updates = []\n",
    "\n",
    "    with tf.variable_scope('func_learner'):\n",
    "        # 0th hidden layer\n",
    "        hidden_layer, update_moving_avg = get_layer_complete(x,m,h[0],'hidden_layer_0',is_test,prob_keep,global_step)\n",
    "        bn_moving_avg_updates.append(update_moving_avg)\n",
    "\n",
    "        # Other hidden layers\n",
    "        for i in range(num_layers-1):\n",
    "            hidden_layer, update_moving_avg = get_layer_complete(hidden_layer,h[i],h[i+1],'hidden_layer_'+str(i+1),is_test,prob_keep,global_step)\n",
    "            bn_moving_avg_updates.append(update_moving_avg)\n",
    "\n",
    "        # Output layer\n",
    "        weights1= tf.get_variable(name='output_layer_weights',\n",
    "                              shape=[h[-1],n],\n",
    "                              initializer=tf.random_normal_initializer(),\n",
    "                              dtype=DTYPE)\n",
    "\n",
    "    return tf.matmul(hidden_layer,weights1), bn_moving_avg_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RBM_complete_mccv(input_size=1,output_size=1,hidden_sizes=[5,5],x_data=None,y_data=None,\n",
    "                  batch_size=32, epochs =5, test_fraction=0.1, test_interval=250,\n",
    "                  initial_learning_rate = 0.02, decay_rate = 1/math.e, decay_steps=2000,\n",
    "                  epoch_learning_rate_decay = 0.5, epoch_learning_rate_interval = 10,\n",
    "                  prob_keep = 0.8):\n",
    "    # Using montecarlo crossvalidation\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Generate test data initially for convenience\n",
    "        test_x,test_y,train_x_full,train_y_full,batches = generate_testtrain(x_data,y_data,test_fraction,batch_size)\n",
    "        max_steps = batches.shape[1]\n",
    "            \n",
    "        with tf.name_scope('input'):\n",
    "            # Placeholder variables which will be fed data at train time\n",
    "            x  = tf.placeholder(DTYPE,[None,input_size],name='x_input')\n",
    "            y  = tf.placeholder(DTYPE,[None,output_size],name='y_input')\n",
    "        \n",
    "        with tf.name_scope('control_inputs'):\n",
    "            global_step = tf.Variable(0, trainable=False,name='global_step')\n",
    "            epoch_ind = tf.Variable(0,trainable=False,name='epoch_ind')\n",
    "            increment_epoch_ind = tf.assign_add(epoch_ind,1,name='increment_epoch_ind')\n",
    "            is_test = tf.contrib.eager.Variable(False, trainable=False,name='is_test')\n",
    "\n",
    "        # Predictions of the NN\n",
    "        y_pred, bn_moving_avg_updates = func_deep_learner_arbshape(x,input_size,output_size,hidden_sizes,is_test,global_step,1)\n",
    "\n",
    "        with tf.name_scope('mean_squared_error'):\n",
    "            mse = tf.losses.mean_squared_error(y,y_pred)\n",
    "        tf.summary.scalar('mean_squared_error',mse)\n",
    "\n",
    "        with tf.name_scope('train'):\n",
    "            global_step_in_epoch = global_step - epoch_ind*max_steps\n",
    "            #learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step_in_epoch, decay_steps, decay_rate, staircase=True)\n",
    "            learning_rate = tf.train.exponential_decay(initial_learning_rate, epoch_ind, epoch_learning_rate_interval, epoch_learning_rate_decay, staircase=True)\n",
    "            tf.summary.scalar('learning_rate', learning_rate)\n",
    "            train_step = tf.train.AdamOptimizer(learning_rate).minimize(mse, global_step = global_step)\n",
    "\n",
    "        # Create merged summary object and file writers\n",
    "        merged_summaries = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(log_dir + '/test', sess.graph)\n",
    "        \n",
    "        # Initialise variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Train the model\n",
    "        start_time = time.time()\n",
    "        old_time = start_time\n",
    "        for j in range(epochs):\n",
    "            # At each epoch, regenerate test data, train data, and batches\n",
    "            test_x,test_y,train_x_full,train_y_full,batches = generate_testtrain(x_data,y_data,test_fraction,batch_size)\n",
    "            n_batches = batches.shape[1]\n",
    "                \n",
    "            print('Starting Epoch %d, with %d batches' % (j,max_steps))\n",
    "            for i in range(n_batches):\n",
    "                if i % test_interval ==0:\n",
    "                    # Check how our model performs against the test data\n",
    "                    [summary, mse_val] = sess.run([merged_summaries,mse], feed_dict={x: test_x, y: test_y, is_test: True})\n",
    "                    test_writer.add_summary(summary,i + j*max_steps)\n",
    "                    curr_time = time.time()\n",
    "                    print('\\tEpoch %d, Step %04d, MSE: %4.3e,  LearnRate: %4.3e, Time taken : %4.3fs' % (sess.run(epoch_ind),i, mse_val, sess.run(learning_rate),curr_time-old_time))\n",
    "                    old_time = curr_time\n",
    "                else:\n",
    "                    # Generate new sample data and train our model\n",
    "                    train_x, train_y = get_xy_by_inds(train_x_full,train_y_full,batches[:,i])\n",
    "                    summary, _ = sess.run([merged_summaries, train_step], feed_dict={x: train_x, y: train_y, is_test: False})\n",
    "                    sess.run(bn_moving_avg_updates, feed_dict={x: train_x, y: train_y, is_test: False})\n",
    "                    train_writer.add_summary(summary,i+ j*max_steps)\n",
    "            sess.run(increment_epoch_ind)\n",
    "        train_writer.close()\n",
    "        test_writer.close()     \n",
    "        print('\\nTotal time:\\t %4.3fs' % (time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_ai_kup(acc,phase):\n",
    "    n_samples  = acc.shape[0]\n",
    "    seq_length = acc.shape[1]\n",
    "    \n",
    "    input_size  = seq_length\n",
    "    output_size = 1\n",
    "    \n",
    "    hidden_sizes = [80,40,20,10,5]\n",
    "    num_layers  = 5\n",
    "    batch_size  = 32\n",
    "    \n",
    "    mccv_steps   = 100\n",
    "    test_fraction= 0.1\n",
    "    \n",
    "    train_RBM_complete_mccv(input_size=input_size,output_size=output_size,hidden_sizes=hidden_sizes,\n",
    "                            x_data=acc,y_data=phase,batch_size=batch_size, epochs=mccv_steps,test_fraction=test_fraction,test_interval=100,\n",
    "                            initial_learning_rate = 0.5, decay_rate = 1/math.e, decay_steps=3000,\n",
    "                            epoch_learning_rate_decay = 0.5, epoch_learning_rate_interval = 10,\n",
    "                            prob_keep = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'phase', 'timestamp']\n",
      "<HDF5 dataset \"acc\": shape (103403, 195), type \"<f8\">\n",
      "<HDF5 dataset \"phase\": shape (103403,), type \"<f8\">\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "103403"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(dset.keys()))\n",
    "print(repr(dset['acc']))\n",
    "print(repr(dset['phase']))\n",
    "dset['phase'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_kup_phase = np.array(list(dset['phase']))\n",
    "ai_kup_acc = np.array(list(dset['acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0, with 2909 batches\n",
      "\tEpoch 0, Step 0000, MSE: 1.143e+14,  LearnRate: 5.000e-01, Time taken : 0.501s\n",
      "\tEpoch 0, Step 0100, MSE: 1.137e+14,  LearnRate: 5.000e-01, Time taken : 2.063s\n",
      "\tEpoch 0, Step 0200, MSE: 1.115e+14,  LearnRate: 5.000e-01, Time taken : 0.972s\n",
      "\tEpoch 0, Step 0300, MSE: 1.077e+14,  LearnRate: 5.000e-01, Time taken : 0.975s\n",
      "\tEpoch 0, Step 0400, MSE: 1.024e+14,  LearnRate: 5.000e-01, Time taken : 0.970s\n",
      "\tEpoch 0, Step 0500, MSE: 9.581e+13,  LearnRate: 5.000e-01, Time taken : 0.912s\n",
      "\tEpoch 0, Step 0600, MSE: 8.849e+13,  LearnRate: 5.000e-01, Time taken : 1.087s\n",
      "\tEpoch 0, Step 0700, MSE: 8.057e+13,  LearnRate: 5.000e-01, Time taken : 1.058s\n",
      "\tEpoch 0, Step 0800, MSE: 7.246e+13,  LearnRate: 5.000e-01, Time taken : 1.090s\n",
      "\tEpoch 0, Step 0900, MSE: 6.418e+13,  LearnRate: 5.000e-01, Time taken : 0.993s\n",
      "\tEpoch 0, Step 1000, MSE: 5.589e+13,  LearnRate: 5.000e-01, Time taken : 0.961s\n",
      "\tEpoch 0, Step 1100, MSE: 4.868e+13,  LearnRate: 5.000e-01, Time taken : 1.095s\n",
      "\tEpoch 0, Step 1200, MSE: 4.106e+13,  LearnRate: 5.000e-01, Time taken : 1.061s\n",
      "\tEpoch 0, Step 1300, MSE: 3.326e+13,  LearnRate: 5.000e-01, Time taken : 0.951s\n",
      "\tEpoch 0, Step 1400, MSE: 2.771e+13,  LearnRate: 5.000e-01, Time taken : 0.974s\n",
      "\tEpoch 0, Step 1500, MSE: 2.159e+13,  LearnRate: 5.000e-01, Time taken : 0.931s\n",
      "\tEpoch 0, Step 1600, MSE: 1.653e+13,  LearnRate: 5.000e-01, Time taken : 0.973s\n",
      "\tEpoch 0, Step 1700, MSE: 1.280e+13,  LearnRate: 5.000e-01, Time taken : 1.045s\n",
      "\tEpoch 0, Step 1800, MSE: 9.658e+12,  LearnRate: 5.000e-01, Time taken : 1.101s\n",
      "\tEpoch 0, Step 1900, MSE: 7.918e+12,  LearnRate: 5.000e-01, Time taken : 1.040s\n",
      "\tEpoch 0, Step 2000, MSE: 5.515e+12,  LearnRate: 5.000e-01, Time taken : 0.994s\n",
      "\tEpoch 0, Step 2100, MSE: 3.990e+12,  LearnRate: 5.000e-01, Time taken : 0.999s\n",
      "\tEpoch 0, Step 2200, MSE: 3.470e+12,  LearnRate: 5.000e-01, Time taken : 1.013s\n",
      "\tEpoch 0, Step 2300, MSE: 1.717e+12,  LearnRate: 5.000e-01, Time taken : 1.024s\n",
      "\tEpoch 0, Step 2400, MSE: 1.258e+12,  LearnRate: 5.000e-01, Time taken : 1.032s\n",
      "\tEpoch 0, Step 2500, MSE: 7.230e+11,  LearnRate: 5.000e-01, Time taken : 1.029s\n",
      "\tEpoch 0, Step 2600, MSE: 9.350e+11,  LearnRate: 5.000e-01, Time taken : 1.011s\n",
      "\tEpoch 0, Step 2700, MSE: 4.518e+11,  LearnRate: 5.000e-01, Time taken : 1.006s\n",
      "\tEpoch 0, Step 2800, MSE: 6.353e+11,  LearnRate: 5.000e-01, Time taken : 1.007s\n",
      "\tEpoch 0, Step 2900, MSE: 2.577e+11,  LearnRate: 5.000e-01, Time taken : 0.983s\n",
      "Starting Epoch 1, with 2909 batches\n",
      "\tEpoch 1, Step 0000, MSE: 3.515e+11,  LearnRate: 5.000e-01, Time taken : 0.277s\n",
      "\tEpoch 1, Step 0100, MSE: 1.804e+11,  LearnRate: 5.000e-01, Time taken : 0.924s\n",
      "\tEpoch 1, Step 0200, MSE: 2.235e+11,  LearnRate: 5.000e-01, Time taken : 0.993s\n",
      "\tEpoch 1, Step 0300, MSE: 1.508e+11,  LearnRate: 5.000e-01, Time taken : 0.984s\n",
      "\tEpoch 1, Step 0400, MSE: 1.486e+11,  LearnRate: 5.000e-01, Time taken : 0.872s\n",
      "\tEpoch 1, Step 0500, MSE: 6.756e+10,  LearnRate: 5.000e-01, Time taken : 0.904s\n",
      "\tEpoch 1, Step 0600, MSE: 1.873e+11,  LearnRate: 5.000e-01, Time taken : 1.042s\n",
      "\tEpoch 1, Step 0700, MSE: 1.126e+11,  LearnRate: 5.000e-01, Time taken : 0.983s\n",
      "\tEpoch 1, Step 0800, MSE: 4.699e+11,  LearnRate: 5.000e-01, Time taken : 0.992s\n",
      "\tEpoch 1, Step 0900, MSE: 9.356e+11,  LearnRate: 5.000e-01, Time taken : 1.063s\n",
      "\tEpoch 1, Step 1000, MSE: 1.321e+11,  LearnRate: 5.000e-01, Time taken : 1.066s\n",
      "\tEpoch 1, Step 1100, MSE: 6.825e+10,  LearnRate: 5.000e-01, Time taken : 0.892s\n",
      "\tEpoch 1, Step 1200, MSE: 4.770e+10,  LearnRate: 5.000e-01, Time taken : 0.923s\n",
      "\tEpoch 1, Step 1300, MSE: 1.538e+11,  LearnRate: 5.000e-01, Time taken : 1.007s\n",
      "\tEpoch 1, Step 1400, MSE: 4.419e+10,  LearnRate: 5.000e-01, Time taken : 0.920s\n",
      "\tEpoch 1, Step 1500, MSE: 5.743e+10,  LearnRate: 5.000e-01, Time taken : 0.994s\n",
      "\tEpoch 1, Step 1600, MSE: 4.034e+10,  LearnRate: 5.000e-01, Time taken : 1.031s\n",
      "\tEpoch 1, Step 1700, MSE: 3.941e+10,  LearnRate: 5.000e-01, Time taken : 0.935s\n",
      "\tEpoch 1, Step 1800, MSE: 1.260e+11,  LearnRate: 5.000e-01, Time taken : 1.042s\n",
      "\tEpoch 1, Step 1900, MSE: 4.459e+10,  LearnRate: 5.000e-01, Time taken : 0.915s\n",
      "\tEpoch 1, Step 2000, MSE: 4.319e+10,  LearnRate: 5.000e-01, Time taken : 0.928s\n",
      "\tEpoch 1, Step 2100, MSE: 4.233e+10,  LearnRate: 5.000e-01, Time taken : 1.078s\n",
      "\tEpoch 1, Step 2200, MSE: 3.622e+10,  LearnRate: 5.000e-01, Time taken : 0.917s\n",
      "\tEpoch 1, Step 2300, MSE: 2.954e+10,  LearnRate: 5.000e-01, Time taken : 1.001s\n",
      "\tEpoch 1, Step 2400, MSE: 3.514e+10,  LearnRate: 5.000e-01, Time taken : 1.022s\n",
      "\tEpoch 1, Step 2500, MSE: 2.188e+10,  LearnRate: 5.000e-01, Time taken : 1.080s\n",
      "\tEpoch 1, Step 2600, MSE: 1.891e+10,  LearnRate: 5.000e-01, Time taken : 0.928s\n",
      "\tEpoch 1, Step 2700, MSE: 2.584e+10,  LearnRate: 5.000e-01, Time taken : 0.935s\n",
      "\tEpoch 1, Step 2800, MSE: 1.993e+10,  LearnRate: 5.000e-01, Time taken : 1.044s\n",
      "\tEpoch 1, Step 2900, MSE: 2.772e+10,  LearnRate: 5.000e-01, Time taken : 1.010s\n",
      "Starting Epoch 2, with 2909 batches\n",
      "\tEpoch 2, Step 0000, MSE: 2.633e+10,  LearnRate: 5.000e-01, Time taken : 0.277s\n",
      "\tEpoch 2, Step 0100, MSE: 3.020e+10,  LearnRate: 5.000e-01, Time taken : 0.954s\n",
      "\tEpoch 2, Step 0200, MSE: 4.157e+10,  LearnRate: 5.000e-01, Time taken : 0.908s\n",
      "\tEpoch 2, Step 0300, MSE: 3.531e+10,  LearnRate: 5.000e-01, Time taken : 1.046s\n",
      "\tEpoch 2, Step 0400, MSE: 1.676e+10,  LearnRate: 5.000e-01, Time taken : 0.954s\n",
      "\tEpoch 2, Step 0500, MSE: 1.973e+10,  LearnRate: 5.000e-01, Time taken : 0.951s\n",
      "\tEpoch 2, Step 0600, MSE: 3.597e+10,  LearnRate: 5.000e-01, Time taken : 1.022s\n",
      "\tEpoch 2, Step 0700, MSE: 2.873e+10,  LearnRate: 5.000e-01, Time taken : 0.993s\n",
      "\tEpoch 2, Step 0800, MSE: 1.604e+10,  LearnRate: 5.000e-01, Time taken : 1.049s\n",
      "\tEpoch 2, Step 0900, MSE: 2.001e+10,  LearnRate: 5.000e-01, Time taken : 1.073s\n",
      "\tEpoch 2, Step 1000, MSE: 2.048e+10,  LearnRate: 5.000e-01, Time taken : 1.018s\n",
      "\tEpoch 2, Step 1100, MSE: 1.416e+10,  LearnRate: 5.000e-01, Time taken : 1.055s\n",
      "\tEpoch 2, Step 1200, MSE: 1.658e+10,  LearnRate: 5.000e-01, Time taken : 0.973s\n",
      "\tEpoch 2, Step 1300, MSE: 1.351e+10,  LearnRate: 5.000e-01, Time taken : 0.879s\n",
      "\tEpoch 2, Step 1400, MSE: 2.675e+10,  LearnRate: 5.000e-01, Time taken : 1.067s\n",
      "\tEpoch 2, Step 1500, MSE: 1.525e+10,  LearnRate: 5.000e-01, Time taken : 0.924s\n",
      "\tEpoch 2, Step 1600, MSE: 1.472e+10,  LearnRate: 5.000e-01, Time taken : 0.983s\n",
      "\tEpoch 2, Step 1700, MSE: 2.304e+10,  LearnRate: 5.000e-01, Time taken : 0.899s\n",
      "\tEpoch 2, Step 1800, MSE: 1.583e+10,  LearnRate: 5.000e-01, Time taken : 0.955s\n",
      "\tEpoch 2, Step 1900, MSE: 1.674e+10,  LearnRate: 5.000e-01, Time taken : 0.905s\n",
      "\tEpoch 2, Step 2000, MSE: 6.994e+10,  LearnRate: 5.000e-01, Time taken : 0.999s\n",
      "\tEpoch 2, Step 2100, MSE: 2.515e+10,  LearnRate: 5.000e-01, Time taken : 0.998s\n",
      "\tEpoch 2, Step 2200, MSE: 1.801e+10,  LearnRate: 5.000e-01, Time taken : 1.015s\n",
      "\tEpoch 2, Step 2300, MSE: 2.058e+10,  LearnRate: 5.000e-01, Time taken : 0.951s\n",
      "\tEpoch 2, Step 2400, MSE: 1.992e+10,  LearnRate: 5.000e-01, Time taken : 1.056s\n",
      "\tEpoch 2, Step 2500, MSE: 1.532e+10,  LearnRate: 5.000e-01, Time taken : 0.934s\n",
      "\tEpoch 2, Step 2600, MSE: 1.661e+10,  LearnRate: 5.000e-01, Time taken : 1.031s\n",
      "\tEpoch 2, Step 2700, MSE: 1.358e+10,  LearnRate: 5.000e-01, Time taken : 1.050s\n",
      "\tEpoch 2, Step 2800, MSE: 1.543e+10,  LearnRate: 5.000e-01, Time taken : 0.913s\n",
      "\tEpoch 2, Step 2900, MSE: 1.229e+10,  LearnRate: 5.000e-01, Time taken : 0.955s\n",
      "Starting Epoch 3, with 2909 batches\n",
      "\tEpoch 3, Step 0000, MSE: 1.042e+10,  LearnRate: 5.000e-01, Time taken : 0.272s\n",
      "\tEpoch 3, Step 0100, MSE: 1.380e+10,  LearnRate: 5.000e-01, Time taken : 0.940s\n",
      "\tEpoch 3, Step 0200, MSE: 1.080e+10,  LearnRate: 5.000e-01, Time taken : 0.960s\n",
      "\tEpoch 3, Step 0300, MSE: 1.512e+10,  LearnRate: 5.000e-01, Time taken : 1.070s\n",
      "\tEpoch 3, Step 0400, MSE: 1.378e+10,  LearnRate: 5.000e-01, Time taken : 0.993s\n",
      "\tEpoch 3, Step 0500, MSE: 2.305e+10,  LearnRate: 5.000e-01, Time taken : 0.960s\n",
      "\tEpoch 3, Step 0600, MSE: 1.637e+10,  LearnRate: 5.000e-01, Time taken : 0.906s\n",
      "\tEpoch 3, Step 0700, MSE: 1.068e+10,  LearnRate: 5.000e-01, Time taken : 0.902s\n",
      "\tEpoch 3, Step 0800, MSE: 1.788e+10,  LearnRate: 5.000e-01, Time taken : 0.975s\n",
      "\tEpoch 3, Step 0900, MSE: 1.061e+10,  LearnRate: 5.000e-01, Time taken : 1.030s\n",
      "\tEpoch 3, Step 1000, MSE: 7.618e+09,  LearnRate: 5.000e-01, Time taken : 1.009s\n",
      "\tEpoch 3, Step 1100, MSE: 1.095e+10,  LearnRate: 5.000e-01, Time taken : 0.926s\n",
      "\tEpoch 3, Step 1200, MSE: 9.427e+09,  LearnRate: 5.000e-01, Time taken : 0.889s\n",
      "\tEpoch 3, Step 1300, MSE: 6.824e+09,  LearnRate: 5.000e-01, Time taken : 0.972s\n",
      "\tEpoch 3, Step 1400, MSE: 7.645e+09,  LearnRate: 5.000e-01, Time taken : 0.995s\n",
      "\tEpoch 3, Step 1500, MSE: 6.820e+09,  LearnRate: 5.000e-01, Time taken : 0.960s\n",
      "\tEpoch 3, Step 1600, MSE: 5.749e+09,  LearnRate: 5.000e-01, Time taken : 0.997s\n",
      "\tEpoch 3, Step 1700, MSE: 1.594e+10,  LearnRate: 5.000e-01, Time taken : 1.025s\n",
      "\tEpoch 3, Step 1800, MSE: 7.377e+09,  LearnRate: 5.000e-01, Time taken : 1.136s\n",
      "\tEpoch 3, Step 1900, MSE: 7.371e+09,  LearnRate: 5.000e-01, Time taken : 1.003s\n",
      "\tEpoch 3, Step 2000, MSE: 1.474e+10,  LearnRate: 5.000e-01, Time taken : 1.146s\n",
      "\tEpoch 3, Step 2100, MSE: 4.084e+09,  LearnRate: 5.000e-01, Time taken : 0.991s\n",
      "\tEpoch 3, Step 2200, MSE: 2.823e+09,  LearnRate: 5.000e-01, Time taken : 0.967s\n",
      "\tEpoch 3, Step 2300, MSE: 3.134e+09,  LearnRate: 5.000e-01, Time taken : 1.130s\n",
      "\tEpoch 3, Step 2400, MSE: 2.860e+09,  LearnRate: 5.000e-01, Time taken : 1.035s\n",
      "\tEpoch 3, Step 2500, MSE: 2.841e+09,  LearnRate: 5.000e-01, Time taken : 1.022s\n",
      "\tEpoch 3, Step 2600, MSE: 2.139e+09,  LearnRate: 5.000e-01, Time taken : 0.999s\n",
      "\tEpoch 3, Step 2700, MSE: 1.770e+09,  LearnRate: 5.000e-01, Time taken : 0.907s\n",
      "\tEpoch 3, Step 2800, MSE: 2.094e+09,  LearnRate: 5.000e-01, Time taken : 0.943s\n",
      "\tEpoch 3, Step 2900, MSE: 1.225e+09,  LearnRate: 5.000e-01, Time taken : 0.969s\n",
      "Starting Epoch 4, with 2909 batches\n",
      "\tEpoch 4, Step 0000, MSE: 8.199e+08,  LearnRate: 5.000e-01, Time taken : 0.339s\n",
      "\tEpoch 4, Step 0100, MSE: 2.125e+09,  LearnRate: 5.000e-01, Time taken : 1.084s\n",
      "\tEpoch 4, Step 0200, MSE: 2.305e+09,  LearnRate: 5.000e-01, Time taken : 1.123s\n",
      "\tEpoch 4, Step 0300, MSE: 7.618e+08,  LearnRate: 5.000e-01, Time taken : 1.107s\n",
      "\tEpoch 4, Step 0400, MSE: 5.311e+08,  LearnRate: 5.000e-01, Time taken : 1.037s\n",
      "\tEpoch 4, Step 0500, MSE: 2.235e+09,  LearnRate: 5.000e-01, Time taken : 0.925s\n",
      "\tEpoch 4, Step 0600, MSE: 5.205e+08,  LearnRate: 5.000e-01, Time taken : 1.011s\n",
      "\tEpoch 4, Step 0700, MSE: 3.400e+08,  LearnRate: 5.000e-01, Time taken : 0.947s\n",
      "\tEpoch 4, Step 0800, MSE: 2.483e+08,  LearnRate: 5.000e-01, Time taken : 0.943s\n",
      "\tEpoch 4, Step 0900, MSE: 3.372e+08,  LearnRate: 5.000e-01, Time taken : 1.031s\n",
      "\tEpoch 4, Step 1000, MSE: 1.993e+08,  LearnRate: 5.000e-01, Time taken : 0.963s\n",
      "\tEpoch 4, Step 1100, MSE: 1.456e+09,  LearnRate: 5.000e-01, Time taken : 1.035s\n",
      "\tEpoch 4, Step 1200, MSE: 1.646e+08,  LearnRate: 5.000e-01, Time taken : 0.986s\n",
      "\tEpoch 4, Step 1300, MSE: 3.396e+08,  LearnRate: 5.000e-01, Time taken : 0.996s\n",
      "\tEpoch 4, Step 1400, MSE: 2.803e+08,  LearnRate: 5.000e-01, Time taken : 1.013s\n",
      "\tEpoch 4, Step 1500, MSE: 2.038e+07,  LearnRate: 5.000e-01, Time taken : 0.917s\n",
      "\tEpoch 4, Step 1600, MSE: 2.784e+08,  LearnRate: 5.000e-01, Time taken : 0.940s\n",
      "\tEpoch 4, Step 1700, MSE: 4.687e+07,  LearnRate: 5.000e-01, Time taken : 0.967s\n",
      "\tEpoch 4, Step 1800, MSE: 3.436e+06,  LearnRate: 5.000e-01, Time taken : 1.030s\n",
      "\tEpoch 4, Step 1900, MSE: 2.361e+05,  LearnRate: 5.000e-01, Time taken : 0.938s\n",
      "\tEpoch 4, Step 2000, MSE: 2.265e+05,  LearnRate: 5.000e-01, Time taken : 1.082s\n",
      "\tEpoch 4, Step 2100, MSE: 8.484e+05,  LearnRate: 5.000e-01, Time taken : 1.041s\n",
      "\tEpoch 4, Step 2200, MSE: 3.358e+06,  LearnRate: 5.000e-01, Time taken : 1.015s\n",
      "\tEpoch 4, Step 2300, MSE: 1.582e+06,  LearnRate: 5.000e-01, Time taken : 1.122s\n",
      "\tEpoch 4, Step 2400, MSE: 3.912e+05,  LearnRate: 5.000e-01, Time taken : 1.139s\n",
      "\tEpoch 4, Step 2500, MSE: 3.495e+06,  LearnRate: 5.000e-01, Time taken : 1.048s\n",
      "\tEpoch 4, Step 2600, MSE: 2.329e+04,  LearnRate: 5.000e-01, Time taken : 1.007s\n",
      "\tEpoch 4, Step 2700, MSE: 2.701e+04,  LearnRate: 5.000e-01, Time taken : 0.989s\n",
      "\tEpoch 4, Step 2800, MSE: 2.243e+05,  LearnRate: 5.000e-01, Time taken : 0.935s\n",
      "\tEpoch 4, Step 2900, MSE: 3.409e+06,  LearnRate: 5.000e-01, Time taken : 0.929s\n",
      "Starting Epoch 5, with 2909 batches\n",
      "\tEpoch 5, Step 0000, MSE: 9.148e+06,  LearnRate: 5.000e-01, Time taken : 0.331s\n",
      "\tEpoch 5, Step 0100, MSE: 2.696e+06,  LearnRate: 5.000e-01, Time taken : 0.928s\n",
      "\tEpoch 5, Step 0200, MSE: 6.347e+06,  LearnRate: 5.000e-01, Time taken : 0.958s\n",
      "\tEpoch 5, Step 0300, MSE: 6.934e+04,  LearnRate: 5.000e-01, Time taken : 0.955s\n",
      "\tEpoch 5, Step 0400, MSE: 3.116e+05,  LearnRate: 5.000e-01, Time taken : 1.016s\n",
      "\tEpoch 5, Step 0500, MSE: 8.609e+05,  LearnRate: 5.000e-01, Time taken : 1.041s\n",
      "\tEpoch 5, Step 0600, MSE: 1.988e+06,  LearnRate: 5.000e-01, Time taken : 1.258s\n",
      "\tEpoch 5, Step 0700, MSE: 6.006e+05,  LearnRate: 5.000e-01, Time taken : 1.114s\n",
      "\tEpoch 5, Step 0800, MSE: 1.559e+07,  LearnRate: 5.000e-01, Time taken : 1.203s\n",
      "\tEpoch 5, Step 0900, MSE: 2.638e+03,  LearnRate: 5.000e-01, Time taken : 1.132s\n",
      "\tEpoch 5, Step 1000, MSE: 2.453e+02,  LearnRate: 5.000e-01, Time taken : 1.085s\n",
      "\tEpoch 5, Step 1100, MSE: 1.056e+07,  LearnRate: 5.000e-01, Time taken : 0.930s\n",
      "\tEpoch 5, Step 1200, MSE: 1.772e+04,  LearnRate: 5.000e-01, Time taken : 0.940s\n",
      "\tEpoch 5, Step 1300, MSE: 6.293e+04,  LearnRate: 5.000e-01, Time taken : 1.055s\n",
      "\tEpoch 5, Step 1400, MSE: 1.857e+07,  LearnRate: 5.000e-01, Time taken : 0.985s\n",
      "\tEpoch 5, Step 1500, MSE: 4.541e+05,  LearnRate: 5.000e-01, Time taken : 1.030s\n",
      "\tEpoch 5, Step 1600, MSE: 1.327e+06,  LearnRate: 5.000e-01, Time taken : 0.981s\n",
      "\tEpoch 5, Step 1700, MSE: 3.208e+02,  LearnRate: 5.000e-01, Time taken : 0.947s\n",
      "\tEpoch 5, Step 1800, MSE: 1.270e+01,  LearnRate: 5.000e-01, Time taken : 0.967s\n",
      "\tEpoch 5, Step 1900, MSE: 7.872e+05,  LearnRate: 5.000e-01, Time taken : 1.035s\n",
      "\tEpoch 5, Step 2000, MSE: 6.270e+00,  LearnRate: 5.000e-01, Time taken : 0.966s\n",
      "\tEpoch 5, Step 2100, MSE: 2.093e+00,  LearnRate: 5.000e-01, Time taken : 0.914s\n",
      "\tEpoch 5, Step 2200, MSE: 4.158e+06,  LearnRate: 5.000e-01, Time taken : 0.919s\n",
      "\tEpoch 5, Step 2300, MSE: 3.799e+04,  LearnRate: 5.000e-01, Time taken : 0.984s\n",
      "\tEpoch 5, Step 2400, MSE: 2.932e+01,  LearnRate: 5.000e-01, Time taken : 1.019s\n",
      "\tEpoch 5, Step 2500, MSE: 2.058e+03,  LearnRate: 5.000e-01, Time taken : 1.010s\n",
      "\tEpoch 5, Step 2600, MSE: 2.546e+06,  LearnRate: 5.000e-01, Time taken : 0.888s\n",
      "\tEpoch 5, Step 2700, MSE: 1.469e+02,  LearnRate: 5.000e-01, Time taken : 0.958s\n",
      "\tEpoch 5, Step 2800, MSE: 4.439e+00,  LearnRate: 5.000e-01, Time taken : 1.031s\n",
      "\tEpoch 5, Step 2900, MSE: 1.850e+03,  LearnRate: 5.000e-01, Time taken : 0.948s\n",
      "Starting Epoch 6, with 2909 batches\n",
      "\tEpoch 6, Step 0000, MSE: 4.451e+02,  LearnRate: 5.000e-01, Time taken : 0.256s\n",
      "\tEpoch 6, Step 0100, MSE: 1.113e+01,  LearnRate: 5.000e-01, Time taken : 0.950s\n",
      "\tEpoch 6, Step 0200, MSE: 2.821e+00,  LearnRate: 5.000e-01, Time taken : 0.944s\n",
      "\tEpoch 6, Step 0300, MSE: 3.724e+00,  LearnRate: 5.000e-01, Time taken : 1.080s\n",
      "\tEpoch 6, Step 0400, MSE: 1.166e+01,  LearnRate: 5.000e-01, Time taken : 0.985s\n",
      "\tEpoch 6, Step 0500, MSE: 2.101e+00,  LearnRate: 5.000e-01, Time taken : 1.017s\n",
      "\tEpoch 6, Step 0600, MSE: 8.507e+01,  LearnRate: 5.000e-01, Time taken : 0.943s\n",
      "\tEpoch 6, Step 0700, MSE: 1.439e+01,  LearnRate: 5.000e-01, Time taken : 0.949s\n",
      "\tEpoch 6, Step 0800, MSE: 8.277e+00,  LearnRate: 5.000e-01, Time taken : 0.946s\n",
      "\tEpoch 6, Step 0900, MSE: 4.736e+00,  LearnRate: 5.000e-01, Time taken : 0.916s\n",
      "\tEpoch 6, Step 1000, MSE: 2.170e+03,  LearnRate: 5.000e-01, Time taken : 1.006s\n",
      "\tEpoch 6, Step 1100, MSE: 5.777e+04,  LearnRate: 5.000e-01, Time taken : 1.013s\n",
      "\tEpoch 6, Step 1200, MSE: 8.716e+01,  LearnRate: 5.000e-01, Time taken : 0.947s\n",
      "\tEpoch 6, Step 1300, MSE: 6.096e+00,  LearnRate: 5.000e-01, Time taken : 0.991s\n",
      "\tEpoch 6, Step 1400, MSE: 4.572e+01,  LearnRate: 5.000e-01, Time taken : 0.963s\n",
      "\tEpoch 6, Step 1500, MSE: 2.665e+00,  LearnRate: 5.000e-01, Time taken : 1.002s\n",
      "\tEpoch 6, Step 1600, MSE: 1.445e+01,  LearnRate: 5.000e-01, Time taken : 0.949s\n",
      "\tEpoch 6, Step 1700, MSE: 8.510e+04,  LearnRate: 5.000e-01, Time taken : 0.926s\n",
      "\tEpoch 6, Step 1800, MSE: 4.479e+03,  LearnRate: 5.000e-01, Time taken : 1.001s\n",
      "\tEpoch 6, Step 1900, MSE: 2.920e+01,  LearnRate: 5.000e-01, Time taken : 0.958s\n",
      "\tEpoch 6, Step 2000, MSE: 1.884e+02,  LearnRate: 5.000e-01, Time taken : 1.009s\n",
      "\tEpoch 6, Step 2100, MSE: 1.300e+04,  LearnRate: 5.000e-01, Time taken : 1.035s\n",
      "\tEpoch 6, Step 2200, MSE: 4.941e+01,  LearnRate: 5.000e-01, Time taken : 1.061s\n",
      "\tEpoch 6, Step 2300, MSE: 4.102e+01,  LearnRate: 5.000e-01, Time taken : 0.952s\n",
      "\tEpoch 6, Step 2400, MSE: 4.138e+00,  LearnRate: 5.000e-01, Time taken : 0.971s\n",
      "\tEpoch 6, Step 2500, MSE: 1.263e+05,  LearnRate: 5.000e-01, Time taken : 1.039s\n",
      "\tEpoch 6, Step 2600, MSE: 1.148e+02,  LearnRate: 5.000e-01, Time taken : 0.927s\n",
      "\tEpoch 6, Step 2700, MSE: 1.748e+01,  LearnRate: 5.000e-01, Time taken : 0.898s\n",
      "\tEpoch 6, Step 2800, MSE: 6.637e+00,  LearnRate: 5.000e-01, Time taken : 0.937s\n",
      "\tEpoch 6, Step 2900, MSE: 5.323e+00,  LearnRate: 5.000e-01, Time taken : 0.949s\n",
      "Starting Epoch 7, with 2909 batches\n",
      "\tEpoch 7, Step 0000, MSE: 2.482e+07,  LearnRate: 5.000e-01, Time taken : 0.302s\n",
      "\tEpoch 7, Step 0100, MSE: 4.466e+05,  LearnRate: 5.000e-01, Time taken : 0.910s\n",
      "\tEpoch 7, Step 0200, MSE: 2.460e+03,  LearnRate: 5.000e-01, Time taken : 0.986s\n",
      "\tEpoch 7, Step 0300, MSE: 4.825e+07,  LearnRate: 5.000e-01, Time taken : 0.906s\n",
      "\tEpoch 7, Step 0400, MSE: 2.985e+03,  LearnRate: 5.000e-01, Time taken : 0.988s\n",
      "\tEpoch 7, Step 0500, MSE: 7.870e+00,  LearnRate: 5.000e-01, Time taken : 0.978s\n",
      "\tEpoch 7, Step 0600, MSE: 1.628e+01,  LearnRate: 5.000e-01, Time taken : 0.977s\n",
      "\tEpoch 7, Step 0700, MSE: 4.235e+00,  LearnRate: 5.000e-01, Time taken : 0.886s\n",
      "\tEpoch 7, Step 0800, MSE: 1.907e+04,  LearnRate: 5.000e-01, Time taken : 0.888s\n",
      "\tEpoch 7, Step 0900, MSE: 8.056e+01,  LearnRate: 5.000e-01, Time taken : 1.094s\n",
      "\tEpoch 7, Step 1000, MSE: 2.275e+01,  LearnRate: 5.000e-01, Time taken : 0.933s\n",
      "\tEpoch 7, Step 1100, MSE: 3.397e+00,  LearnRate: 5.000e-01, Time taken : 0.921s\n",
      "\tEpoch 7, Step 1200, MSE: 5.652e+00,  LearnRate: 5.000e-01, Time taken : 0.971s\n",
      "\tEpoch 7, Step 1300, MSE: 2.612e+01,  LearnRate: 5.000e-01, Time taken : 0.987s\n",
      "\tEpoch 7, Step 1400, MSE: 6.064e+01,  LearnRate: 5.000e-01, Time taken : 0.995s\n",
      "\tEpoch 7, Step 1500, MSE: 1.548e+01,  LearnRate: 5.000e-01, Time taken : 1.025s\n",
      "\tEpoch 7, Step 1600, MSE: 1.647e+03,  LearnRate: 5.000e-01, Time taken : 0.968s\n",
      "\tEpoch 7, Step 1700, MSE: 8.645e+03,  LearnRate: 5.000e-01, Time taken : 1.017s\n",
      "\tEpoch 7, Step 1800, MSE: 3.634e+02,  LearnRate: 5.000e-01, Time taken : 0.965s\n",
      "\tEpoch 7, Step 1900, MSE: 4.554e+03,  LearnRate: 5.000e-01, Time taken : 1.060s\n",
      "\tEpoch 7, Step 2000, MSE: 4.904e+04,  LearnRate: 5.000e-01, Time taken : 0.958s\n",
      "\tEpoch 7, Step 2100, MSE: 1.116e+07,  LearnRate: 5.000e-01, Time taken : 0.946s\n",
      "\tEpoch 7, Step 2200, MSE: 1.462e+03,  LearnRate: 5.000e-01, Time taken : 0.886s\n",
      "\tEpoch 7, Step 2300, MSE: 5.447e+03,  LearnRate: 5.000e-01, Time taken : 0.952s\n",
      "\tEpoch 7, Step 2400, MSE: 1.818e+03,  LearnRate: 5.000e-01, Time taken : 0.987s\n",
      "\tEpoch 7, Step 2500, MSE: 3.793e+00,  LearnRate: 5.000e-01, Time taken : 0.926s\n",
      "\tEpoch 7, Step 2600, MSE: 3.689e+00,  LearnRate: 5.000e-01, Time taken : 0.932s\n",
      "\tEpoch 7, Step 2700, MSE: 6.555e+00,  LearnRate: 5.000e-01, Time taken : 1.043s\n",
      "\tEpoch 7, Step 2800, MSE: 3.593e+03,  LearnRate: 5.000e-01, Time taken : 1.021s\n",
      "\tEpoch 7, Step 2900, MSE: 3.964e+01,  LearnRate: 5.000e-01, Time taken : 0.994s\n",
      "Starting Epoch 8, with 2909 batches\n",
      "\tEpoch 8, Step 0000, MSE: 9.515e+01,  LearnRate: 5.000e-01, Time taken : 0.258s\n",
      "\tEpoch 8, Step 0100, MSE: 1.305e+01,  LearnRate: 5.000e-01, Time taken : 1.258s\n",
      "\tEpoch 8, Step 0200, MSE: 2.299e+02,  LearnRate: 5.000e-01, Time taken : 1.217s\n",
      "\tEpoch 8, Step 0300, MSE: 1.300e+02,  LearnRate: 5.000e-01, Time taken : 1.132s\n",
      "\tEpoch 8, Step 0400, MSE: 3.538e+00,  LearnRate: 5.000e-01, Time taken : 1.307s\n",
      "\tEpoch 8, Step 0500, MSE: 4.021e+01,  LearnRate: 5.000e-01, Time taken : 1.190s\n",
      "\tEpoch 8, Step 0600, MSE: 2.934e+01,  LearnRate: 5.000e-01, Time taken : 0.989s\n",
      "\tEpoch 8, Step 0700, MSE: 3.154e+00,  LearnRate: 5.000e-01, Time taken : 0.993s\n",
      "\tEpoch 8, Step 0800, MSE: 4.261e+00,  LearnRate: 5.000e-01, Time taken : 0.929s\n",
      "\tEpoch 8, Step 0900, MSE: 1.859e+03,  LearnRate: 5.000e-01, Time taken : 0.885s\n",
      "\tEpoch 8, Step 1000, MSE: 2.011e+02,  LearnRate: 5.000e-01, Time taken : 0.980s\n",
      "\tEpoch 8, Step 1100, MSE: 1.268e+01,  LearnRate: 5.000e-01, Time taken : 0.978s\n",
      "\tEpoch 8, Step 1200, MSE: 1.623e+06,  LearnRate: 5.000e-01, Time taken : 0.898s\n",
      "\tEpoch 8, Step 1300, MSE: 6.631e+04,  LearnRate: 5.000e-01, Time taken : 0.906s\n",
      "\tEpoch 8, Step 1400, MSE: 1.464e+01,  LearnRate: 5.000e-01, Time taken : 0.912s\n",
      "\tEpoch 8, Step 1500, MSE: 9.251e+05,  LearnRate: 5.000e-01, Time taken : 0.936s\n",
      "\tEpoch 8, Step 1600, MSE: 2.890e+01,  LearnRate: 5.000e-01, Time taken : 0.967s\n",
      "\tEpoch 8, Step 1700, MSE: 1.452e+05,  LearnRate: 5.000e-01, Time taken : 0.925s\n",
      "\tEpoch 8, Step 1800, MSE: 3.286e+01,  LearnRate: 5.000e-01, Time taken : 0.957s\n",
      "\tEpoch 8, Step 1900, MSE: 4.394e+01,  LearnRate: 5.000e-01, Time taken : 1.031s\n",
      "\tEpoch 8, Step 2000, MSE: 5.513e+01,  LearnRate: 5.000e-01, Time taken : 0.885s\n",
      "\tEpoch 8, Step 2100, MSE: 6.551e+01,  LearnRate: 5.000e-01, Time taken : 0.926s\n",
      "\tEpoch 8, Step 2200, MSE: 7.110e+01,  LearnRate: 5.000e-01, Time taken : 0.952s\n",
      "\tEpoch 8, Step 2300, MSE: 6.525e+01,  LearnRate: 5.000e-01, Time taken : 0.949s\n",
      "\tEpoch 8, Step 2400, MSE: 6.829e+01,  LearnRate: 5.000e-01, Time taken : 1.015s\n",
      "\tEpoch 8, Step 2500, MSE: 7.366e+01,  LearnRate: 5.000e-01, Time taken : 0.995s\n",
      "\tEpoch 8, Step 2600, MSE: 8.194e+01,  LearnRate: 5.000e-01, Time taken : 0.941s\n",
      "\tEpoch 8, Step 2700, MSE: 8.517e+01,  LearnRate: 5.000e-01, Time taken : 0.993s\n",
      "\tEpoch 8, Step 2800, MSE: 8.464e+01,  LearnRate: 5.000e-01, Time taken : 1.020s\n",
      "\tEpoch 8, Step 2900, MSE: 8.200e+01,  LearnRate: 5.000e-01, Time taken : 0.919s\n",
      "Starting Epoch 9, with 2909 batches\n",
      "\tEpoch 9, Step 0000, MSE: 8.364e+01,  LearnRate: 5.000e-01, Time taken : 0.274s\n",
      "\tEpoch 9, Step 0100, MSE: 8.460e+01,  LearnRate: 5.000e-01, Time taken : 1.001s\n",
      "\tEpoch 9, Step 0200, MSE: 8.271e+01,  LearnRate: 5.000e-01, Time taken : 0.933s\n",
      "\tEpoch 9, Step 0300, MSE: 8.019e+01,  LearnRate: 5.000e-01, Time taken : 0.915s\n",
      "\tEpoch 9, Step 0400, MSE: 1.407e+06,  LearnRate: 5.000e-01, Time taken : 0.929s\n",
      "\tEpoch 9, Step 0500, MSE: 5.554e+01,  LearnRate: 5.000e-01, Time taken : 0.873s\n",
      "\tEpoch 9, Step 0600, MSE: 5.301e+01,  LearnRate: 5.000e-01, Time taken : 0.945s\n",
      "\tEpoch 9, Step 0700, MSE: 7.110e+01,  LearnRate: 5.000e-01, Time taken : 0.895s\n",
      "\tEpoch 9, Step 0800, MSE: 7.728e+01,  LearnRate: 5.000e-01, Time taken : 0.981s\n",
      "\tEpoch 9, Step 0900, MSE: 7.844e+01,  LearnRate: 5.000e-01, Time taken : 0.916s\n",
      "\tEpoch 9, Step 1000, MSE: 8.304e+01,  LearnRate: 5.000e-01, Time taken : 0.893s\n",
      "\tEpoch 9, Step 1100, MSE: 8.166e+01,  LearnRate: 5.000e-01, Time taken : 0.954s\n",
      "\tEpoch 9, Step 1200, MSE: 8.221e+01,  LearnRate: 5.000e-01, Time taken : 1.057s\n",
      "\tEpoch 9, Step 1300, MSE: 8.878e+01,  LearnRate: 5.000e-01, Time taken : 0.955s\n",
      "\tEpoch 9, Step 1400, MSE: 8.937e+01,  LearnRate: 5.000e-01, Time taken : 1.023s\n",
      "\tEpoch 9, Step 1500, MSE: 8.615e+01,  LearnRate: 5.000e-01, Time taken : 1.012s\n",
      "\tEpoch 9, Step 1600, MSE: 8.859e+01,  LearnRate: 5.000e-01, Time taken : 0.990s\n",
      "\tEpoch 9, Step 1700, MSE: 8.095e+01,  LearnRate: 5.000e-01, Time taken : 0.967s\n",
      "\tEpoch 9, Step 1800, MSE: 7.974e+01,  LearnRate: 5.000e-01, Time taken : 0.940s\n",
      "\tEpoch 9, Step 1900, MSE: 7.761e+01,  LearnRate: 5.000e-01, Time taken : 0.883s\n",
      "\tEpoch 9, Step 2000, MSE: 8.118e+01,  LearnRate: 5.000e-01, Time taken : 0.975s\n",
      "\tEpoch 9, Step 2100, MSE: 9.063e+01,  LearnRate: 5.000e-01, Time taken : 0.924s\n",
      "\tEpoch 9, Step 2200, MSE: 8.724e+01,  LearnRate: 5.000e-01, Time taken : 0.927s\n",
      "\tEpoch 9, Step 2300, MSE: 8.877e+01,  LearnRate: 5.000e-01, Time taken : 0.961s\n",
      "\tEpoch 9, Step 2400, MSE: 7.714e+01,  LearnRate: 5.000e-01, Time taken : 1.008s\n",
      "\tEpoch 9, Step 2500, MSE: 7.608e+01,  LearnRate: 5.000e-01, Time taken : 0.940s\n",
      "\tEpoch 9, Step 2600, MSE: 6.769e+01,  LearnRate: 5.000e-01, Time taken : 0.914s\n",
      "\tEpoch 9, Step 2700, MSE: 6.856e+01,  LearnRate: 5.000e-01, Time taken : 0.931s\n",
      "\tEpoch 9, Step 2800, MSE: 9.301e+01,  LearnRate: 5.000e-01, Time taken : 0.990s\n",
      "\tEpoch 9, Step 2900, MSE: 1.125e+02,  LearnRate: 5.000e-01, Time taken : 1.027s\n",
      "Starting Epoch 10, with 2909 batches\n",
      "\tEpoch 10, Step 0000, MSE: 7.524e+01,  LearnRate: 2.500e-01, Time taken : 0.254s\n",
      "\tEpoch 10, Step 0100, MSE: 6.206e+01,  LearnRate: 2.500e-01, Time taken : 0.961s\n",
      "\tEpoch 10, Step 0200, MSE: 5.887e+01,  LearnRate: 2.500e-01, Time taken : 0.964s\n",
      "\tEpoch 10, Step 0300, MSE: 8.202e+01,  LearnRate: 2.500e-01, Time taken : 0.952s\n",
      "\tEpoch 10, Step 0400, MSE: 5.262e+01,  LearnRate: 2.500e-01, Time taken : 1.017s\n",
      "\tEpoch 10, Step 0500, MSE: 5.065e+01,  LearnRate: 2.500e-01, Time taken : 0.934s\n",
      "\tEpoch 10, Step 0600, MSE: 1.605e+05,  LearnRate: 2.500e-01, Time taken : 0.954s\n",
      "\tEpoch 10, Step 0700, MSE: 1.027e+02,  LearnRate: 2.500e-01, Time taken : 0.926s\n",
      "\tEpoch 10, Step 0800, MSE: 8.659e+00,  LearnRate: 2.500e-01, Time taken : 0.948s\n",
      "\tEpoch 10, Step 0900, MSE: 1.617e+01,  LearnRate: 2.500e-01, Time taken : 0.908s\n",
      "\tEpoch 10, Step 1000, MSE: 1.311e+01,  LearnRate: 2.500e-01, Time taken : 0.980s\n",
      "\tEpoch 10, Step 1100, MSE: 1.006e+01,  LearnRate: 2.500e-01, Time taken : 1.045s\n",
      "\tEpoch 10, Step 1200, MSE: 1.488e+01,  LearnRate: 2.500e-01, Time taken : 1.093s\n",
      "\tEpoch 10, Step 1300, MSE: 1.459e+01,  LearnRate: 2.500e-01, Time taken : 0.946s\n",
      "\tEpoch 10, Step 1400, MSE: 1.503e+01,  LearnRate: 2.500e-01, Time taken : 1.050s\n",
      "\tEpoch 10, Step 1500, MSE: 1.412e+01,  LearnRate: 2.500e-01, Time taken : 0.970s\n",
      "\tEpoch 10, Step 1600, MSE: 1.806e+01,  LearnRate: 2.500e-01, Time taken : 0.937s\n",
      "\tEpoch 10, Step 1700, MSE: 2.947e+01,  LearnRate: 2.500e-01, Time taken : 0.993s\n",
      "\tEpoch 10, Step 1800, MSE: 2.240e+01,  LearnRate: 2.500e-01, Time taken : 0.987s\n",
      "\tEpoch 10, Step 1900, MSE: 1.889e+01,  LearnRate: 2.500e-01, Time taken : 1.074s\n",
      "\tEpoch 10, Step 2000, MSE: 4.731e+01,  LearnRate: 2.500e-01, Time taken : 0.961s\n",
      "\tEpoch 10, Step 2100, MSE: 1.909e+01,  LearnRate: 2.500e-01, Time taken : 0.998s\n",
      "\tEpoch 10, Step 2200, MSE: 3.132e+01,  LearnRate: 2.500e-01, Time taken : 1.043s\n",
      "\tEpoch 10, Step 2300, MSE: 4.001e+01,  LearnRate: 2.500e-01, Time taken : 1.072s\n",
      "\tEpoch 10, Step 2400, MSE: 2.001e+01,  LearnRate: 2.500e-01, Time taken : 1.174s\n",
      "\tEpoch 10, Step 2500, MSE: 2.273e+01,  LearnRate: 2.500e-01, Time taken : 1.186s\n",
      "\tEpoch 10, Step 2600, MSE: 1.951e+01,  LearnRate: 2.500e-01, Time taken : 1.194s\n",
      "\tEpoch 10, Step 2700, MSE: 4.487e+01,  LearnRate: 2.500e-01, Time taken : 1.120s\n",
      "\tEpoch 10, Step 2800, MSE: 2.492e+04,  LearnRate: 2.500e-01, Time taken : 1.262s\n",
      "\tEpoch 10, Step 2900, MSE: 1.240e+03,  LearnRate: 2.500e-01, Time taken : 1.074s\n",
      "Starting Epoch 11, with 2909 batches\n",
      "\tEpoch 11, Step 0000, MSE: 9.523e+03,  LearnRate: 2.500e-01, Time taken : 0.276s\n",
      "\tEpoch 11, Step 0100, MSE: 5.187e+02,  LearnRate: 2.500e-01, Time taken : 0.947s\n",
      "\tEpoch 11, Step 0200, MSE: 4.747e+01,  LearnRate: 2.500e-01, Time taken : 1.062s\n",
      "\tEpoch 11, Step 0300, MSE: 1.338e+03,  LearnRate: 2.500e-01, Time taken : 0.973s\n",
      "\tEpoch 11, Step 0400, MSE: 9.821e+03,  LearnRate: 2.500e-01, Time taken : 0.921s\n",
      "\tEpoch 11, Step 0500, MSE: 1.616e+03,  LearnRate: 2.500e-01, Time taken : 1.013s\n",
      "\tEpoch 11, Step 0600, MSE: 5.773e+01,  LearnRate: 2.500e-01, Time taken : 0.992s\n",
      "\tEpoch 11, Step 0700, MSE: 4.689e+07,  LearnRate: 2.500e-01, Time taken : 0.996s\n",
      "\tEpoch 11, Step 0800, MSE: 5.642e+05,  LearnRate: 2.500e-01, Time taken : 0.957s\n",
      "\tEpoch 11, Step 0900, MSE: 7.750e+00,  LearnRate: 2.500e-01, Time taken : 0.985s\n",
      "\tEpoch 11, Step 1000, MSE: 1.128e+00,  LearnRate: 2.500e-01, Time taken : 0.949s\n",
      "\tEpoch 11, Step 1100, MSE: 9.070e-01,  LearnRate: 2.500e-01, Time taken : 0.978s\n",
      "\tEpoch 11, Step 1200, MSE: 8.939e-01,  LearnRate: 2.500e-01, Time taken : 1.020s\n",
      "\tEpoch 11, Step 1300, MSE: 2.474e+00,  LearnRate: 2.500e-01, Time taken : 0.967s\n",
      "\tEpoch 11, Step 1400, MSE: 1.406e+00,  LearnRate: 2.500e-01, Time taken : 0.942s\n",
      "\tEpoch 11, Step 1500, MSE: 1.095e+00,  LearnRate: 2.500e-01, Time taken : 0.997s\n",
      "\tEpoch 11, Step 1600, MSE: 3.414e+00,  LearnRate: 2.500e-01, Time taken : 0.929s\n",
      "\tEpoch 11, Step 1700, MSE: 1.259e+00,  LearnRate: 2.500e-01, Time taken : 0.921s\n",
      "\tEpoch 11, Step 1800, MSE: 5.024e+00,  LearnRate: 2.500e-01, Time taken : 1.011s\n",
      "\tEpoch 11, Step 1900, MSE: 6.934e-01,  LearnRate: 2.500e-01, Time taken : 0.941s\n",
      "\tEpoch 11, Step 2000, MSE: 9.754e-01,  LearnRate: 2.500e-01, Time taken : 0.943s\n",
      "\tEpoch 11, Step 2100, MSE: 6.308e+00,  LearnRate: 2.500e-01, Time taken : 0.960s\n",
      "\tEpoch 11, Step 2200, MSE: 5.905e-01,  LearnRate: 2.500e-01, Time taken : 0.940s\n",
      "\tEpoch 11, Step 2300, MSE: 1.109e+00,  LearnRate: 2.500e-01, Time taken : 1.028s\n",
      "\tEpoch 11, Step 2400, MSE: 3.819e+00,  LearnRate: 2.500e-01, Time taken : 0.920s\n",
      "\tEpoch 11, Step 2500, MSE: 8.959e+00,  LearnRate: 2.500e-01, Time taken : 1.002s\n",
      "\tEpoch 11, Step 2600, MSE: 9.347e-01,  LearnRate: 2.500e-01, Time taken : 0.992s\n",
      "\tEpoch 11, Step 2700, MSE: 1.058e+00,  LearnRate: 2.500e-01, Time taken : 1.032s\n",
      "\tEpoch 11, Step 2800, MSE: 4.083e+00,  LearnRate: 2.500e-01, Time taken : 0.927s\n",
      "\tEpoch 11, Step 2900, MSE: 9.365e-01,  LearnRate: 2.500e-01, Time taken : 1.061s\n",
      "Starting Epoch 12, with 2909 batches\n",
      "\tEpoch 12, Step 0000, MSE: 8.653e-01,  LearnRate: 2.500e-01, Time taken : 0.316s\n",
      "\tEpoch 12, Step 0100, MSE: 3.136e+00,  LearnRate: 2.500e-01, Time taken : 1.050s\n",
      "\tEpoch 12, Step 0200, MSE: 2.773e+00,  LearnRate: 2.500e-01, Time taken : 1.023s\n",
      "\tEpoch 12, Step 0300, MSE: 7.137e+00,  LearnRate: 2.500e-01, Time taken : 1.006s\n",
      "\tEpoch 12, Step 0400, MSE: 8.687e-01,  LearnRate: 2.500e-01, Time taken : 0.940s\n",
      "\tEpoch 12, Step 0500, MSE: 1.343e+01,  LearnRate: 2.500e-01, Time taken : 0.871s\n",
      "\tEpoch 12, Step 0600, MSE: 3.622e+01,  LearnRate: 2.500e-01, Time taken : 0.954s\n",
      "\tEpoch 12, Step 0700, MSE: 2.778e+00,  LearnRate: 2.500e-01, Time taken : 1.023s\n",
      "\tEpoch 12, Step 0800, MSE: 2.771e+00,  LearnRate: 2.500e-01, Time taken : 1.094s\n",
      "\tEpoch 12, Step 0900, MSE: 7.225e-01,  LearnRate: 2.500e-01, Time taken : 0.953s\n",
      "\tEpoch 12, Step 1000, MSE: 6.609e+00,  LearnRate: 2.500e-01, Time taken : 0.890s\n",
      "\tEpoch 12, Step 1100, MSE: 1.128e+00,  LearnRate: 2.500e-01, Time taken : 0.909s\n",
      "\tEpoch 12, Step 1200, MSE: 1.498e+01,  LearnRate: 2.500e-01, Time taken : 0.966s\n",
      "\tEpoch 12, Step 1300, MSE: 1.361e+00,  LearnRate: 2.500e-01, Time taken : 0.872s\n",
      "\tEpoch 12, Step 1400, MSE: 1.209e+00,  LearnRate: 2.500e-01, Time taken : 1.013s\n",
      "\tEpoch 12, Step 1500, MSE: 3.504e+00,  LearnRate: 2.500e-01, Time taken : 0.950s\n",
      "\tEpoch 12, Step 1600, MSE: 1.438e+01,  LearnRate: 2.500e-01, Time taken : 1.170s\n",
      "\tEpoch 12, Step 1700, MSE: 3.009e+00,  LearnRate: 2.500e-01, Time taken : 1.041s\n",
      "\tEpoch 12, Step 1800, MSE: 3.952e+00,  LearnRate: 2.500e-01, Time taken : 0.958s\n",
      "\tEpoch 12, Step 1900, MSE: 2.368e+01,  LearnRate: 2.500e-01, Time taken : 0.913s\n",
      "\tEpoch 12, Step 2000, MSE: 2.937e+00,  LearnRate: 2.500e-01, Time taken : 1.005s\n",
      "\tEpoch 12, Step 2100, MSE: 1.718e+01,  LearnRate: 2.500e-01, Time taken : 0.994s\n",
      "\tEpoch 12, Step 2200, MSE: 1.018e+01,  LearnRate: 2.500e-01, Time taken : 0.999s\n",
      "\tEpoch 12, Step 2300, MSE: 5.644e+01,  LearnRate: 2.500e-01, Time taken : 0.974s\n",
      "\tEpoch 12, Step 2400, MSE: 2.697e+00,  LearnRate: 2.500e-01, Time taken : 1.037s\n",
      "\tEpoch 12, Step 2500, MSE: 9.019e+01,  LearnRate: 2.500e-01, Time taken : 1.037s\n",
      "\tEpoch 12, Step 2600, MSE: 4.334e+02,  LearnRate: 2.500e-01, Time taken : 0.996s\n",
      "\tEpoch 12, Step 2700, MSE: 5.458e+02,  LearnRate: 2.500e-01, Time taken : 0.959s\n",
      "\tEpoch 12, Step 2800, MSE: 1.155e+05,  LearnRate: 2.500e-01, Time taken : 0.982s\n",
      "\tEpoch 12, Step 2900, MSE: 2.298e+02,  LearnRate: 2.500e-01, Time taken : 1.050s\n",
      "Starting Epoch 13, with 2909 batches\n",
      "\tEpoch 13, Step 0000, MSE: 7.882e+01,  LearnRate: 2.500e-01, Time taken : 0.249s\n",
      "\tEpoch 13, Step 0100, MSE: 8.156e+01,  LearnRate: 2.500e-01, Time taken : 1.118s\n",
      "\tEpoch 13, Step 0200, MSE: 2.245e+03,  LearnRate: 2.500e-01, Time taken : 1.100s\n",
      "\tEpoch 13, Step 0300, MSE: 1.390e+04,  LearnRate: 2.500e-01, Time taken : 1.130s\n",
      "\tEpoch 13, Step 0400, MSE: 6.098e+04,  LearnRate: 2.500e-01, Time taken : 0.916s\n",
      "\tEpoch 13, Step 0500, MSE: 2.390e+04,  LearnRate: 2.500e-01, Time taken : 1.046s\n",
      "\tEpoch 13, Step 0600, MSE: 2.958e+03,  LearnRate: 2.500e-01, Time taken : 0.951s\n",
      "\tEpoch 13, Step 0700, MSE: 3.658e+02,  LearnRate: 2.500e-01, Time taken : 0.984s\n",
      "\tEpoch 13, Step 0800, MSE: 1.013e+05,  LearnRate: 2.500e-01, Time taken : 0.938s\n",
      "\tEpoch 13, Step 0900, MSE: 7.440e+02,  LearnRate: 2.500e-01, Time taken : 0.934s\n",
      "\tEpoch 13, Step 1000, MSE: 3.317e+03,  LearnRate: 2.500e-01, Time taken : 0.942s\n",
      "\tEpoch 13, Step 1100, MSE: 7.422e+04,  LearnRate: 2.500e-01, Time taken : 0.987s\n",
      "\tEpoch 13, Step 1200, MSE: 4.308e+03,  LearnRate: 2.500e-01, Time taken : 0.972s\n",
      "\tEpoch 13, Step 1300, MSE: 7.674e+04,  LearnRate: 2.500e-01, Time taken : 1.026s\n",
      "\tEpoch 13, Step 1400, MSE: 6.873e+03,  LearnRate: 2.500e-01, Time taken : 0.977s\n",
      "\tEpoch 13, Step 1500, MSE: 1.369e+03,  LearnRate: 2.500e-01, Time taken : 0.913s\n",
      "\tEpoch 13, Step 1600, MSE: 1.282e+04,  LearnRate: 2.500e-01, Time taken : 0.949s\n",
      "\tEpoch 13, Step 1700, MSE: 2.371e+03,  LearnRate: 2.500e-01, Time taken : 1.122s\n",
      "\tEpoch 13, Step 1800, MSE: 3.698e+03,  LearnRate: 2.500e-01, Time taken : 0.984s\n",
      "\tEpoch 13, Step 1900, MSE: 1.025e+04,  LearnRate: 2.500e-01, Time taken : 1.032s\n",
      "\tEpoch 13, Step 2000, MSE: 2.422e+03,  LearnRate: 2.500e-01, Time taken : 0.999s\n",
      "\tEpoch 13, Step 2100, MSE: 2.096e+04,  LearnRate: 2.500e-01, Time taken : 0.979s\n",
      "\tEpoch 13, Step 2200, MSE: 1.117e+04,  LearnRate: 2.500e-01, Time taken : 1.078s\n",
      "\tEpoch 13, Step 2300, MSE: 1.039e+03,  LearnRate: 2.500e-01, Time taken : 1.027s\n",
      "\tEpoch 13, Step 2400, MSE: 1.320e+05,  LearnRate: 2.500e-01, Time taken : 0.967s\n",
      "\tEpoch 13, Step 2500, MSE: 1.148e+04,  LearnRate: 2.500e-01, Time taken : 0.952s\n",
      "\tEpoch 13, Step 2600, MSE: 5.980e+04,  LearnRate: 2.500e-01, Time taken : 1.015s\n",
      "\tEpoch 13, Step 2700, MSE: 3.588e+04,  LearnRate: 2.500e-01, Time taken : 0.936s\n",
      "\tEpoch 13, Step 2800, MSE: 2.748e+04,  LearnRate: 2.500e-01, Time taken : 1.009s\n",
      "\tEpoch 13, Step 2900, MSE: 6.888e+03,  LearnRate: 2.500e-01, Time taken : 0.949s\n",
      "Starting Epoch 14, with 2909 batches\n",
      "\tEpoch 14, Step 0000, MSE: 5.611e+03,  LearnRate: 2.500e-01, Time taken : 0.278s\n",
      "\tEpoch 14, Step 0100, MSE: 2.528e+06,  LearnRate: 2.500e-01, Time taken : 1.056s\n",
      "\tEpoch 14, Step 0200, MSE: 5.720e+00,  LearnRate: 2.500e-01, Time taken : 1.012s\n",
      "\tEpoch 14, Step 0300, MSE: 1.312e+01,  LearnRate: 2.500e-01, Time taken : 1.024s\n",
      "\tEpoch 14, Step 0400, MSE: 3.810e+00,  LearnRate: 2.500e-01, Time taken : 1.041s\n",
      "\tEpoch 14, Step 0500, MSE: 4.540e+04,  LearnRate: 2.500e-01, Time taken : 0.938s\n",
      "\tEpoch 14, Step 0600, MSE: 1.419e+03,  LearnRate: 2.500e-01, Time taken : 0.921s\n",
      "\tEpoch 14, Step 0700, MSE: 6.722e+02,  LearnRate: 2.500e-01, Time taken : 1.046s\n",
      "\tEpoch 14, Step 0800, MSE: 1.781e+02,  LearnRate: 2.500e-01, Time taken : 0.951s\n",
      "\tEpoch 14, Step 0900, MSE: 1.649e+02,  LearnRate: 2.500e-01, Time taken : 1.019s\n",
      "\tEpoch 14, Step 1000, MSE: 4.054e+02,  LearnRate: 2.500e-01, Time taken : 0.948s\n",
      "\tEpoch 14, Step 1100, MSE: 4.514e+02,  LearnRate: 2.500e-01, Time taken : 0.964s\n",
      "\tEpoch 14, Step 1200, MSE: 2.205e+02,  LearnRate: 2.500e-01, Time taken : 0.959s\n",
      "\tEpoch 14, Step 1300, MSE: 2.128e+02,  LearnRate: 2.500e-01, Time taken : 0.992s\n",
      "\tEpoch 14, Step 1400, MSE: 1.284e+03,  LearnRate: 2.500e-01, Time taken : 1.039s\n",
      "\tEpoch 14, Step 1500, MSE: 3.822e+02,  LearnRate: 2.500e-01, Time taken : 0.979s\n",
      "\tEpoch 14, Step 1600, MSE: 4.561e+02,  LearnRate: 2.500e-01, Time taken : 0.926s\n",
      "\tEpoch 14, Step 1700, MSE: 2.711e+02,  LearnRate: 2.500e-01, Time taken : 1.059s\n",
      "\tEpoch 14, Step 1800, MSE: 7.044e+01,  LearnRate: 2.500e-01, Time taken : 1.091s\n",
      "\tEpoch 14, Step 1900, MSE: 6.163e+01,  LearnRate: 2.500e-01, Time taken : 1.143s\n",
      "\tEpoch 14, Step 2000, MSE: 8.542e+01,  LearnRate: 2.500e-01, Time taken : 1.028s\n",
      "\tEpoch 14, Step 2100, MSE: 1.631e+02,  LearnRate: 2.500e-01, Time taken : 1.026s\n",
      "\tEpoch 14, Step 2200, MSE: 1.117e+02,  LearnRate: 2.500e-01, Time taken : 1.002s\n",
      "\tEpoch 14, Step 2300, MSE: 2.205e+03,  LearnRate: 2.500e-01, Time taken : 1.002s\n",
      "\tEpoch 14, Step 2400, MSE: 8.065e+01,  LearnRate: 2.500e-01, Time taken : 0.975s\n",
      "\tEpoch 14, Step 2500, MSE: 7.126e+02,  LearnRate: 2.500e-01, Time taken : 0.936s\n",
      "\tEpoch 14, Step 2600, MSE: 1.064e+02,  LearnRate: 2.500e-01, Time taken : 0.959s\n",
      "\tEpoch 14, Step 2700, MSE: 1.275e+03,  LearnRate: 2.500e-01, Time taken : 0.972s\n",
      "\tEpoch 14, Step 2800, MSE: 2.643e+02,  LearnRate: 2.500e-01, Time taken : 0.902s\n",
      "\tEpoch 14, Step 2900, MSE: 6.139e+02,  LearnRate: 2.500e-01, Time taken : 0.947s\n",
      "Starting Epoch 15, with 2909 batches\n",
      "\tEpoch 15, Step 0000, MSE: 7.112e+01,  LearnRate: 2.500e-01, Time taken : 0.291s\n",
      "\tEpoch 15, Step 0100, MSE: 1.019e+02,  LearnRate: 2.500e-01, Time taken : 0.946s\n",
      "\tEpoch 15, Step 0200, MSE: 2.847e+02,  LearnRate: 2.500e-01, Time taken : 0.939s\n",
      "\tEpoch 15, Step 0300, MSE: 5.086e+01,  LearnRate: 2.500e-01, Time taken : 0.937s\n",
      "\tEpoch 15, Step 0400, MSE: 2.034e+02,  LearnRate: 2.500e-01, Time taken : 0.997s\n",
      "\tEpoch 15, Step 0500, MSE: 3.319e+01,  LearnRate: 2.500e-01, Time taken : 0.976s\n",
      "\tEpoch 15, Step 0600, MSE: 3.394e+02,  LearnRate: 2.500e-01, Time taken : 1.168s\n",
      "\tEpoch 15, Step 0700, MSE: 7.483e+01,  LearnRate: 2.500e-01, Time taken : 1.187s\n",
      "\tEpoch 15, Step 0800, MSE: 6.732e+01,  LearnRate: 2.500e-01, Time taken : 1.004s\n",
      "\tEpoch 15, Step 0900, MSE: 1.706e+02,  LearnRate: 2.500e-01, Time taken : 0.934s\n",
      "\tEpoch 15, Step 1000, MSE: 7.006e+01,  LearnRate: 2.500e-01, Time taken : 0.938s\n",
      "\tEpoch 15, Step 1100, MSE: 1.684e+02,  LearnRate: 2.500e-01, Time taken : 1.092s\n",
      "\tEpoch 15, Step 1200, MSE: 1.777e+02,  LearnRate: 2.500e-01, Time taken : 1.059s\n",
      "\tEpoch 15, Step 1300, MSE: 1.453e+02,  LearnRate: 2.500e-01, Time taken : 0.962s\n",
      "\tEpoch 15, Step 1400, MSE: 3.824e+01,  LearnRate: 2.500e-01, Time taken : 1.046s\n",
      "\tEpoch 15, Step 1500, MSE: 1.948e+02,  LearnRate: 2.500e-01, Time taken : 0.989s\n",
      "\tEpoch 15, Step 1600, MSE: 4.955e+02,  LearnRate: 2.500e-01, Time taken : 1.001s\n",
      "\tEpoch 15, Step 1700, MSE: 3.073e+03,  LearnRate: 2.500e-01, Time taken : 1.095s\n",
      "\tEpoch 15, Step 1800, MSE: 2.892e+03,  LearnRate: 2.500e-01, Time taken : 1.070s\n",
      "\tEpoch 15, Step 1900, MSE: 1.002e+04,  LearnRate: 2.500e-01, Time taken : 0.996s\n",
      "\tEpoch 15, Step 2000, MSE: 1.604e+03,  LearnRate: 2.500e-01, Time taken : 0.945s\n",
      "\tEpoch 15, Step 2100, MSE: 3.521e+04,  LearnRate: 2.500e-01, Time taken : 1.044s\n",
      "\tEpoch 15, Step 2200, MSE: 1.878e+03,  LearnRate: 2.500e-01, Time taken : 0.969s\n",
      "\tEpoch 15, Step 2300, MSE: 1.903e+03,  LearnRate: 2.500e-01, Time taken : 0.884s\n",
      "\tEpoch 15, Step 2400, MSE: 8.754e+01,  LearnRate: 2.500e-01, Time taken : 1.132s\n",
      "\tEpoch 15, Step 2500, MSE: 3.896e+03,  LearnRate: 2.500e-01, Time taken : 1.150s\n",
      "\tEpoch 15, Step 2600, MSE: 1.949e+04,  LearnRate: 2.500e-01, Time taken : 1.111s\n",
      "\tEpoch 15, Step 2700, MSE: 6.942e+05,  LearnRate: 2.500e-01, Time taken : 1.065s\n",
      "\tEpoch 15, Step 2800, MSE: 2.773e+02,  LearnRate: 2.500e-01, Time taken : 1.069s\n",
      "\tEpoch 15, Step 2900, MSE: 5.376e+02,  LearnRate: 2.500e-01, Time taken : 1.014s\n",
      "Starting Epoch 16, with 2909 batches\n",
      "\tEpoch 16, Step 0000, MSE: 6.358e+02,  LearnRate: 2.500e-01, Time taken : 0.251s\n",
      "\tEpoch 16, Step 0100, MSE: 4.491e+01,  LearnRate: 2.500e-01, Time taken : 0.957s\n",
      "\tEpoch 16, Step 0200, MSE: 4.440e+02,  LearnRate: 2.500e-01, Time taken : 0.973s\n",
      "\tEpoch 16, Step 0300, MSE: 8.221e+01,  LearnRate: 2.500e-01, Time taken : 0.920s\n",
      "\tEpoch 16, Step 0400, MSE: 5.299e+02,  LearnRate: 2.500e-01, Time taken : 1.018s\n",
      "\tEpoch 16, Step 0500, MSE: 1.784e+02,  LearnRate: 2.500e-01, Time taken : 0.926s\n",
      "\tEpoch 16, Step 0600, MSE: 2.309e+02,  LearnRate: 2.500e-01, Time taken : 0.942s\n",
      "\tEpoch 16, Step 0700, MSE: 1.117e+03,  LearnRate: 2.500e-01, Time taken : 1.049s\n",
      "\tEpoch 16, Step 0800, MSE: 1.428e+02,  LearnRate: 2.500e-01, Time taken : 0.958s\n",
      "\tEpoch 16, Step 0900, MSE: 1.646e+02,  LearnRate: 2.500e-01, Time taken : 0.955s\n",
      "\tEpoch 16, Step 1000, MSE: 1.633e+03,  LearnRate: 2.500e-01, Time taken : 1.008s\n",
      "\tEpoch 16, Step 1100, MSE: 3.722e+02,  LearnRate: 2.500e-01, Time taken : 0.939s\n",
      "\tEpoch 16, Step 1200, MSE: 1.907e+02,  LearnRate: 2.500e-01, Time taken : 0.996s\n",
      "\tEpoch 16, Step 1300, MSE: 2.997e+02,  LearnRate: 2.500e-01, Time taken : 0.985s\n",
      "\tEpoch 16, Step 1400, MSE: 7.597e+02,  LearnRate: 2.500e-01, Time taken : 1.007s\n",
      "\tEpoch 16, Step 1500, MSE: 1.199e+07,  LearnRate: 2.500e-01, Time taken : 0.934s\n",
      "\tEpoch 16, Step 1600, MSE: 1.300e+03,  LearnRate: 2.500e-01, Time taken : 0.973s\n",
      "\tEpoch 16, Step 1700, MSE: 7.637e+02,  LearnRate: 2.500e-01, Time taken : 0.937s\n",
      "\tEpoch 16, Step 1800, MSE: 2.079e+03,  LearnRate: 2.500e-01, Time taken : 0.945s\n",
      "\tEpoch 16, Step 1900, MSE: 1.944e+03,  LearnRate: 2.500e-01, Time taken : 1.001s\n",
      "\tEpoch 16, Step 2000, MSE: 3.907e+02,  LearnRate: 2.500e-01, Time taken : 1.035s\n",
      "\tEpoch 16, Step 2100, MSE: 2.584e+03,  LearnRate: 2.500e-01, Time taken : 1.197s\n",
      "\tEpoch 16, Step 2200, MSE: 1.374e+03,  LearnRate: 2.500e-01, Time taken : 1.278s\n",
      "\tEpoch 16, Step 2300, MSE: 5.485e+01,  LearnRate: 2.500e-01, Time taken : 1.234s\n",
      "\tEpoch 16, Step 2400, MSE: 3.803e+02,  LearnRate: 2.500e-01, Time taken : 1.195s\n",
      "\tEpoch 16, Step 2500, MSE: 4.678e+02,  LearnRate: 2.500e-01, Time taken : 1.179s\n",
      "\tEpoch 16, Step 2600, MSE: 1.098e+03,  LearnRate: 2.500e-01, Time taken : 1.167s\n",
      "\tEpoch 16, Step 2700, MSE: 8.339e+02,  LearnRate: 2.500e-01, Time taken : 0.951s\n",
      "\tEpoch 16, Step 2800, MSE: 7.656e+02,  LearnRate: 2.500e-01, Time taken : 0.998s\n",
      "\tEpoch 16, Step 2900, MSE: 5.626e+02,  LearnRate: 2.500e-01, Time taken : 0.919s\n",
      "Starting Epoch 17, with 2909 batches\n",
      "\tEpoch 17, Step 0000, MSE: 5.237e+01,  LearnRate: 2.500e-01, Time taken : 0.239s\n",
      "\tEpoch 17, Step 0100, MSE: 5.520e+02,  LearnRate: 2.500e-01, Time taken : 0.986s\n",
      "\tEpoch 17, Step 0200, MSE: 3.097e+02,  LearnRate: 2.500e-01, Time taken : 0.929s\n",
      "\tEpoch 17, Step 0300, MSE: 2.017e+02,  LearnRate: 2.500e-01, Time taken : 0.951s\n",
      "\tEpoch 17, Step 0400, MSE: 7.447e+02,  LearnRate: 2.500e-01, Time taken : 1.085s\n",
      "\tEpoch 17, Step 0500, MSE: 1.041e+03,  LearnRate: 2.500e-01, Time taken : 1.116s\n",
      "\tEpoch 17, Step 0600, MSE: 1.962e+01,  LearnRate: 2.500e-01, Time taken : 0.974s\n",
      "\tEpoch 17, Step 0700, MSE: 7.799e+01,  LearnRate: 2.500e-01, Time taken : 0.937s\n",
      "\tEpoch 17, Step 0800, MSE: 7.178e+02,  LearnRate: 2.500e-01, Time taken : 0.932s\n",
      "\tEpoch 17, Step 0900, MSE: 9.104e+01,  LearnRate: 2.500e-01, Time taken : 1.022s\n",
      "\tEpoch 17, Step 1000, MSE: 1.927e+01,  LearnRate: 2.500e-01, Time taken : 1.030s\n",
      "\tEpoch 17, Step 1100, MSE: 2.785e+02,  LearnRate: 2.500e-01, Time taken : 0.928s\n",
      "\tEpoch 17, Step 1200, MSE: 2.637e+02,  LearnRate: 2.500e-01, Time taken : 1.025s\n",
      "\tEpoch 17, Step 1300, MSE: 3.589e+02,  LearnRate: 2.500e-01, Time taken : 1.048s\n",
      "\tEpoch 17, Step 1400, MSE: 2.837e+02,  LearnRate: 2.500e-01, Time taken : 1.072s\n",
      "\tEpoch 17, Step 1500, MSE: 4.061e+02,  LearnRate: 2.500e-01, Time taken : 1.067s\n",
      "\tEpoch 17, Step 1600, MSE: 6.778e+01,  LearnRate: 2.500e-01, Time taken : 1.004s\n",
      "\tEpoch 17, Step 1700, MSE: 6.656e+02,  LearnRate: 2.500e-01, Time taken : 0.925s\n",
      "\tEpoch 17, Step 1800, MSE: 7.474e+02,  LearnRate: 2.500e-01, Time taken : 0.941s\n",
      "\tEpoch 17, Step 1900, MSE: 1.011e+03,  LearnRate: 2.500e-01, Time taken : 1.010s\n",
      "\tEpoch 17, Step 2000, MSE: 1.068e+03,  LearnRate: 2.500e-01, Time taken : 0.989s\n",
      "\tEpoch 17, Step 2100, MSE: 9.874e+02,  LearnRate: 2.500e-01, Time taken : 0.983s\n",
      "\tEpoch 17, Step 2200, MSE: 3.123e+03,  LearnRate: 2.500e-01, Time taken : 1.027s\n",
      "\tEpoch 17, Step 2300, MSE: 7.389e+03,  LearnRate: 2.500e-01, Time taken : 0.996s\n",
      "\tEpoch 17, Step 2400, MSE: 4.777e+03,  LearnRate: 2.500e-01, Time taken : 0.946s\n",
      "\tEpoch 17, Step 2500, MSE: 2.239e+04,  LearnRate: 2.500e-01, Time taken : 0.886s\n",
      "\tEpoch 17, Step 2600, MSE: 7.511e+03,  LearnRate: 2.500e-01, Time taken : 0.952s\n",
      "\tEpoch 17, Step 2700, MSE: 3.384e+04,  LearnRate: 2.500e-01, Time taken : 0.907s\n",
      "\tEpoch 17, Step 2800, MSE: 8.011e+03,  LearnRate: 2.500e-01, Time taken : 0.898s\n",
      "\tEpoch 17, Step 2900, MSE: 4.105e+03,  LearnRate: 2.500e-01, Time taken : 0.942s\n",
      "Starting Epoch 18, with 2909 batches\n",
      "\tEpoch 18, Step 0000, MSE: 8.678e+02,  LearnRate: 2.500e-01, Time taken : 0.243s\n",
      "\tEpoch 18, Step 0100, MSE: 1.871e+04,  LearnRate: 2.500e-01, Time taken : 0.880s\n",
      "\tEpoch 18, Step 0200, MSE: 6.776e+02,  LearnRate: 2.500e-01, Time taken : 0.884s\n",
      "\tEpoch 18, Step 0300, MSE: 6.617e+03,  LearnRate: 2.500e-01, Time taken : 0.998s\n",
      "\tEpoch 18, Step 0400, MSE: 1.691e+03,  LearnRate: 2.500e-01, Time taken : 0.975s\n",
      "\tEpoch 18, Step 0500, MSE: 1.384e+03,  LearnRate: 2.500e-01, Time taken : 0.991s\n",
      "\tEpoch 18, Step 0600, MSE: 1.407e+02,  LearnRate: 2.500e-01, Time taken : 1.090s\n",
      "\tEpoch 18, Step 0700, MSE: 2.340e+03,  LearnRate: 2.500e-01, Time taken : 1.028s\n",
      "\tEpoch 18, Step 0800, MSE: 1.459e+04,  LearnRate: 2.500e-01, Time taken : 0.992s\n",
      "\tEpoch 18, Step 0900, MSE: 1.634e+03,  LearnRate: 2.500e-01, Time taken : 1.059s\n",
      "\tEpoch 18, Step 1000, MSE: 1.826e+03,  LearnRate: 2.500e-01, Time taken : 0.969s\n",
      "\tEpoch 18, Step 1100, MSE: 2.849e+04,  LearnRate: 2.500e-01, Time taken : 0.945s\n",
      "\tEpoch 18, Step 1200, MSE: 3.423e+04,  LearnRate: 2.500e-01, Time taken : 0.984s\n",
      "\tEpoch 18, Step 1300, MSE: 7.356e+02,  LearnRate: 2.500e-01, Time taken : 0.926s\n",
      "\tEpoch 18, Step 1400, MSE: 1.211e+03,  LearnRate: 2.500e-01, Time taken : 0.965s\n",
      "\tEpoch 18, Step 1500, MSE: 7.537e+02,  LearnRate: 2.500e-01, Time taken : 0.941s\n",
      "\tEpoch 18, Step 1600, MSE: 3.561e+04,  LearnRate: 2.500e-01, Time taken : 0.965s\n",
      "\tEpoch 18, Step 1700, MSE: 5.494e+03,  LearnRate: 2.500e-01, Time taken : 0.987s\n",
      "\tEpoch 18, Step 1800, MSE: 3.337e+03,  LearnRate: 2.500e-01, Time taken : 0.985s\n",
      "\tEpoch 18, Step 1900, MSE: 5.488e+02,  LearnRate: 2.500e-01, Time taken : 1.024s\n",
      "\tEpoch 18, Step 2000, MSE: 3.134e+03,  LearnRate: 2.500e-01, Time taken : 1.051s\n",
      "\tEpoch 18, Step 2100, MSE: 1.932e+04,  LearnRate: 2.500e-01, Time taken : 0.995s\n",
      "\tEpoch 18, Step 2200, MSE: 1.995e+04,  LearnRate: 2.500e-01, Time taken : 0.933s\n",
      "\tEpoch 18, Step 2300, MSE: 3.998e+03,  LearnRate: 2.500e-01, Time taken : 0.922s\n",
      "\tEpoch 18, Step 2400, MSE: 1.355e+03,  LearnRate: 2.500e-01, Time taken : 0.984s\n",
      "\tEpoch 18, Step 2500, MSE: 1.293e+03,  LearnRate: 2.500e-01, Time taken : 0.904s\n",
      "\tEpoch 18, Step 2600, MSE: 5.466e+03,  LearnRate: 2.500e-01, Time taken : 0.913s\n",
      "\tEpoch 18, Step 2700, MSE: 2.758e+03,  LearnRate: 2.500e-01, Time taken : 0.988s\n",
      "\tEpoch 18, Step 2800, MSE: 3.493e+03,  LearnRate: 2.500e-01, Time taken : 0.964s\n",
      "\tEpoch 18, Step 2900, MSE: 2.164e+03,  LearnRate: 2.500e-01, Time taken : 0.965s\n",
      "Starting Epoch 19, with 2909 batches\n",
      "\tEpoch 19, Step 0000, MSE: 1.018e+04,  LearnRate: 2.500e-01, Time taken : 0.245s\n",
      "\tEpoch 19, Step 0100, MSE: 2.191e+01,  LearnRate: 2.500e-01, Time taken : 0.913s\n",
      "\tEpoch 19, Step 0200, MSE: 2.316e+03,  LearnRate: 2.500e-01, Time taken : 0.964s\n",
      "\tEpoch 19, Step 0300, MSE: 2.486e+04,  LearnRate: 2.500e-01, Time taken : 0.975s\n",
      "\tEpoch 19, Step 0400, MSE: 1.784e+02,  LearnRate: 2.500e-01, Time taken : 1.071s\n",
      "\tEpoch 19, Step 0500, MSE: 2.667e+03,  LearnRate: 2.500e-01, Time taken : 0.941s\n",
      "\tEpoch 19, Step 0600, MSE: 6.713e+03,  LearnRate: 2.500e-01, Time taken : 0.924s\n",
      "\tEpoch 19, Step 0700, MSE: 4.660e+03,  LearnRate: 2.500e-01, Time taken : 1.025s\n",
      "\tEpoch 19, Step 0800, MSE: 9.059e+03,  LearnRate: 2.500e-01, Time taken : 1.022s\n",
      "\tEpoch 19, Step 0900, MSE: 2.545e+03,  LearnRate: 2.500e-01, Time taken : 0.963s\n",
      "\tEpoch 19, Step 1000, MSE: 2.321e+03,  LearnRate: 2.500e-01, Time taken : 0.933s\n",
      "\tEpoch 19, Step 1100, MSE: 2.635e+03,  LearnRate: 2.500e-01, Time taken : 1.035s\n",
      "\tEpoch 19, Step 1200, MSE: 7.204e+02,  LearnRate: 2.500e-01, Time taken : 1.113s\n",
      "\tEpoch 19, Step 1300, MSE: 1.808e+02,  LearnRate: 2.500e-01, Time taken : 0.998s\n",
      "\tEpoch 19, Step 1400, MSE: 8.665e+03,  LearnRate: 2.500e-01, Time taken : 0.969s\n",
      "\tEpoch 19, Step 1500, MSE: 1.658e+04,  LearnRate: 2.500e-01, Time taken : 0.927s\n",
      "\tEpoch 19, Step 1600, MSE: 5.937e+03,  LearnRate: 2.500e-01, Time taken : 0.937s\n",
      "\tEpoch 19, Step 1700, MSE: 2.777e+03,  LearnRate: 2.500e-01, Time taken : 0.945s\n",
      "\tEpoch 19, Step 1800, MSE: 7.539e+04,  LearnRate: 2.500e-01, Time taken : 1.070s\n",
      "\tEpoch 19, Step 1900, MSE: 8.401e+02,  LearnRate: 2.500e-01, Time taken : 0.947s\n",
      "\tEpoch 19, Step 2000, MSE: 2.485e+02,  LearnRate: 2.500e-01, Time taken : 0.912s\n",
      "\tEpoch 19, Step 2100, MSE: 6.924e+03,  LearnRate: 2.500e-01, Time taken : 0.904s\n",
      "\tEpoch 19, Step 2200, MSE: 2.074e+03,  LearnRate: 2.500e-01, Time taken : 0.941s\n",
      "\tEpoch 19, Step 2300, MSE: 3.123e+02,  LearnRate: 2.500e-01, Time taken : 1.120s\n",
      "\tEpoch 19, Step 2400, MSE: 5.257e+02,  LearnRate: 2.500e-01, Time taken : 1.105s\n",
      "\tEpoch 19, Step 2500, MSE: 2.103e+04,  LearnRate: 2.500e-01, Time taken : 1.078s\n",
      "\tEpoch 19, Step 2600, MSE: 2.129e+04,  LearnRate: 2.500e-01, Time taken : 1.048s\n",
      "\tEpoch 19, Step 2700, MSE: 7.062e+03,  LearnRate: 2.500e-01, Time taken : 0.899s\n",
      "\tEpoch 19, Step 2800, MSE: 2.489e+03,  LearnRate: 2.500e-01, Time taken : 0.972s\n",
      "\tEpoch 19, Step 2900, MSE: 2.245e+03,  LearnRate: 2.500e-01, Time taken : 0.982s\n",
      "Starting Epoch 20, with 2909 batches\n",
      "\tEpoch 20, Step 0000, MSE: 4.012e+03,  LearnRate: 1.250e-01, Time taken : 0.260s\n",
      "\tEpoch 20, Step 0100, MSE: 8.136e-01,  LearnRate: 1.250e-01, Time taken : 0.983s\n",
      "\tEpoch 20, Step 0200, MSE: 8.457e-01,  LearnRate: 1.250e-01, Time taken : 0.923s\n",
      "\tEpoch 20, Step 0300, MSE: 1.321e+01,  LearnRate: 1.250e-01, Time taken : 0.920s\n",
      "\tEpoch 20, Step 0400, MSE: 1.766e+00,  LearnRate: 1.250e-01, Time taken : 1.007s\n",
      "\tEpoch 20, Step 0500, MSE: 5.811e+00,  LearnRate: 1.250e-01, Time taken : 1.008s\n",
      "\tEpoch 20, Step 0600, MSE: 2.975e+01,  LearnRate: 1.250e-01, Time taken : 0.996s\n",
      "\tEpoch 20, Step 0700, MSE: 2.589e+00,  LearnRate: 1.250e-01, Time taken : 0.991s\n",
      "\tEpoch 20, Step 0800, MSE: 2.044e+01,  LearnRate: 1.250e-01, Time taken : 1.054s\n",
      "\tEpoch 20, Step 0900, MSE: 2.647e+01,  LearnRate: 1.250e-01, Time taken : 1.032s\n",
      "\tEpoch 20, Step 1000, MSE: 1.074e+01,  LearnRate: 1.250e-01, Time taken : 1.010s\n",
      "\tEpoch 20, Step 1100, MSE: 5.684e+00,  LearnRate: 1.250e-01, Time taken : 1.026s\n",
      "\tEpoch 20, Step 1200, MSE: 1.121e+00,  LearnRate: 1.250e-01, Time taken : 0.881s\n",
      "\tEpoch 20, Step 1300, MSE: 9.519e+01,  LearnRate: 1.250e-01, Time taken : 0.985s\n",
      "\tEpoch 20, Step 1400, MSE: 4.638e+01,  LearnRate: 1.250e-01, Time taken : 1.048s\n",
      "\tEpoch 20, Step 1500, MSE: 8.741e+01,  LearnRate: 1.250e-01, Time taken : 0.948s\n",
      "\tEpoch 20, Step 1600, MSE: 6.484e+02,  LearnRate: 1.250e-01, Time taken : 0.970s\n",
      "\tEpoch 20, Step 1700, MSE: 3.232e+02,  LearnRate: 1.250e-01, Time taken : 0.988s\n",
      "\tEpoch 20, Step 1800, MSE: 6.640e+03,  LearnRate: 1.250e-01, Time taken : 1.003s\n",
      "\tEpoch 20, Step 1900, MSE: 1.607e+03,  LearnRate: 1.250e-01, Time taken : 0.886s\n",
      "\tEpoch 20, Step 2000, MSE: 5.892e+04,  LearnRate: 1.250e-01, Time taken : 0.993s\n",
      "\tEpoch 20, Step 2100, MSE: 1.800e+02,  LearnRate: 1.250e-01, Time taken : 0.948s\n",
      "\tEpoch 20, Step 2200, MSE: 1.758e+03,  LearnRate: 1.250e-01, Time taken : 0.927s\n",
      "\tEpoch 20, Step 2300, MSE: 5.254e+02,  LearnRate: 1.250e-01, Time taken : 0.879s\n",
      "\tEpoch 20, Step 2400, MSE: 9.625e+02,  LearnRate: 1.250e-01, Time taken : 1.111s\n",
      "\tEpoch 20, Step 2500, MSE: 6.063e+02,  LearnRate: 1.250e-01, Time taken : 1.094s\n",
      "\tEpoch 20, Step 2600, MSE: 3.689e+03,  LearnRate: 1.250e-01, Time taken : 0.990s\n",
      "\tEpoch 20, Step 2700, MSE: 2.859e+02,  LearnRate: 1.250e-01, Time taken : 0.955s\n",
      "\tEpoch 20, Step 2800, MSE: 6.478e+03,  LearnRate: 1.250e-01, Time taken : 1.056s\n",
      "\tEpoch 20, Step 2900, MSE: 4.564e+02,  LearnRate: 1.250e-01, Time taken : 1.021s\n",
      "Starting Epoch 21, with 2909 batches\n",
      "\tEpoch 21, Step 0000, MSE: 7.273e+01,  LearnRate: 1.250e-01, Time taken : 0.252s\n",
      "\tEpoch 21, Step 0100, MSE: 7.052e+01,  LearnRate: 1.250e-01, Time taken : 1.057s\n",
      "\tEpoch 21, Step 0200, MSE: 1.742e+03,  LearnRate: 1.250e-01, Time taken : 0.939s\n",
      "\tEpoch 21, Step 0300, MSE: 2.019e+03,  LearnRate: 1.250e-01, Time taken : 1.000s\n",
      "\tEpoch 21, Step 0400, MSE: 7.017e+02,  LearnRate: 1.250e-01, Time taken : 0.959s\n",
      "\tEpoch 21, Step 0500, MSE: 1.185e+02,  LearnRate: 1.250e-01, Time taken : 0.943s\n",
      "\tEpoch 21, Step 0600, MSE: 4.119e+00,  LearnRate: 1.250e-01, Time taken : 1.035s\n",
      "\tEpoch 21, Step 0700, MSE: 5.138e+02,  LearnRate: 1.250e-01, Time taken : 1.013s\n",
      "\tEpoch 21, Step 0800, MSE: 7.271e+03,  LearnRate: 1.250e-01, Time taken : 1.059s\n",
      "\tEpoch 21, Step 0900, MSE: 5.101e+02,  LearnRate: 1.250e-01, Time taken : 1.030s\n",
      "\tEpoch 21, Step 1000, MSE: 9.181e+02,  LearnRate: 1.250e-01, Time taken : 1.033s\n",
      "\tEpoch 21, Step 1100, MSE: 2.164e+04,  LearnRate: 1.250e-01, Time taken : 0.997s\n",
      "\tEpoch 21, Step 1200, MSE: 1.462e+03,  LearnRate: 1.250e-01, Time taken : 0.944s\n",
      "\tEpoch 21, Step 1300, MSE: 2.891e+02,  LearnRate: 1.250e-01, Time taken : 0.971s\n",
      "\tEpoch 21, Step 1400, MSE: 6.058e+03,  LearnRate: 1.250e-01, Time taken : 0.979s\n",
      "\tEpoch 21, Step 1500, MSE: 9.505e+02,  LearnRate: 1.250e-01, Time taken : 1.013s\n",
      "\tEpoch 21, Step 1600, MSE: 1.131e+02,  LearnRate: 1.250e-01, Time taken : 0.965s\n",
      "\tEpoch 21, Step 1700, MSE: 2.858e+03,  LearnRate: 1.250e-01, Time taken : 1.047s\n",
      "\tEpoch 21, Step 1800, MSE: 4.753e+02,  LearnRate: 1.250e-01, Time taken : 0.995s\n",
      "\tEpoch 21, Step 1900, MSE: 8.953e+02,  LearnRate: 1.250e-01, Time taken : 0.981s\n",
      "\tEpoch 21, Step 2000, MSE: 1.263e+03,  LearnRate: 1.250e-01, Time taken : 1.025s\n",
      "\tEpoch 21, Step 2100, MSE: 7.258e+02,  LearnRate: 1.250e-01, Time taken : 0.911s\n",
      "\tEpoch 21, Step 2200, MSE: 4.710e+03,  LearnRate: 1.250e-01, Time taken : 0.994s\n",
      "\tEpoch 21, Step 2300, MSE: 1.073e+04,  LearnRate: 1.250e-01, Time taken : 0.926s\n",
      "\tEpoch 21, Step 2400, MSE: 3.640e+03,  LearnRate: 1.250e-01, Time taken : 0.955s\n",
      "\tEpoch 21, Step 2500, MSE: 2.386e+03,  LearnRate: 1.250e-01, Time taken : 0.995s\n",
      "\tEpoch 21, Step 2600, MSE: 7.857e+02,  LearnRate: 1.250e-01, Time taken : 0.998s\n",
      "\tEpoch 21, Step 2700, MSE: 2.727e+02,  LearnRate: 1.250e-01, Time taken : 0.970s\n",
      "\tEpoch 21, Step 2800, MSE: 2.009e+03,  LearnRate: 1.250e-01, Time taken : 0.913s\n",
      "\tEpoch 21, Step 2900, MSE: 5.151e+03,  LearnRate: 1.250e-01, Time taken : 0.929s\n",
      "Starting Epoch 22, with 2909 batches\n",
      "\tEpoch 22, Step 0000, MSE: 5.032e+03,  LearnRate: 1.250e-01, Time taken : 0.245s\n",
      "\tEpoch 22, Step 0100, MSE: 1.735e+02,  LearnRate: 1.250e-01, Time taken : 1.035s\n",
      "\tEpoch 22, Step 0200, MSE: 6.133e+02,  LearnRate: 1.250e-01, Time taken : 1.037s\n",
      "\tEpoch 22, Step 0300, MSE: 2.436e+03,  LearnRate: 1.250e-01, Time taken : 0.966s\n",
      "\tEpoch 22, Step 0400, MSE: 1.289e+03,  LearnRate: 1.250e-01, Time taken : 1.007s\n",
      "\tEpoch 22, Step 0500, MSE: 1.591e+02,  LearnRate: 1.250e-01, Time taken : 0.999s\n",
      "\tEpoch 22, Step 0600, MSE: 5.346e+02,  LearnRate: 1.250e-01, Time taken : 0.905s\n",
      "\tEpoch 22, Step 0700, MSE: 6.301e+03,  LearnRate: 1.250e-01, Time taken : 0.979s\n",
      "\tEpoch 22, Step 0800, MSE: 5.727e+02,  LearnRate: 1.250e-01, Time taken : 1.028s\n",
      "\tEpoch 22, Step 0900, MSE: 1.657e+03,  LearnRate: 1.250e-01, Time taken : 0.941s\n",
      "\tEpoch 22, Step 1000, MSE: 3.139e+03,  LearnRate: 1.250e-01, Time taken : 0.925s\n",
      "\tEpoch 22, Step 1100, MSE: 5.373e+03,  LearnRate: 1.250e-01, Time taken : 1.068s\n",
      "\tEpoch 22, Step 1200, MSE: 3.544e+03,  LearnRate: 1.250e-01, Time taken : 1.006s\n",
      "\tEpoch 22, Step 1300, MSE: 1.850e+03,  LearnRate: 1.250e-01, Time taken : 0.928s\n",
      "\tEpoch 22, Step 1400, MSE: 3.837e+02,  LearnRate: 1.250e-01, Time taken : 0.887s\n",
      "\tEpoch 22, Step 1500, MSE: 1.427e+03,  LearnRate: 1.250e-01, Time taken : 0.895s\n",
      "\tEpoch 22, Step 1600, MSE: 1.643e+02,  LearnRate: 1.250e-01, Time taken : 0.971s\n",
      "\tEpoch 22, Step 1700, MSE: 8.889e+03,  LearnRate: 1.250e-01, Time taken : 0.902s\n",
      "\tEpoch 22, Step 1800, MSE: 1.144e+03,  LearnRate: 1.250e-01, Time taken : 0.939s\n",
      "\tEpoch 22, Step 1900, MSE: 1.142e+03,  LearnRate: 1.250e-01, Time taken : 0.954s\n",
      "\tEpoch 22, Step 2000, MSE: 1.650e+03,  LearnRate: 1.250e-01, Time taken : 0.962s\n",
      "\tEpoch 22, Step 2100, MSE: 6.415e+03,  LearnRate: 1.250e-01, Time taken : 0.986s\n",
      "\tEpoch 22, Step 2200, MSE: 2.467e+02,  LearnRate: 1.250e-01, Time taken : 0.892s\n",
      "\tEpoch 22, Step 2300, MSE: 5.657e+03,  LearnRate: 1.250e-01, Time taken : 0.888s\n",
      "\tEpoch 22, Step 2400, MSE: 4.300e+02,  LearnRate: 1.250e-01, Time taken : 0.940s\n",
      "\tEpoch 22, Step 2500, MSE: 1.782e+03,  LearnRate: 1.250e-01, Time taken : 0.956s\n",
      "\tEpoch 22, Step 2600, MSE: 1.932e+03,  LearnRate: 1.250e-01, Time taken : 0.974s\n",
      "\tEpoch 22, Step 2700, MSE: 1.861e+03,  LearnRate: 1.250e-01, Time taken : 0.955s\n",
      "\tEpoch 22, Step 2800, MSE: 4.778e+02,  LearnRate: 1.250e-01, Time taken : 0.911s\n",
      "\tEpoch 22, Step 2900, MSE: 8.866e+03,  LearnRate: 1.250e-01, Time taken : 1.007s\n",
      "Starting Epoch 23, with 2909 batches\n",
      "\tEpoch 23, Step 0000, MSE: 2.814e+03,  LearnRate: 1.250e-01, Time taken : 0.254s\n",
      "\tEpoch 23, Step 0100, MSE: 1.205e+03,  LearnRate: 1.250e-01, Time taken : 1.076s\n",
      "\tEpoch 23, Step 0200, MSE: 1.392e+03,  LearnRate: 1.250e-01, Time taken : 0.908s\n",
      "\tEpoch 23, Step 0300, MSE: 3.394e+03,  LearnRate: 1.250e-01, Time taken : 1.052s\n",
      "\tEpoch 23, Step 0400, MSE: 1.017e+03,  LearnRate: 1.250e-01, Time taken : 1.103s\n",
      "\tEpoch 23, Step 0500, MSE: 5.990e+02,  LearnRate: 1.250e-01, Time taken : 1.020s\n",
      "\tEpoch 23, Step 0600, MSE: 5.545e+03,  LearnRate: 1.250e-01, Time taken : 1.039s\n",
      "\tEpoch 23, Step 0700, MSE: 1.180e+03,  LearnRate: 1.250e-01, Time taken : 0.953s\n",
      "\tEpoch 23, Step 0800, MSE: 2.125e+03,  LearnRate: 1.250e-01, Time taken : 0.939s\n",
      "\tEpoch 23, Step 0900, MSE: 3.323e+03,  LearnRate: 1.250e-01, Time taken : 0.959s\n",
      "\tEpoch 23, Step 1000, MSE: 2.750e+03,  LearnRate: 1.250e-01, Time taken : 1.033s\n",
      "\tEpoch 23, Step 1100, MSE: 3.897e+03,  LearnRate: 1.250e-01, Time taken : 0.967s\n",
      "\tEpoch 23, Step 1200, MSE: 1.223e+04,  LearnRate: 1.250e-01, Time taken : 1.050s\n",
      "\tEpoch 23, Step 1300, MSE: 3.361e+02,  LearnRate: 1.250e-01, Time taken : 0.988s\n",
      "\tEpoch 23, Step 1400, MSE: 3.233e+03,  LearnRate: 1.250e-01, Time taken : 0.936s\n",
      "\tEpoch 23, Step 1500, MSE: 7.934e+03,  LearnRate: 1.250e-01, Time taken : 0.916s\n",
      "\tEpoch 23, Step 1600, MSE: 6.318e+03,  LearnRate: 1.250e-01, Time taken : 1.067s\n",
      "\tEpoch 23, Step 1700, MSE: 1.896e+03,  LearnRate: 1.250e-01, Time taken : 1.151s\n",
      "\tEpoch 23, Step 1800, MSE: 1.919e+03,  LearnRate: 1.250e-01, Time taken : 1.032s\n",
      "\tEpoch 23, Step 1900, MSE: 2.504e+03,  LearnRate: 1.250e-01, Time taken : 0.923s\n",
      "\tEpoch 23, Step 2000, MSE: 3.221e+03,  LearnRate: 1.250e-01, Time taken : 1.095s\n",
      "\tEpoch 23, Step 2100, MSE: 4.635e+02,  LearnRate: 1.250e-01, Time taken : 1.107s\n",
      "\tEpoch 23, Step 2200, MSE: 2.400e+02,  LearnRate: 1.250e-01, Time taken : 1.097s\n",
      "\tEpoch 23, Step 2300, MSE: 3.139e+03,  LearnRate: 1.250e-01, Time taken : 0.995s\n",
      "\tEpoch 23, Step 2400, MSE: 8.191e+02,  LearnRate: 1.250e-01, Time taken : 0.940s\n",
      "\tEpoch 23, Step 2500, MSE: 3.163e+02,  LearnRate: 1.250e-01, Time taken : 1.132s\n",
      "\tEpoch 23, Step 2600, MSE: 9.964e+02,  LearnRate: 1.250e-01, Time taken : 1.220s\n",
      "\tEpoch 23, Step 2700, MSE: 2.025e+03,  LearnRate: 1.250e-01, Time taken : 1.253s\n",
      "\tEpoch 23, Step 2800, MSE: 2.038e+03,  LearnRate: 1.250e-01, Time taken : 1.203s\n",
      "\tEpoch 23, Step 2900, MSE: 3.795e+03,  LearnRate: 1.250e-01, Time taken : 1.238s\n",
      "Starting Epoch 24, with 2909 batches\n",
      "\tEpoch 24, Step 0000, MSE: 3.440e+03,  LearnRate: 1.250e-01, Time taken : 0.286s\n",
      "\tEpoch 24, Step 0100, MSE: 1.188e+01,  LearnRate: 1.250e-01, Time taken : 0.992s\n",
      "\tEpoch 24, Step 0200, MSE: 1.358e+04,  LearnRate: 1.250e-01, Time taken : 1.066s\n",
      "\tEpoch 24, Step 0300, MSE: 1.667e+03,  LearnRate: 1.250e-01, Time taken : 0.947s\n",
      "\tEpoch 24, Step 0400, MSE: 3.496e+02,  LearnRate: 1.250e-01, Time taken : 1.007s\n",
      "\tEpoch 24, Step 0500, MSE: 2.903e+03,  LearnRate: 1.250e-01, Time taken : 1.062s\n",
      "\tEpoch 24, Step 0600, MSE: 1.533e+03,  LearnRate: 1.250e-01, Time taken : 1.158s\n",
      "\tEpoch 24, Step 0700, MSE: 9.698e+02,  LearnRate: 1.250e-01, Time taken : 1.168s\n",
      "\tEpoch 24, Step 0800, MSE: 4.093e+03,  LearnRate: 1.250e-01, Time taken : 0.985s\n",
      "\tEpoch 24, Step 0900, MSE: 6.859e+01,  LearnRate: 1.250e-01, Time taken : 0.942s\n",
      "\tEpoch 24, Step 1000, MSE: 2.705e+03,  LearnRate: 1.250e-01, Time taken : 0.936s\n",
      "\tEpoch 24, Step 1100, MSE: 1.051e+03,  LearnRate: 1.250e-01, Time taken : 0.989s\n",
      "\tEpoch 24, Step 1200, MSE: 2.771e+02,  LearnRate: 1.250e-01, Time taken : 0.954s\n",
      "\tEpoch 24, Step 1300, MSE: 4.012e+03,  LearnRate: 1.250e-01, Time taken : 0.964s\n",
      "\tEpoch 24, Step 1400, MSE: 4.575e+02,  LearnRate: 1.250e-01, Time taken : 0.968s\n",
      "\tEpoch 24, Step 1500, MSE: 7.936e+02,  LearnRate: 1.250e-01, Time taken : 1.051s\n",
      "\tEpoch 24, Step 1600, MSE: 7.200e+03,  LearnRate: 1.250e-01, Time taken : 1.206s\n",
      "\tEpoch 24, Step 1700, MSE: 2.874e+03,  LearnRate: 1.250e-01, Time taken : 1.260s\n",
      "\tEpoch 24, Step 1800, MSE: 1.275e+03,  LearnRate: 1.250e-01, Time taken : 0.914s\n",
      "\tEpoch 24, Step 1900, MSE: 4.899e+02,  LearnRate: 1.250e-01, Time taken : 0.957s\n",
      "\tEpoch 24, Step 2000, MSE: 4.512e+02,  LearnRate: 1.250e-01, Time taken : 0.945s\n",
      "\tEpoch 24, Step 2100, MSE: 3.421e+02,  LearnRate: 1.250e-01, Time taken : 1.034s\n",
      "\tEpoch 24, Step 2200, MSE: 1.543e+03,  LearnRate: 1.250e-01, Time taken : 0.980s\n",
      "\tEpoch 24, Step 2300, MSE: 5.445e+03,  LearnRate: 1.250e-01, Time taken : 0.937s\n",
      "\tEpoch 24, Step 2400, MSE: 1.162e+03,  LearnRate: 1.250e-01, Time taken : 1.000s\n",
      "\tEpoch 24, Step 2500, MSE: 2.960e+02,  LearnRate: 1.250e-01, Time taken : 0.951s\n",
      "\tEpoch 24, Step 2600, MSE: 3.409e+04,  LearnRate: 1.250e-01, Time taken : 1.034s\n",
      "\tEpoch 24, Step 2700, MSE: 9.816e+03,  LearnRate: 1.250e-01, Time taken : 1.033s\n",
      "\tEpoch 24, Step 2800, MSE: 6.582e+02,  LearnRate: 1.250e-01, Time taken : 1.110s\n",
      "\tEpoch 24, Step 2900, MSE: 3.854e+02,  LearnRate: 1.250e-01, Time taken : 1.057s\n",
      "Starting Epoch 25, with 2909 batches\n",
      "\tEpoch 25, Step 0000, MSE: 7.238e+01,  LearnRate: 1.250e-01, Time taken : 0.272s\n",
      "\tEpoch 25, Step 0100, MSE: 2.300e+03,  LearnRate: 1.250e-01, Time taken : 1.016s\n",
      "\tEpoch 25, Step 0200, MSE: 3.821e+02,  LearnRate: 1.250e-01, Time taken : 0.997s\n",
      "\tEpoch 25, Step 0300, MSE: 2.147e+03,  LearnRate: 1.250e-01, Time taken : 1.004s\n",
      "\tEpoch 25, Step 0400, MSE: 3.781e+03,  LearnRate: 1.250e-01, Time taken : 1.088s\n",
      "\tEpoch 25, Step 0500, MSE: 4.419e+02,  LearnRate: 1.250e-01, Time taken : 1.110s\n",
      "\tEpoch 25, Step 0600, MSE: 2.147e+02,  LearnRate: 1.250e-01, Time taken : 1.116s\n",
      "\tEpoch 25, Step 0700, MSE: 2.926e+03,  LearnRate: 1.250e-01, Time taken : 1.105s\n",
      "\tEpoch 25, Step 0800, MSE: 3.128e+03,  LearnRate: 1.250e-01, Time taken : 1.139s\n",
      "\tEpoch 25, Step 0900, MSE: 4.667e+02,  LearnRate: 1.250e-01, Time taken : 1.014s\n",
      "\tEpoch 25, Step 1000, MSE: 6.939e+02,  LearnRate: 1.250e-01, Time taken : 0.936s\n",
      "\tEpoch 25, Step 1100, MSE: 3.412e+02,  LearnRate: 1.250e-01, Time taken : 1.017s\n",
      "\tEpoch 25, Step 1200, MSE: 6.631e+03,  LearnRate: 1.250e-01, Time taken : 0.982s\n",
      "\tEpoch 25, Step 1300, MSE: 2.795e+01,  LearnRate: 1.250e-01, Time taken : 0.961s\n",
      "\tEpoch 25, Step 1400, MSE: 1.391e+03,  LearnRate: 1.250e-01, Time taken : 0.946s\n",
      "\tEpoch 25, Step 1500, MSE: 6.824e+02,  LearnRate: 1.250e-01, Time taken : 0.964s\n",
      "\tEpoch 25, Step 1600, MSE: 1.007e+04,  LearnRate: 1.250e-01, Time taken : 1.061s\n",
      "\tEpoch 25, Step 1700, MSE: 9.715e+01,  LearnRate: 1.250e-01, Time taken : 0.974s\n",
      "\tEpoch 25, Step 1800, MSE: 6.749e+02,  LearnRate: 1.250e-01, Time taken : 0.984s\n",
      "\tEpoch 25, Step 1900, MSE: 7.791e+03,  LearnRate: 1.250e-01, Time taken : 0.971s\n",
      "\tEpoch 25, Step 2000, MSE: 2.589e+03,  LearnRate: 1.250e-01, Time taken : 0.998s\n",
      "\tEpoch 25, Step 2100, MSE: 9.388e+02,  LearnRate: 1.250e-01, Time taken : 0.930s\n",
      "\tEpoch 25, Step 2200, MSE: 9.542e+02,  LearnRate: 1.250e-01, Time taken : 0.941s\n",
      "\tEpoch 25, Step 2300, MSE: 1.039e+02,  LearnRate: 1.250e-01, Time taken : 0.965s\n",
      "\tEpoch 25, Step 2400, MSE: 5.070e+03,  LearnRate: 1.250e-01, Time taken : 0.983s\n",
      "\tEpoch 25, Step 2500, MSE: 1.426e+03,  LearnRate: 1.250e-01, Time taken : 0.999s\n",
      "\tEpoch 25, Step 2600, MSE: 9.804e+03,  LearnRate: 1.250e-01, Time taken : 1.048s\n",
      "\tEpoch 25, Step 2700, MSE: 6.651e+02,  LearnRate: 1.250e-01, Time taken : 0.907s\n",
      "\tEpoch 25, Step 2800, MSE: 1.277e+03,  LearnRate: 1.250e-01, Time taken : 1.072s\n",
      "\tEpoch 25, Step 2900, MSE: 2.419e+03,  LearnRate: 1.250e-01, Time taken : 1.075s\n",
      "Starting Epoch 26, with 2909 batches\n",
      "\tEpoch 26, Step 0000, MSE: 2.267e+02,  LearnRate: 1.250e-01, Time taken : 0.256s\n",
      "\tEpoch 26, Step 0100, MSE: 3.671e+03,  LearnRate: 1.250e-01, Time taken : 1.011s\n",
      "\tEpoch 26, Step 0200, MSE: 1.658e+03,  LearnRate: 1.250e-01, Time taken : 0.914s\n",
      "\tEpoch 26, Step 0300, MSE: 4.555e+03,  LearnRate: 1.250e-01, Time taken : 1.033s\n",
      "\tEpoch 26, Step 0400, MSE: 1.172e+03,  LearnRate: 1.250e-01, Time taken : 1.005s\n",
      "\tEpoch 26, Step 0500, MSE: 7.758e+03,  LearnRate: 1.250e-01, Time taken : 0.991s\n",
      "\tEpoch 26, Step 0600, MSE: 3.279e+02,  LearnRate: 1.250e-01, Time taken : 0.949s\n",
      "\tEpoch 26, Step 0700, MSE: 1.502e+04,  LearnRate: 1.250e-01, Time taken : 0.979s\n",
      "\tEpoch 26, Step 0800, MSE: 1.117e+03,  LearnRate: 1.250e-01, Time taken : 0.978s\n",
      "\tEpoch 26, Step 0900, MSE: 1.193e+02,  LearnRate: 1.250e-01, Time taken : 1.083s\n",
      "\tEpoch 26, Step 1000, MSE: 8.686e+03,  LearnRate: 1.250e-01, Time taken : 0.978s\n",
      "\tEpoch 26, Step 1100, MSE: 9.353e+01,  LearnRate: 1.250e-01, Time taken : 0.905s\n",
      "\tEpoch 26, Step 1200, MSE: 1.273e+03,  LearnRate: 1.250e-01, Time taken : 0.877s\n",
      "\tEpoch 26, Step 1300, MSE: 9.995e+02,  LearnRate: 1.250e-01, Time taken : 0.937s\n",
      "\tEpoch 26, Step 1400, MSE: 2.152e+03,  LearnRate: 1.250e-01, Time taken : 0.997s\n",
      "\tEpoch 26, Step 1500, MSE: 8.601e+03,  LearnRate: 1.250e-01, Time taken : 0.943s\n",
      "\tEpoch 26, Step 1600, MSE: 1.507e+03,  LearnRate: 1.250e-01, Time taken : 1.075s\n",
      "\tEpoch 26, Step 1700, MSE: 2.225e+02,  LearnRate: 1.250e-01, Time taken : 1.247s\n",
      "\tEpoch 26, Step 1800, MSE: 3.127e+03,  LearnRate: 1.250e-01, Time taken : 1.064s\n",
      "\tEpoch 26, Step 1900, MSE: 6.959e+02,  LearnRate: 1.250e-01, Time taken : 0.944s\n",
      "\tEpoch 26, Step 2000, MSE: 5.930e+03,  LearnRate: 1.250e-01, Time taken : 1.070s\n",
      "\tEpoch 26, Step 2100, MSE: 9.930e+03,  LearnRate: 1.250e-01, Time taken : 0.910s\n",
      "\tEpoch 26, Step 2200, MSE: 1.144e+03,  LearnRate: 1.250e-01, Time taken : 1.007s\n",
      "\tEpoch 26, Step 2300, MSE: 3.389e+03,  LearnRate: 1.250e-01, Time taken : 1.092s\n",
      "\tEpoch 26, Step 2400, MSE: 2.432e+03,  LearnRate: 1.250e-01, Time taken : 1.019s\n",
      "\tEpoch 26, Step 2500, MSE: 2.638e+03,  LearnRate: 1.250e-01, Time taken : 1.008s\n",
      "\tEpoch 26, Step 2600, MSE: 2.376e+02,  LearnRate: 1.250e-01, Time taken : 0.995s\n",
      "\tEpoch 26, Step 2700, MSE: 3.065e+03,  LearnRate: 1.250e-01, Time taken : 0.938s\n",
      "\tEpoch 26, Step 2800, MSE: 1.749e+04,  LearnRate: 1.250e-01, Time taken : 0.994s\n",
      "\tEpoch 26, Step 2900, MSE: 3.807e+03,  LearnRate: 1.250e-01, Time taken : 0.960s\n",
      "Starting Epoch 27, with 2909 batches\n",
      "\tEpoch 27, Step 0000, MSE: 1.788e+04,  LearnRate: 1.250e-01, Time taken : 0.255s\n",
      "\tEpoch 27, Step 0100, MSE: 1.168e+03,  LearnRate: 1.250e-01, Time taken : 0.986s\n",
      "\tEpoch 27, Step 0200, MSE: 8.710e+03,  LearnRate: 1.250e-01, Time taken : 1.047s\n",
      "\tEpoch 27, Step 0300, MSE: 2.199e+03,  LearnRate: 1.250e-01, Time taken : 1.114s\n",
      "\tEpoch 27, Step 0400, MSE: 2.759e+02,  LearnRate: 1.250e-01, Time taken : 1.131s\n",
      "\tEpoch 27, Step 0500, MSE: 6.891e+03,  LearnRate: 1.250e-01, Time taken : 1.184s\n",
      "\tEpoch 27, Step 0600, MSE: 6.464e+00,  LearnRate: 1.250e-01, Time taken : 1.202s\n",
      "\tEpoch 27, Step 0700, MSE: 8.482e+00,  LearnRate: 1.250e-01, Time taken : 1.170s\n",
      "\tEpoch 27, Step 0800, MSE: 7.914e+00,  LearnRate: 1.250e-01, Time taken : 1.002s\n",
      "\tEpoch 27, Step 0900, MSE: 7.381e+00,  LearnRate: 1.250e-01, Time taken : 1.004s\n",
      "\tEpoch 27, Step 1000, MSE: 7.741e+00,  LearnRate: 1.250e-01, Time taken : 1.002s\n",
      "\tEpoch 27, Step 1100, MSE: 4.655e+00,  LearnRate: 1.250e-01, Time taken : 0.991s\n",
      "\tEpoch 27, Step 1200, MSE: 6.608e+00,  LearnRate: 1.250e-01, Time taken : 1.012s\n",
      "\tEpoch 27, Step 1300, MSE: 2.809e+01,  LearnRate: 1.250e-01, Time taken : 0.972s\n",
      "\tEpoch 27, Step 1400, MSE: 2.184e+02,  LearnRate: 1.250e-01, Time taken : 0.985s\n",
      "\tEpoch 27, Step 1500, MSE: 3.556e+03,  LearnRate: 1.250e-01, Time taken : 0.964s\n",
      "\tEpoch 27, Step 1600, MSE: 5.807e+02,  LearnRate: 1.250e-01, Time taken : 0.940s\n",
      "\tEpoch 27, Step 1700, MSE: 1.280e+04,  LearnRate: 1.250e-01, Time taken : 0.904s\n",
      "\tEpoch 27, Step 1800, MSE: 3.507e+00,  LearnRate: 1.250e-01, Time taken : 0.952s\n",
      "\tEpoch 27, Step 1900, MSE: 4.674e+02,  LearnRate: 1.250e-01, Time taken : 1.000s\n",
      "\tEpoch 27, Step 2000, MSE: 2.982e+02,  LearnRate: 1.250e-01, Time taken : 1.102s\n",
      "\tEpoch 27, Step 2100, MSE: 5.753e+01,  LearnRate: 1.250e-01, Time taken : 1.038s\n",
      "\tEpoch 27, Step 2200, MSE: 2.773e+03,  LearnRate: 1.250e-01, Time taken : 0.961s\n",
      "\tEpoch 27, Step 2300, MSE: 1.762e+04,  LearnRate: 1.250e-01, Time taken : 0.947s\n",
      "\tEpoch 27, Step 2400, MSE: 1.479e+03,  LearnRate: 1.250e-01, Time taken : 1.038s\n",
      "\tEpoch 27, Step 2500, MSE: 8.329e+02,  LearnRate: 1.250e-01, Time taken : 1.018s\n",
      "\tEpoch 27, Step 2600, MSE: 2.115e+02,  LearnRate: 1.250e-01, Time taken : 0.933s\n",
      "\tEpoch 27, Step 2700, MSE: 9.891e+02,  LearnRate: 1.250e-01, Time taken : 0.934s\n",
      "\tEpoch 27, Step 2800, MSE: 3.903e+02,  LearnRate: 1.250e-01, Time taken : 1.043s\n",
      "\tEpoch 27, Step 2900, MSE: 2.254e+03,  LearnRate: 1.250e-01, Time taken : 1.132s\n",
      "Starting Epoch 28, with 2909 batches\n",
      "\tEpoch 28, Step 0000, MSE: 3.080e+03,  LearnRate: 1.250e-01, Time taken : 0.293s\n",
      "\tEpoch 28, Step 0100, MSE: 1.183e+03,  LearnRate: 1.250e-01, Time taken : 1.190s\n",
      "\tEpoch 28, Step 0200, MSE: 3.358e+03,  LearnRate: 1.250e-01, Time taken : 0.998s\n",
      "\tEpoch 28, Step 0300, MSE: 2.154e+03,  LearnRate: 1.250e-01, Time taken : 0.992s\n",
      "\tEpoch 28, Step 0400, MSE: 3.767e+03,  LearnRate: 1.250e-01, Time taken : 1.045s\n",
      "\tEpoch 28, Step 0500, MSE: 1.601e+04,  LearnRate: 1.250e-01, Time taken : 0.963s\n",
      "\tEpoch 28, Step 0600, MSE: 3.317e+03,  LearnRate: 1.250e-01, Time taken : 0.967s\n",
      "\tEpoch 28, Step 0700, MSE: 1.580e+03,  LearnRate: 1.250e-01, Time taken : 0.997s\n",
      "\tEpoch 28, Step 0800, MSE: 2.705e+02,  LearnRate: 1.250e-01, Time taken : 0.960s\n",
      "\tEpoch 28, Step 0900, MSE: 2.647e+02,  LearnRate: 1.250e-01, Time taken : 0.980s\n",
      "\tEpoch 28, Step 1000, MSE: 5.665e+02,  LearnRate: 1.250e-01, Time taken : 1.051s\n",
      "\tEpoch 28, Step 1100, MSE: 5.026e+01,  LearnRate: 1.250e-01, Time taken : 0.980s\n",
      "\tEpoch 28, Step 1200, MSE: 1.514e+03,  LearnRate: 1.250e-01, Time taken : 0.912s\n",
      "\tEpoch 28, Step 1300, MSE: 9.193e+02,  LearnRate: 1.250e-01, Time taken : 1.023s\n",
      "\tEpoch 28, Step 1400, MSE: 5.405e+03,  LearnRate: 1.250e-01, Time taken : 0.999s\n",
      "\tEpoch 28, Step 1500, MSE: 6.332e+03,  LearnRate: 1.250e-01, Time taken : 0.986s\n",
      "\tEpoch 28, Step 1600, MSE: 3.482e+02,  LearnRate: 1.250e-01, Time taken : 0.971s\n",
      "\tEpoch 28, Step 1700, MSE: 1.746e+03,  LearnRate: 1.250e-01, Time taken : 1.029s\n",
      "\tEpoch 28, Step 1800, MSE: 3.886e+02,  LearnRate: 1.250e-01, Time taken : 0.955s\n",
      "\tEpoch 28, Step 1900, MSE: 2.104e+04,  LearnRate: 1.250e-01, Time taken : 0.920s\n",
      "\tEpoch 28, Step 2000, MSE: 1.122e+04,  LearnRate: 1.250e-01, Time taken : 0.968s\n",
      "\tEpoch 28, Step 2100, MSE: 2.551e+02,  LearnRate: 1.250e-01, Time taken : 0.940s\n",
      "\tEpoch 28, Step 2200, MSE: 6.493e+03,  LearnRate: 1.250e-01, Time taken : 0.926s\n",
      "\tEpoch 28, Step 2300, MSE: 6.368e+02,  LearnRate: 1.250e-01, Time taken : 0.883s\n",
      "\tEpoch 28, Step 2400, MSE: 1.927e+03,  LearnRate: 1.250e-01, Time taken : 0.894s\n",
      "\tEpoch 28, Step 2500, MSE: 6.359e+02,  LearnRate: 1.250e-01, Time taken : 1.019s\n",
      "\tEpoch 28, Step 2600, MSE: 9.825e+02,  LearnRate: 1.250e-01, Time taken : 0.982s\n",
      "\tEpoch 28, Step 2700, MSE: 2.925e+03,  LearnRate: 1.250e-01, Time taken : 0.965s\n",
      "\tEpoch 28, Step 2800, MSE: 3.663e+02,  LearnRate: 1.250e-01, Time taken : 0.961s\n",
      "\tEpoch 28, Step 2900, MSE: 1.463e+03,  LearnRate: 1.250e-01, Time taken : 0.943s\n",
      "Starting Epoch 29, with 2909 batches\n",
      "\tEpoch 29, Step 0000, MSE: 3.503e+03,  LearnRate: 1.250e-01, Time taken : 0.339s\n",
      "\tEpoch 29, Step 0100, MSE: 1.628e+02,  LearnRate: 1.250e-01, Time taken : 1.256s\n",
      "\tEpoch 29, Step 0200, MSE: 7.875e+02,  LearnRate: 1.250e-01, Time taken : 1.185s\n",
      "\tEpoch 29, Step 0300, MSE: 1.211e+03,  LearnRate: 1.250e-01, Time taken : 1.103s\n",
      "\tEpoch 29, Step 0400, MSE: 5.312e+02,  LearnRate: 1.250e-01, Time taken : 0.936s\n",
      "\tEpoch 29, Step 0500, MSE: 9.798e+02,  LearnRate: 1.250e-01, Time taken : 1.043s\n",
      "\tEpoch 29, Step 0600, MSE: 2.210e+01,  LearnRate: 1.250e-01, Time taken : 1.033s\n",
      "\tEpoch 29, Step 0700, MSE: 2.816e+02,  LearnRate: 1.250e-01, Time taken : 1.040s\n",
      "\tEpoch 29, Step 0800, MSE: 5.540e+02,  LearnRate: 1.250e-01, Time taken : 0.910s\n",
      "\tEpoch 29, Step 0900, MSE: 1.229e+00,  LearnRate: 1.250e-01, Time taken : 0.896s\n",
      "\tEpoch 29, Step 1000, MSE: 1.034e+00,  LearnRate: 1.250e-01, Time taken : 0.902s\n",
      "\tEpoch 29, Step 1100, MSE: 3.933e+00,  LearnRate: 1.250e-01, Time taken : 0.961s\n",
      "\tEpoch 29, Step 1200, MSE: 1.543e+00,  LearnRate: 1.250e-01, Time taken : 1.048s\n",
      "\tEpoch 29, Step 1300, MSE: 8.929e-01,  LearnRate: 1.250e-01, Time taken : 1.034s\n",
      "\tEpoch 29, Step 1400, MSE: 9.171e+00,  LearnRate: 1.250e-01, Time taken : 0.997s\n",
      "\tEpoch 29, Step 1500, MSE: 5.282e+00,  LearnRate: 1.250e-01, Time taken : 0.996s\n",
      "\tEpoch 29, Step 1600, MSE: 1.068e+00,  LearnRate: 1.250e-01, Time taken : 0.939s\n",
      "\tEpoch 29, Step 1700, MSE: 1.538e+01,  LearnRate: 1.250e-01, Time taken : 0.932s\n",
      "\tEpoch 29, Step 1800, MSE: 2.472e+00,  LearnRate: 1.250e-01, Time taken : 1.022s\n",
      "\tEpoch 29, Step 1900, MSE: 9.505e-01,  LearnRate: 1.250e-01, Time taken : 1.013s\n",
      "\tEpoch 29, Step 2000, MSE: 1.686e+01,  LearnRate: 1.250e-01, Time taken : 0.932s\n",
      "\tEpoch 29, Step 2100, MSE: 1.166e+01,  LearnRate: 1.250e-01, Time taken : 1.037s\n",
      "\tEpoch 29, Step 2200, MSE: 4.789e+00,  LearnRate: 1.250e-01, Time taken : 1.029s\n",
      "\tEpoch 29, Step 2300, MSE: 1.231e+00,  LearnRate: 1.250e-01, Time taken : 0.915s\n",
      "\tEpoch 29, Step 2400, MSE: 3.711e+00,  LearnRate: 1.250e-01, Time taken : 1.005s\n",
      "\tEpoch 29, Step 2500, MSE: 1.755e+01,  LearnRate: 1.250e-01, Time taken : 0.934s\n",
      "\tEpoch 29, Step 2600, MSE: 1.621e+01,  LearnRate: 1.250e-01, Time taken : 0.974s\n",
      "\tEpoch 29, Step 2700, MSE: 1.113e+02,  LearnRate: 1.250e-01, Time taken : 1.130s\n",
      "\tEpoch 29, Step 2800, MSE: 1.431e+00,  LearnRate: 1.250e-01, Time taken : 0.900s\n",
      "\tEpoch 29, Step 2900, MSE: 1.528e+01,  LearnRate: 1.250e-01, Time taken : 0.924s\n",
      "Starting Epoch 30, with 2909 batches\n",
      "\tEpoch 30, Step 0000, MSE: 1.361e+01,  LearnRate: 6.250e-02, Time taken : 0.291s\n",
      "\tEpoch 30, Step 0100, MSE: 1.278e+00,  LearnRate: 6.250e-02, Time taken : 0.885s\n",
      "\tEpoch 30, Step 0200, MSE: 8.011e+00,  LearnRate: 6.250e-02, Time taken : 1.098s\n",
      "\tEpoch 30, Step 0300, MSE: 5.865e-01,  LearnRate: 6.250e-02, Time taken : 1.015s\n",
      "\tEpoch 30, Step 0400, MSE: 8.900e-01,  LearnRate: 6.250e-02, Time taken : 0.963s\n",
      "\tEpoch 30, Step 0500, MSE: 2.947e+00,  LearnRate: 6.250e-02, Time taken : 0.943s\n",
      "\tEpoch 30, Step 0600, MSE: 1.037e+00,  LearnRate: 6.250e-02, Time taken : 1.025s\n",
      "\tEpoch 30, Step 0700, MSE: 7.309e-01,  LearnRate: 6.250e-02, Time taken : 1.016s\n",
      "\tEpoch 30, Step 0800, MSE: 7.628e-01,  LearnRate: 6.250e-02, Time taken : 0.965s\n",
      "\tEpoch 30, Step 0900, MSE: 1.117e+01,  LearnRate: 6.250e-02, Time taken : 0.983s\n",
      "\tEpoch 30, Step 1000, MSE: 2.144e+00,  LearnRate: 6.250e-02, Time taken : 0.978s\n",
      "\tEpoch 30, Step 1100, MSE: 1.182e+00,  LearnRate: 6.250e-02, Time taken : 0.986s\n",
      "\tEpoch 30, Step 1200, MSE: 1.273e+01,  LearnRate: 6.250e-02, Time taken : 0.911s\n",
      "\tEpoch 30, Step 1300, MSE: 6.301e+00,  LearnRate: 6.250e-02, Time taken : 0.931s\n",
      "\tEpoch 30, Step 1400, MSE: 1.573e+01,  LearnRate: 6.250e-02, Time taken : 0.935s\n",
      "\tEpoch 30, Step 1500, MSE: 1.012e+02,  LearnRate: 6.250e-02, Time taken : 0.948s\n",
      "\tEpoch 30, Step 1600, MSE: 2.867e+00,  LearnRate: 6.250e-02, Time taken : 1.030s\n",
      "\tEpoch 30, Step 1700, MSE: 4.803e+01,  LearnRate: 6.250e-02, Time taken : 0.970s\n",
      "\tEpoch 30, Step 1800, MSE: 4.379e+01,  LearnRate: 6.250e-02, Time taken : 0.949s\n",
      "\tEpoch 30, Step 1900, MSE: 6.971e+02,  LearnRate: 6.250e-02, Time taken : 0.994s\n",
      "\tEpoch 30, Step 2000, MSE: 1.589e+02,  LearnRate: 6.250e-02, Time taken : 0.883s\n",
      "\tEpoch 30, Step 2100, MSE: 1.837e+02,  LearnRate: 6.250e-02, Time taken : 0.913s\n",
      "\tEpoch 30, Step 2200, MSE: 2.816e+01,  LearnRate: 6.250e-02, Time taken : 0.958s\n",
      "\tEpoch 30, Step 2300, MSE: 4.396e+00,  LearnRate: 6.250e-02, Time taken : 1.060s\n",
      "\tEpoch 30, Step 2400, MSE: 2.666e+02,  LearnRate: 6.250e-02, Time taken : 0.921s\n",
      "\tEpoch 30, Step 2500, MSE: 1.630e+03,  LearnRate: 6.250e-02, Time taken : 0.985s\n",
      "\tEpoch 30, Step 2600, MSE: 2.389e+01,  LearnRate: 6.250e-02, Time taken : 0.945s\n",
      "\tEpoch 30, Step 2700, MSE: 2.526e+02,  LearnRate: 6.250e-02, Time taken : 1.023s\n",
      "\tEpoch 30, Step 2800, MSE: 2.417e+02,  LearnRate: 6.250e-02, Time taken : 1.011s\n",
      "\tEpoch 30, Step 2900, MSE: 9.681e+01,  LearnRate: 6.250e-02, Time taken : 1.036s\n",
      "Starting Epoch 31, with 2909 batches\n",
      "\tEpoch 31, Step 0000, MSE: 2.987e+01,  LearnRate: 6.250e-02, Time taken : 0.243s\n",
      "\tEpoch 31, Step 0100, MSE: 1.448e+01,  LearnRate: 6.250e-02, Time taken : 1.273s\n",
      "\tEpoch 31, Step 0200, MSE: 1.391e+03,  LearnRate: 6.250e-02, Time taken : 1.278s\n",
      "\tEpoch 31, Step 0300, MSE: 1.371e+03,  LearnRate: 6.250e-02, Time taken : 1.243s\n",
      "\tEpoch 31, Step 0400, MSE: 9.602e+01,  LearnRate: 6.250e-02, Time taken : 1.139s\n",
      "\tEpoch 31, Step 0500, MSE: 2.702e+03,  LearnRate: 6.250e-02, Time taken : 1.233s\n",
      "\tEpoch 31, Step 0600, MSE: 1.264e+02,  LearnRate: 6.250e-02, Time taken : 1.163s\n",
      "\tEpoch 31, Step 0700, MSE: 1.349e+03,  LearnRate: 6.250e-02, Time taken : 1.174s\n",
      "\tEpoch 31, Step 0800, MSE: 2.114e+02,  LearnRate: 6.250e-02, Time taken : 1.213s\n",
      "\tEpoch 31, Step 0900, MSE: 2.850e+02,  LearnRate: 6.250e-02, Time taken : 1.156s\n",
      "\tEpoch 31, Step 1000, MSE: 1.774e+03,  LearnRate: 6.250e-02, Time taken : 0.957s\n",
      "\tEpoch 31, Step 1100, MSE: 1.621e+00,  LearnRate: 6.250e-02, Time taken : 1.073s\n",
      "\tEpoch 31, Step 1200, MSE: 1.832e+03,  LearnRate: 6.250e-02, Time taken : 1.041s\n",
      "\tEpoch 31, Step 1300, MSE: 2.248e+01,  LearnRate: 6.250e-02, Time taken : 1.097s\n",
      "\tEpoch 31, Step 1400, MSE: 2.951e+02,  LearnRate: 6.250e-02, Time taken : 1.118s\n",
      "\tEpoch 31, Step 1500, MSE: 5.432e+00,  LearnRate: 6.250e-02, Time taken : 0.967s\n",
      "\tEpoch 31, Step 1600, MSE: 6.752e+01,  LearnRate: 6.250e-02, Time taken : 0.965s\n",
      "\tEpoch 31, Step 1700, MSE: 4.180e+03,  LearnRate: 6.250e-02, Time taken : 0.927s\n",
      "\tEpoch 31, Step 1800, MSE: 1.959e+01,  LearnRate: 6.250e-02, Time taken : 0.951s\n",
      "\tEpoch 31, Step 1900, MSE: 1.662e+02,  LearnRate: 6.250e-02, Time taken : 0.955s\n",
      "\tEpoch 31, Step 2000, MSE: 1.154e+03,  LearnRate: 6.250e-02, Time taken : 0.951s\n",
      "\tEpoch 31, Step 2100, MSE: 3.165e+02,  LearnRate: 6.250e-02, Time taken : 0.990s\n",
      "\tEpoch 31, Step 2200, MSE: 1.303e+03,  LearnRate: 6.250e-02, Time taken : 0.945s\n",
      "\tEpoch 31, Step 2300, MSE: 1.096e+03,  LearnRate: 6.250e-02, Time taken : 0.944s\n",
      "\tEpoch 31, Step 2400, MSE: 3.032e+02,  LearnRate: 6.250e-02, Time taken : 0.992s\n",
      "\tEpoch 31, Step 2500, MSE: 4.852e+02,  LearnRate: 6.250e-02, Time taken : 0.985s\n",
      "\tEpoch 31, Step 2600, MSE: 6.428e+02,  LearnRate: 6.250e-02, Time taken : 0.884s\n",
      "\tEpoch 31, Step 2700, MSE: 8.265e+02,  LearnRate: 6.250e-02, Time taken : 0.998s\n",
      "\tEpoch 31, Step 2800, MSE: 8.510e+02,  LearnRate: 6.250e-02, Time taken : 0.969s\n",
      "\tEpoch 31, Step 2900, MSE: 2.057e+02,  LearnRate: 6.250e-02, Time taken : 0.961s\n",
      "Starting Epoch 32, with 2909 batches\n",
      "\tEpoch 32, Step 0000, MSE: 9.764e+00,  LearnRate: 6.250e-02, Time taken : 0.268s\n",
      "\tEpoch 32, Step 0100, MSE: 7.994e+02,  LearnRate: 6.250e-02, Time taken : 0.901s\n",
      "\tEpoch 32, Step 0200, MSE: 3.170e+03,  LearnRate: 6.250e-02, Time taken : 1.018s\n",
      "\tEpoch 32, Step 0300, MSE: 5.619e+01,  LearnRate: 6.250e-02, Time taken : 0.881s\n",
      "\tEpoch 32, Step 0400, MSE: 1.828e+02,  LearnRate: 6.250e-02, Time taken : 0.899s\n",
      "\tEpoch 32, Step 0500, MSE: 5.647e+00,  LearnRate: 6.250e-02, Time taken : 1.065s\n",
      "\tEpoch 32, Step 0600, MSE: 9.749e+01,  LearnRate: 6.250e-02, Time taken : 1.142s\n",
      "\tEpoch 32, Step 0700, MSE: 5.438e+01,  LearnRate: 6.250e-02, Time taken : 1.053s\n",
      "\tEpoch 32, Step 0800, MSE: 5.494e+01,  LearnRate: 6.250e-02, Time taken : 0.945s\n",
      "\tEpoch 32, Step 0900, MSE: 4.040e+01,  LearnRate: 6.250e-02, Time taken : 0.962s\n",
      "\tEpoch 32, Step 1000, MSE: 8.195e+02,  LearnRate: 6.250e-02, Time taken : 1.081s\n",
      "\tEpoch 32, Step 1100, MSE: 3.473e+02,  LearnRate: 6.250e-02, Time taken : 0.955s\n",
      "\tEpoch 32, Step 1200, MSE: 4.956e+02,  LearnRate: 6.250e-02, Time taken : 0.967s\n",
      "\tEpoch 32, Step 1300, MSE: 1.300e+01,  LearnRate: 6.250e-02, Time taken : 0.939s\n",
      "\tEpoch 32, Step 1400, MSE: 6.822e+01,  LearnRate: 6.250e-02, Time taken : 0.988s\n",
      "\tEpoch 32, Step 1500, MSE: 4.594e+01,  LearnRate: 6.250e-02, Time taken : 0.942s\n",
      "\tEpoch 32, Step 1600, MSE: 9.759e+01,  LearnRate: 6.250e-02, Time taken : 0.967s\n",
      "\tEpoch 32, Step 1700, MSE: 1.542e+01,  LearnRate: 6.250e-02, Time taken : 0.948s\n",
      "\tEpoch 32, Step 1800, MSE: 9.332e+01,  LearnRate: 6.250e-02, Time taken : 0.974s\n",
      "\tEpoch 32, Step 1900, MSE: 1.202e+03,  LearnRate: 6.250e-02, Time taken : 0.963s\n",
      "\tEpoch 32, Step 2000, MSE: 1.565e+02,  LearnRate: 6.250e-02, Time taken : 0.953s\n",
      "\tEpoch 32, Step 2100, MSE: 1.879e+03,  LearnRate: 6.250e-02, Time taken : 0.985s\n",
      "\tEpoch 32, Step 2200, MSE: 6.520e+01,  LearnRate: 6.250e-02, Time taken : 0.965s\n",
      "\tEpoch 32, Step 2300, MSE: 2.096e+02,  LearnRate: 6.250e-02, Time taken : 1.050s\n",
      "\tEpoch 32, Step 2400, MSE: 2.463e+00,  LearnRate: 6.250e-02, Time taken : 1.021s\n",
      "\tEpoch 32, Step 2500, MSE: 2.520e+03,  LearnRate: 6.250e-02, Time taken : 0.899s\n",
      "\tEpoch 32, Step 2600, MSE: 4.251e+02,  LearnRate: 6.250e-02, Time taken : 1.057s\n",
      "\tEpoch 32, Step 2700, MSE: 1.415e+03,  LearnRate: 6.250e-02, Time taken : 0.951s\n",
      "\tEpoch 32, Step 2800, MSE: 7.329e+02,  LearnRate: 6.250e-02, Time taken : 0.968s\n",
      "\tEpoch 32, Step 2900, MSE: 1.002e+03,  LearnRate: 6.250e-02, Time taken : 0.931s\n",
      "Starting Epoch 33, with 2909 batches\n",
      "\tEpoch 33, Step 0000, MSE: 5.411e+02,  LearnRate: 6.250e-02, Time taken : 0.245s\n",
      "\tEpoch 33, Step 0100, MSE: 8.228e+01,  LearnRate: 6.250e-02, Time taken : 0.944s\n",
      "\tEpoch 33, Step 0200, MSE: 2.902e+03,  LearnRate: 6.250e-02, Time taken : 0.952s\n",
      "\tEpoch 33, Step 0300, MSE: 3.828e+02,  LearnRate: 6.250e-02, Time taken : 0.959s\n",
      "\tEpoch 33, Step 0400, MSE: 3.591e+02,  LearnRate: 6.250e-02, Time taken : 1.071s\n",
      "\tEpoch 33, Step 0500, MSE: 4.299e+00,  LearnRate: 6.250e-02, Time taken : 1.074s\n",
      "\tEpoch 33, Step 0600, MSE: 2.663e+02,  LearnRate: 6.250e-02, Time taken : 0.957s\n",
      "\tEpoch 33, Step 0700, MSE: 8.454e+02,  LearnRate: 6.250e-02, Time taken : 0.981s\n",
      "\tEpoch 33, Step 0800, MSE: 1.679e+03,  LearnRate: 6.250e-02, Time taken : 0.993s\n",
      "\tEpoch 33, Step 0900, MSE: 1.023e+02,  LearnRate: 6.250e-02, Time taken : 0.951s\n",
      "\tEpoch 33, Step 1000, MSE: 6.361e+02,  LearnRate: 6.250e-02, Time taken : 0.883s\n",
      "\tEpoch 33, Step 1100, MSE: 3.491e+02,  LearnRate: 6.250e-02, Time taken : 0.940s\n",
      "\tEpoch 33, Step 1200, MSE: 9.026e+02,  LearnRate: 6.250e-02, Time taken : 0.972s\n",
      "\tEpoch 33, Step 1300, MSE: 8.966e+02,  LearnRate: 6.250e-02, Time taken : 1.003s\n",
      "\tEpoch 33, Step 1400, MSE: 4.173e+02,  LearnRate: 6.250e-02, Time taken : 1.014s\n",
      "\tEpoch 33, Step 1500, MSE: 2.636e+02,  LearnRate: 6.250e-02, Time taken : 0.985s\n",
      "\tEpoch 33, Step 1600, MSE: 1.605e+02,  LearnRate: 6.250e-02, Time taken : 0.910s\n",
      "\tEpoch 33, Step 1700, MSE: 1.405e+03,  LearnRate: 6.250e-02, Time taken : 0.915s\n",
      "\tEpoch 33, Step 1800, MSE: 2.910e+02,  LearnRate: 6.250e-02, Time taken : 1.017s\n",
      "\tEpoch 33, Step 1900, MSE: 3.918e+02,  LearnRate: 6.250e-02, Time taken : 0.941s\n",
      "\tEpoch 33, Step 2000, MSE: 5.838e+02,  LearnRate: 6.250e-02, Time taken : 0.933s\n",
      "\tEpoch 33, Step 2100, MSE: 3.881e+02,  LearnRate: 6.250e-02, Time taken : 0.976s\n",
      "\tEpoch 33, Step 2200, MSE: 1.469e+03,  LearnRate: 6.250e-02, Time taken : 0.896s\n",
      "\tEpoch 33, Step 2300, MSE: 1.450e+03,  LearnRate: 6.250e-02, Time taken : 1.092s\n",
      "\tEpoch 33, Step 2400, MSE: 3.934e+03,  LearnRate: 6.250e-02, Time taken : 1.009s\n",
      "\tEpoch 33, Step 2500, MSE: 6.181e+01,  LearnRate: 6.250e-02, Time taken : 0.945s\n",
      "\tEpoch 33, Step 2600, MSE: 2.133e+02,  LearnRate: 6.250e-02, Time taken : 1.055s\n",
      "\tEpoch 33, Step 2700, MSE: 2.818e+01,  LearnRate: 6.250e-02, Time taken : 1.033s\n",
      "\tEpoch 33, Step 2800, MSE: 1.112e+02,  LearnRate: 6.250e-02, Time taken : 1.039s\n",
      "\tEpoch 33, Step 2900, MSE: 1.467e+02,  LearnRate: 6.250e-02, Time taken : 1.057s\n",
      "Starting Epoch 34, with 2909 batches\n",
      "\tEpoch 34, Step 0000, MSE: 7.726e+02,  LearnRate: 6.250e-02, Time taken : 0.262s\n",
      "\tEpoch 34, Step 0100, MSE: 3.097e+02,  LearnRate: 6.250e-02, Time taken : 0.953s\n",
      "\tEpoch 34, Step 0200, MSE: 4.263e+02,  LearnRate: 6.250e-02, Time taken : 0.887s\n",
      "\tEpoch 34, Step 0300, MSE: 4.294e+02,  LearnRate: 6.250e-02, Time taken : 0.971s\n",
      "\tEpoch 34, Step 0400, MSE: 3.327e+02,  LearnRate: 6.250e-02, Time taken : 1.000s\n",
      "\tEpoch 34, Step 0500, MSE: 2.408e+03,  LearnRate: 6.250e-02, Time taken : 1.078s\n",
      "\tEpoch 34, Step 0600, MSE: 3.996e+01,  LearnRate: 6.250e-02, Time taken : 0.995s\n",
      "\tEpoch 34, Step 0700, MSE: 3.999e+02,  LearnRate: 6.250e-02, Time taken : 1.037s\n",
      "\tEpoch 34, Step 0800, MSE: 7.413e+02,  LearnRate: 6.250e-02, Time taken : 0.995s\n",
      "\tEpoch 34, Step 0900, MSE: 5.422e+02,  LearnRate: 6.250e-02, Time taken : 0.924s\n",
      "\tEpoch 34, Step 1000, MSE: 1.399e+03,  LearnRate: 6.250e-02, Time taken : 0.998s\n",
      "\tEpoch 34, Step 1100, MSE: 1.752e+03,  LearnRate: 6.250e-02, Time taken : 1.100s\n",
      "\tEpoch 34, Step 1200, MSE: 2.599e+03,  LearnRate: 6.250e-02, Time taken : 0.991s\n",
      "\tEpoch 34, Step 1300, MSE: 2.441e+03,  LearnRate: 6.250e-02, Time taken : 0.947s\n",
      "\tEpoch 34, Step 1400, MSE: 8.601e+01,  LearnRate: 6.250e-02, Time taken : 0.905s\n",
      "\tEpoch 34, Step 1500, MSE: 3.005e+02,  LearnRate: 6.250e-02, Time taken : 1.157s\n",
      "\tEpoch 34, Step 1600, MSE: 5.182e+01,  LearnRate: 6.250e-02, Time taken : 1.160s\n",
      "\tEpoch 34, Step 1700, MSE: 2.202e+03,  LearnRate: 6.250e-02, Time taken : 1.170s\n",
      "\tEpoch 34, Step 1800, MSE: 6.993e+02,  LearnRate: 6.250e-02, Time taken : 1.183s\n",
      "\tEpoch 34, Step 1900, MSE: 1.587e+02,  LearnRate: 6.250e-02, Time taken : 0.957s\n",
      "\tEpoch 34, Step 2000, MSE: 1.108e+03,  LearnRate: 6.250e-02, Time taken : 0.972s\n",
      "\tEpoch 34, Step 2100, MSE: 3.025e+02,  LearnRate: 6.250e-02, Time taken : 0.912s\n",
      "\tEpoch 34, Step 2200, MSE: 6.124e+00,  LearnRate: 6.250e-02, Time taken : 0.954s\n",
      "\tEpoch 34, Step 2300, MSE: 4.624e+02,  LearnRate: 6.250e-02, Time taken : 1.014s\n",
      "\tEpoch 34, Step 2400, MSE: 3.170e+03,  LearnRate: 6.250e-02, Time taken : 0.932s\n",
      "\tEpoch 34, Step 2500, MSE: 5.175e+01,  LearnRate: 6.250e-02, Time taken : 1.100s\n",
      "\tEpoch 34, Step 2600, MSE: 5.449e+02,  LearnRate: 6.250e-02, Time taken : 1.032s\n",
      "\tEpoch 34, Step 2700, MSE: 9.134e+02,  LearnRate: 6.250e-02, Time taken : 0.906s\n",
      "\tEpoch 34, Step 2800, MSE: 8.134e+02,  LearnRate: 6.250e-02, Time taken : 0.936s\n",
      "\tEpoch 34, Step 2900, MSE: 2.581e+02,  LearnRate: 6.250e-02, Time taken : 0.960s\n",
      "Starting Epoch 35, with 2909 batches\n",
      "\tEpoch 35, Step 0000, MSE: 4.886e+01,  LearnRate: 6.250e-02, Time taken : 0.215s\n",
      "\tEpoch 35, Step 0100, MSE: 7.490e+02,  LearnRate: 6.250e-02, Time taken : 0.934s\n",
      "\tEpoch 35, Step 0200, MSE: 8.534e+02,  LearnRate: 6.250e-02, Time taken : 1.017s\n",
      "\tEpoch 35, Step 0300, MSE: 4.696e+02,  LearnRate: 6.250e-02, Time taken : 0.935s\n",
      "\tEpoch 35, Step 0400, MSE: 2.110e+02,  LearnRate: 6.250e-02, Time taken : 0.997s\n",
      "\tEpoch 35, Step 0500, MSE: 5.146e+02,  LearnRate: 6.250e-02, Time taken : 0.965s\n",
      "\tEpoch 35, Step 0600, MSE: 5.075e+02,  LearnRate: 6.250e-02, Time taken : 0.991s\n",
      "\tEpoch 35, Step 0700, MSE: 1.218e+02,  LearnRate: 6.250e-02, Time taken : 0.992s\n",
      "\tEpoch 35, Step 0800, MSE: 2.532e+02,  LearnRate: 6.250e-02, Time taken : 1.019s\n",
      "\tEpoch 35, Step 0900, MSE: 1.073e+03,  LearnRate: 6.250e-02, Time taken : 0.936s\n",
      "\tEpoch 35, Step 1000, MSE: 4.988e+02,  LearnRate: 6.250e-02, Time taken : 0.961s\n",
      "\tEpoch 35, Step 1100, MSE: 2.097e+02,  LearnRate: 6.250e-02, Time taken : 0.927s\n",
      "\tEpoch 35, Step 1200, MSE: 9.386e+02,  LearnRate: 6.250e-02, Time taken : 0.896s\n",
      "\tEpoch 35, Step 1300, MSE: 5.248e+02,  LearnRate: 6.250e-02, Time taken : 0.983s\n",
      "\tEpoch 35, Step 1400, MSE: 2.405e+02,  LearnRate: 6.250e-02, Time taken : 0.993s\n",
      "\tEpoch 35, Step 1500, MSE: 4.784e+01,  LearnRate: 6.250e-02, Time taken : 0.970s\n",
      "\tEpoch 35, Step 1600, MSE: 9.225e+02,  LearnRate: 6.250e-02, Time taken : 0.983s\n",
      "\tEpoch 35, Step 1700, MSE: 4.707e+01,  LearnRate: 6.250e-02, Time taken : 1.002s\n",
      "\tEpoch 35, Step 1800, MSE: 8.460e+02,  LearnRate: 6.250e-02, Time taken : 0.895s\n",
      "\tEpoch 35, Step 1900, MSE: 3.486e+02,  LearnRate: 6.250e-02, Time taken : 0.915s\n",
      "\tEpoch 35, Step 2000, MSE: 6.990e+02,  LearnRate: 6.250e-02, Time taken : 1.021s\n",
      "\tEpoch 35, Step 2100, MSE: 7.730e+02,  LearnRate: 6.250e-02, Time taken : 0.957s\n",
      "\tEpoch 35, Step 2200, MSE: 1.152e+03,  LearnRate: 6.250e-02, Time taken : 0.921s\n",
      "\tEpoch 35, Step 2300, MSE: 3.513e+02,  LearnRate: 6.250e-02, Time taken : 0.937s\n",
      "\tEpoch 35, Step 2400, MSE: 1.438e+02,  LearnRate: 6.250e-02, Time taken : 1.023s\n",
      "\tEpoch 35, Step 2500, MSE: 2.177e+03,  LearnRate: 6.250e-02, Time taken : 1.010s\n",
      "\tEpoch 35, Step 2600, MSE: 2.954e+02,  LearnRate: 6.250e-02, Time taken : 0.898s\n",
      "\tEpoch 35, Step 2700, MSE: 3.126e+02,  LearnRate: 6.250e-02, Time taken : 0.907s\n",
      "\tEpoch 35, Step 2800, MSE: 3.271e+02,  LearnRate: 6.250e-02, Time taken : 0.984s\n",
      "\tEpoch 35, Step 2900, MSE: 2.532e+02,  LearnRate: 6.250e-02, Time taken : 0.961s\n",
      "Starting Epoch 36, with 2909 batches\n",
      "\tEpoch 36, Step 0000, MSE: 3.241e+02,  LearnRate: 6.250e-02, Time taken : 0.285s\n",
      "\tEpoch 36, Step 0100, MSE: 2.237e+02,  LearnRate: 6.250e-02, Time taken : 1.020s\n",
      "\tEpoch 36, Step 0200, MSE: 8.547e+02,  LearnRate: 6.250e-02, Time taken : 1.049s\n",
      "\tEpoch 36, Step 0300, MSE: 1.202e+03,  LearnRate: 6.250e-02, Time taken : 1.085s\n",
      "\tEpoch 36, Step 0400, MSE: 4.843e+02,  LearnRate: 6.250e-02, Time taken : 1.001s\n",
      "\tEpoch 36, Step 0500, MSE: 3.489e+01,  LearnRate: 6.250e-02, Time taken : 1.022s\n",
      "\tEpoch 36, Step 0600, MSE: 1.096e+02,  LearnRate: 6.250e-02, Time taken : 0.975s\n",
      "\tEpoch 36, Step 0700, MSE: 1.245e+02,  LearnRate: 6.250e-02, Time taken : 0.984s\n",
      "\tEpoch 36, Step 0800, MSE: 1.351e+03,  LearnRate: 6.250e-02, Time taken : 1.007s\n",
      "\tEpoch 36, Step 0900, MSE: 3.705e+02,  LearnRate: 6.250e-02, Time taken : 1.075s\n",
      "\tEpoch 36, Step 1000, MSE: 6.905e+02,  LearnRate: 6.250e-02, Time taken : 0.995s\n",
      "\tEpoch 36, Step 1100, MSE: 6.888e+01,  LearnRate: 6.250e-02, Time taken : 0.906s\n",
      "\tEpoch 36, Step 1200, MSE: 4.755e+00,  LearnRate: 6.250e-02, Time taken : 0.906s\n",
      "\tEpoch 36, Step 1300, MSE: 3.717e+01,  LearnRate: 6.250e-02, Time taken : 0.968s\n",
      "\tEpoch 36, Step 1400, MSE: 3.410e+02,  LearnRate: 6.250e-02, Time taken : 0.969s\n",
      "\tEpoch 36, Step 1500, MSE: 1.669e+02,  LearnRate: 6.250e-02, Time taken : 1.053s\n",
      "\tEpoch 36, Step 1600, MSE: 4.593e+02,  LearnRate: 6.250e-02, Time taken : 1.024s\n",
      "\tEpoch 36, Step 1700, MSE: 4.654e+02,  LearnRate: 6.250e-02, Time taken : 1.013s\n",
      "\tEpoch 36, Step 1800, MSE: 7.647e+01,  LearnRate: 6.250e-02, Time taken : 1.023s\n",
      "\tEpoch 36, Step 1900, MSE: 4.573e+02,  LearnRate: 6.250e-02, Time taken : 0.975s\n",
      "\tEpoch 36, Step 2000, MSE: 2.372e+02,  LearnRate: 6.250e-02, Time taken : 0.992s\n",
      "\tEpoch 36, Step 2100, MSE: 3.619e+03,  LearnRate: 6.250e-02, Time taken : 1.073s\n",
      "\tEpoch 36, Step 2200, MSE: 1.071e+03,  LearnRate: 6.250e-02, Time taken : 1.009s\n",
      "\tEpoch 36, Step 2300, MSE: 6.494e+01,  LearnRate: 6.250e-02, Time taken : 1.031s\n",
      "\tEpoch 36, Step 2400, MSE: 4.330e+02,  LearnRate: 6.250e-02, Time taken : 0.983s\n",
      "\tEpoch 36, Step 2500, MSE: 1.020e+03,  LearnRate: 6.250e-02, Time taken : 0.987s\n",
      "\tEpoch 36, Step 2600, MSE: 6.848e+02,  LearnRate: 6.250e-02, Time taken : 0.995s\n",
      "\tEpoch 36, Step 2700, MSE: 1.223e+02,  LearnRate: 6.250e-02, Time taken : 1.039s\n",
      "\tEpoch 36, Step 2800, MSE: 8.930e+01,  LearnRate: 6.250e-02, Time taken : 0.997s\n",
      "\tEpoch 36, Step 2900, MSE: 6.027e+01,  LearnRate: 6.250e-02, Time taken : 0.957s\n",
      "Starting Epoch 37, with 2909 batches\n",
      "\tEpoch 37, Step 0000, MSE: 1.154e+02,  LearnRate: 6.250e-02, Time taken : 0.232s\n",
      "\tEpoch 37, Step 0100, MSE: 3.359e+03,  LearnRate: 6.250e-02, Time taken : 1.034s\n",
      "\tEpoch 37, Step 0200, MSE: 8.568e+02,  LearnRate: 6.250e-02, Time taken : 1.026s\n",
      "\tEpoch 37, Step 0300, MSE: 3.141e+03,  LearnRate: 6.250e-02, Time taken : 0.959s\n",
      "\tEpoch 37, Step 0400, MSE: 5.768e+02,  LearnRate: 6.250e-02, Time taken : 0.936s\n",
      "\tEpoch 37, Step 0500, MSE: 3.070e+02,  LearnRate: 6.250e-02, Time taken : 0.989s\n",
      "\tEpoch 37, Step 0600, MSE: 6.190e+01,  LearnRate: 6.250e-02, Time taken : 1.042s\n",
      "\tEpoch 37, Step 0700, MSE: 1.104e+02,  LearnRate: 6.250e-02, Time taken : 0.893s\n",
      "\tEpoch 37, Step 0800, MSE: 2.296e+02,  LearnRate: 6.250e-02, Time taken : 1.058s\n",
      "\tEpoch 37, Step 0900, MSE: 2.669e+02,  LearnRate: 6.250e-02, Time taken : 1.096s\n",
      "\tEpoch 37, Step 1000, MSE: 1.655e+02,  LearnRate: 6.250e-02, Time taken : 0.981s\n",
      "\tEpoch 37, Step 1100, MSE: 3.434e+02,  LearnRate: 6.250e-02, Time taken : 0.994s\n",
      "\tEpoch 37, Step 1200, MSE: 8.305e+01,  LearnRate: 6.250e-02, Time taken : 0.992s\n",
      "\tEpoch 37, Step 1300, MSE: 2.403e+03,  LearnRate: 6.250e-02, Time taken : 0.939s\n",
      "\tEpoch 37, Step 1400, MSE: 3.920e+02,  LearnRate: 6.250e-02, Time taken : 0.948s\n",
      "\tEpoch 37, Step 1500, MSE: 4.800e+00,  LearnRate: 6.250e-02, Time taken : 1.120s\n",
      "\tEpoch 37, Step 1600, MSE: 1.741e+03,  LearnRate: 6.250e-02, Time taken : 1.094s\n",
      "\tEpoch 37, Step 1700, MSE: 8.129e+02,  LearnRate: 6.250e-02, Time taken : 1.022s\n",
      "\tEpoch 37, Step 1800, MSE: 1.063e+03,  LearnRate: 6.250e-02, Time taken : 0.997s\n",
      "\tEpoch 37, Step 1900, MSE: 1.309e+03,  LearnRate: 6.250e-02, Time taken : 0.973s\n",
      "\tEpoch 37, Step 2000, MSE: 1.813e+02,  LearnRate: 6.250e-02, Time taken : 1.022s\n",
      "\tEpoch 37, Step 2100, MSE: 2.006e+01,  LearnRate: 6.250e-02, Time taken : 0.982s\n",
      "\tEpoch 37, Step 2200, MSE: 2.609e+02,  LearnRate: 6.250e-02, Time taken : 1.048s\n",
      "\tEpoch 37, Step 2300, MSE: 1.099e+01,  LearnRate: 6.250e-02, Time taken : 0.978s\n",
      "\tEpoch 37, Step 2400, MSE: 8.577e+02,  LearnRate: 6.250e-02, Time taken : 0.987s\n",
      "\tEpoch 37, Step 2500, MSE: 9.862e+01,  LearnRate: 6.250e-02, Time taken : 0.928s\n"
     ]
    }
   ],
   "source": [
    "train_model_ai_kup(ai_kup_acc,ai_kup_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:intel_3.6_TF_1.8]",
   "language": "python",
   "name": "conda-env-intel_3.6_TF_1.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
